[ { "title": "Centos8 Development Of Machine", "url": "/posts/centos8-development-of-machine/", "categories": "Linux, CentOS", "tags": "", "date": "2022-06-05 00:00:00 +0800", "snippet": "æœ¬äººCentOSå¼€å‘æœåŠ¡å™¨æ¢äº†å—ç¡¬ç›˜ï¼Œå› æ­¤éœ€è¦é‡æ–°å®‰è£…ä¸€ä¸‹ï¼Œä¸ºäº†ä¸‹æ¬¡åŠ å¿«å®‰è£…è®¾ç½®é€Ÿåº¦ï¼ŒæŠŠé‡åˆ°çš„é—®é¢˜è®°å½•ä¸€ä¸‹CentOS8åˆå§‹å®‰è£…ä»‹è´¨æ˜¯CentOS 8.2ï¼Œä»å…‰ç›˜æˆ–è€…Uç›˜å¯åŠ¨ï¼Œè¿›å…¥å®‰è£…ç¨‹åºï¼š è¯­è¨€ï¼šEnglish æ—¶åŒºï¼šAsia/Shanghai æ ¹æ®éœ€è¦é€‰æ‹©å®‰è£…è½¯ä»¶ å®‰è£…ç£ç›˜ï¼šsda1ï¼Œå¦‚æœç©ºé—´ä¸å¤Ÿé€‰æ‹©æ¸…ç©ºç£ç›˜ ç½‘ç»œå¼€å…³æ‰“å¼€ä»¥å¤ªç½‘ è®¾ç½®rootå¯†ç ï¼ˆä¸è®¾ç½®æ— æ³•è¿œç¨‹ç™»å½•ï¼‰ è®¾ç½®ä¸€ä¸ªæ–°ç”¨æˆ· â€œadminâ€ å®‰è£…å®Œæˆï¼Œé‡å¯ç³»ç»Ÿä»¥rootç”¨æˆ·ç™»å½•ï¼Œå®Œæˆä¸€äº›åˆå§‹é…ç½®networkç¬¬ä¸€æ­¥è®¾ç½®ç½‘ç»œï¼Œå¦åˆ™æ²¡æœ‰è¿æ¥# ä¸‹é¢å‘½ä»¤ä¸­çš„enp2s0è§†ä¸åŒä¸»æœºçš„ç½‘å¡åç§°ä¼šæœ‰æ‰€ä¸åŒï¼ŒæŒ‰ç…§å®é™…æ›¿æ¢å³å¯vi /etc/sysconfig/network-scripts/ifcfg-enp2s0é…ç½®æ–‡ä»¶çš„åˆå§‹å€¼ONBOOT=noï¼Œæ„å‘³ç€ä¸ä¼šéšç³»ç»Ÿå¯åŠ¨è€Œå¯åŠ¨ï¼Œæ‰€ä»¥å¼€æœºåç½‘ç»œå¤„äºä¸å¯ç”¨çŠ¶æ€ï¼Œå¿…é¡»æ”¹æ‰ä½¿ç”¨DHCPè‡ªåŠ¨åˆ†é…IPçš„é…ç½®å¦‚ä¸‹TYPE=EthernetPROXY_METHOD=noneBROWSER_ONLY=noBOOTPROTO=dhcpDEFROUTE=yesIPV4_FAILURE_FATAL=noIPV6INIT=noIPV6_AUTOCONF=noIPV6_DEFROUTE=noIPV6_FAILURE_FATAL=noIPV6_ADDR_GEN_MODE=stable-privacyNAME=enp2s0UUID=1184bd2c-04f9-4169-8a4d-f9191cf60542DEVICE=enp2s0ONBOOT=yesä½¿ç”¨staticé™æ€IPé…ç½®å¦‚ä¸‹TYPE=EthernetPROXY_METHOD=noneBROWSER_ONLY=noBOOTPROTO=staticDEFROUTE=yesIPV4_FAILURE_FATAL=noIPV6INIT=noIPV6_AUTOCONF=noIPV6_DEFROUTE=noIPV6_FAILURE_FATAL=noIPV6_ADDR_GEN_MODE=stable-privacyNAME=enp2s0UUID=1184bd2c-04f9-4169-8a4d-f9191cf60542DEVICE=enp2s0IPADDR=192.168.0.100NETMASK=255.255.255.0GATEWAY=192.168.0.1ONBOOT=yesä¿®æ”¹å®Œæˆåé‡å¯ç½‘å¡# é‡æ–°åŠ è½½é…ç½®æ–‡ä»¶nmcli c reload# é‡å¯ç½‘å¡nmcli c up enp2s0æ›´æ¢yumæºä¸ºå›½å†…é˜¿é‡Œæºç”±äºCentos8çš„å®˜æ–¹æºå·²æ›´æ¢ï¼Œæˆ‘å®‰è£…å¥½çš„ç³»ç»Ÿæ ¹æœ¬è®¿é—®ä¸äº†é»˜è®¤yumæºï¼Œç›´æ¥å…¨éƒ¨åˆ é™¤é‡é…ç½®sudo rm -f /etc/yum.repos.d/*.reposudo curl -o /etc/yum.repos.d/CentOS-Base.repo http://mirrors.aliyun.com/repo/Centos-8.repoæ‰“å¼€ä¸‹è½½çš„CentOS-Base.repoæ·»åŠ å¦‚ä¸‹å†…å®¹[epel]name=epelbaseurl=https://mirrors.aliyun.com/epel/8/Everything/x86_64/gpgcheck=1gpgkey=https://mirrors.aliyun.com/epel/RPM-GPG-KEY-EPEL-8æ›´æ–°yumæºyum -y update" }, { "title": "ä¿®æ”¹bashçª—å£å‰å¯¼æç¤º", "url": "/posts/bash-pre-symbol/", "categories": "Linux", "tags": "", "date": "2022-05-29 11:01:00 +0800", "snippet": "ä¸Šæ¬¡ä¿®æ”¹æ¡Œé¢å¸ƒå±€åï¼Œterminal çª—å£å®½åº¦å˜å¾—è¾ƒä¸ºå›ºå®šï¼Œæ­¤æ—¶é‡åˆ°ä¸€ä¸ªé—®é¢˜æ˜¯å½“æˆ‘è¿›å…¥ä¸€ä¸ªåç§°è¾ƒé•¿çš„ç›®å½•åçª—å£çš„å‰å¯¼æç¤ºå·²ç»å æ®äº†ä¸€è¡Œä¸­å¤§åŠçš„ç©ºé—´ï¼Œä½“éªŒéå¸¸ä¸å¥½ï¼Œäºæ˜¯å†³å®šåŠ¨æ‰‹ä¿®æ”¹ä¸€ä¸‹ã€‚å…ˆæŸ¥çœ‹ä¸€ä¸‹å½“å‰æ‰€ä½¿ç”¨çš„å‰å¯¼æ ¼å¼echo $PS1&amp;gt; \\h:\\W \\u\\$è¿™é‡Œè´´ä¸€ä¸‹æ ¼å¼è¯´æ˜ï¼š å˜é‡ æè¿° \\d å½“å‰ç³»ç»Ÿæ—¥æœŸ \\t ç³»ç»Ÿæ—¶é—´ \\h ä¸»æœºå # å‘½ä»¤ç¬¦å· \\u ç”¨æˆ·å \\W å½“å‰è·¯å¾„å \\w å½“å‰å®Œæ•´è·¯å¾„ ä¿®æ”¹ä¸ºåªæ˜¾ç¤ºå½“å‰è·¯å¾„åçš„æ ¼å¼ï¼Œå› ä¸ºè¦ä¿®æ”¹ç³»ç»Ÿçº§é…ç½®ï¼Œéœ€è¦åŠ ä¸Šsudoä½¿ç”¨rootæƒé™sudo sed -i &#39;&#39; &#39;s/\\\\h:\\\\W \\\\u/\\\\W/g&#39; /etc/bashrc# æ£€æŸ¥ä¿®æ”¹æ˜¯å¦æ­£ç¡®cat /etc/bash | grep PS1=&amp;gt; PS1=&#39;\\W\\$&#39;# ä½¿ä¿®æ”¹ç”Ÿæ•ˆsource /etc/bashrc" }, { "title": "Flink CDC 2.2", "url": "/posts/flink-cdc-2.2/", "categories": "Big data, Flink", "tags": "", "date": "2022-05-28 00:00:00 +0800", "snippet": "Flink CDC å‘å¸ƒäº†2.2ç‰ˆæœ¬ï¼Œè¿™æ¬¡æ–°å¢åŠ äº†4ç§æ•°æ®æºï¼šOceanBaseï¼ŒPolarDB-Xï¼ŒSqlServerï¼ŒTiDBï¼›è¿™å…¶ä¸­çš„ä¸‰ç§ï¼šOceanBaseï¼ŒSqlServerï¼ŒTiDBåº”è¯¥ç®—æ˜¯æ¯”è¾ƒå¸¸è§çš„æ•°æ®åº“äº†ï¼Œè€Œä¸”å¯¹äºMySQLçš„åŒæ­¥æ”¯æŒåŠ¨æ€åŠ è¡¨ï¼Œä¹Ÿå°±æ˜¯è¯´å¯ä»¥åœ¨åŸæ¥çš„åŒæ­¥ä¸ä¸­æ–­çš„æƒ…å†µä¸‹å¢åŠ å¯¹æ–°è¡¨çš„åŒæ­¥ï¼Œå¯ä»¥è¯´æ˜¯ä¸€ä¸ªéå¸¸é‡è¦çš„åŠŸèƒ½ã€‚ to be continueâ€¦" }, { "title": "Linux Usb Image", "url": "/posts/linux-usb-image/", "categories": "Linux", "tags": "", "date": "2020-12-25 00:00:00 +0800", "snippet": "åšç‰©è”ç½‘ç›¸å…³é¡¹ç›®æ—¶ï¼Œç»å¸¸éœ€è¦åœ¨ä¼—å¤šåŒç±»ä¸»æœºä¸Šå®‰è£…Linuxç³»ç»Ÿï¼Œå¹¶é…ç½®ä¸Šä¸€ç³»åˆ—è½¯ä»¶ï¼Œæ‰‹åŠ¨ä¸€å°å°å®‰è£…åˆæ…¢åˆå®¹æ˜“å‡ºé”™ï¼Œæ­¤æ—¶å¯é‡‡ç”¨USBè®¾å¤‡å®‰è£…æ–¹æ¡ˆï¼Œå…·ä½“åšæ³•æ˜¯ä½¿ç”¨é‡äº§å·²å®‰è£…å¥½Linuxç³»ç»ŸåŠè½¯ä»¶çš„Uç›˜ï¼Œæ€¼åˆ°ä¸»æœºä¸Šå°±å¯ä»¥è¿è¡Œäº†ï¼Œå…ˆæŒ‰ç…§éœ€è¦åˆ¶ä½œå¥½Linuxé•œåƒï¼Œç„¶åå°†é•œåƒå†™å…¥USBç›˜ï¼Œæœ€åå°†USBç›˜æ’ä¸Šä¸»æœºUSBå£è®¾ç½®ä¸ºUSBå¼•å¯¼å¼€æœºã€‚Linuxå‘è¡Œç‰ˆé€‰æ‹©é€‰å®šLinuxå‘è¡Œç‰ˆï¼Œåœ¨ä¸»æœºä¸Šè¿›è¡Œç³»ç»Ÿå®‰è£…å’Œè½¯ä»¶åŠŸèƒ½æµ‹è¯•ï¼Œç¡®ä¿ç³»ç»ŸåŠŸèƒ½å…¼å®¹å’Œè½¯ä»¶å¯ç”¨æ€§ï¼Œå®Œæˆæµ‹è¯•åå°±å¯ä»¥é€‰å®šå‘è¡Œç‰ˆäº†ã€‚ä¸‹é¢ä»¥ArchLinuxå‘è¡Œç‰ˆä¸ºä¾‹ç¼–å†™è°ƒåº¦å®‰è£…è„šæœ¬ åœ¨å¼€å‘æœºä¸Šå®‰è£…VMWareæˆ–Virtualboxè™šæ‹Ÿæœºè½¯ä»¶ ä¸‹è½½ArchLinuxå‘è¡Œç‰ˆisoé•œåƒæ–‡ä»¶ åˆ›å»ºä¸€ä¸ªLinuxè™šæ‹Ÿæœºå¹¶è®¾ç½®ä¸ºisoé•œåƒå¯åŠ¨ å‡†å¤‡1ä¸ª8Gä»¥ä¸ŠUç›˜ï¼ˆæˆ–è€…USBç§»åŠ¨ç¡¬ç›˜ï¼‰ç©ºç›˜ï¼Œå®¹é‡å¤§å°è§†è¦å®‰è£…çš„ç³»ç»ŸåŠè½¯ä»¶å¤§å°è€Œå®šï¼Œ16Gä»¥ä¸Šå®¹é‡æ›´ä¸ºç¨³å¦¥ å°†Uç›˜æ¥å…¥å®¿ä¸»æœºï¼Œå¹¶è®¾ç½®è™šæ‹Ÿæœºå¯¹USBè®¾å¤‡çš„è®¿é—®ï¼ŒVMWare æˆ– Virtualboxæœ‰ä¸åŒçš„è®¾ç½®æ–¹å¼ å¯åŠ¨è™šæ‹Ÿæœºä»å…‰é©±é•œåƒè¿›å…¥ArchLinuxç³»ç»Ÿ ç¼–å†™åœ¨USBè®¾å¤‡ä¸Šå®‰è£…Linuxç³»ç»Ÿçš„åˆå§‹åŒ–è„šæœ¬#!/usr/bin/bash#1.Network Testtimedatectl set-ntp truedhcpcdecho &quot;ArchLinux to USB Flash Disk Auto Install&quot;echo &quot;Ver:1.0&quot;echo &quot;github.com/multichian/arch-usb-installer&quot;#2.Disk Partitionlsblkread -t 5 -p &quot;Select Your USB Disk (Default &#39;sdb&#39;):&quot; DISKDISK=${DISK:-&#39;sdb&#39;}read -t 5 -p &quot;Storage Size(Default 200M):&quot; STORAGESTORAGE=${STORAGE:-200}read -t 5 -p &quot;EFI Size(Default 100M):&quot; EFIEFI=${EFI:-100}OS=`expr 8000 - $STORAGE - $EFI`echo &quot;OS Size:&quot; $OSread -t 5 -p &quot;Are you sure you choice is correct? Enter N to restart: &quot; AXif [[ ${AX} = N ]]; then exitfifdisk /dev/${DISK} &amp;lt;&amp;lt;EOF d o n p +${EFI}M n p +${STORAGE}M n p +${OS}M wqEOFecho &quot;Partition USB Disk Done&quot;#3.Wipe And Mount Diskmkfs.vfat /dev/${DISK}1 -n EFImkfs.vfat /dev/${DISK}2 -n MCOSmkfs.ext4 -O &quot;^has_journal&quot; /dev/${DISK}3mount /dev/${DISK}3 /mntmkdir -p /mnt/boot/efimount /dev/${DISK}1 /mnt/boot/efiecho &quot;Wipe And Mount USB Disk Done&quot;#4.Using China Mirrorlistmv /etc/pacman.d/mirrorlist /etc/pacman.d/mirrorlist.old#echo -e &quot;https://mirrors.ustc.edu.cn/archlinux/$repo/os/$arch\\n&quot;echo &quot;Server=https://mirrors.ustc.edu.cn/archlinux/\\$repo/os/\\$arch&quot; &amp;gt;&amp;gt; /etc/pacman.d/mirrorlistecho &quot;Server=https://mirrors.aliyun.com/archlinux/\\$repo/os/\\$arch&quot; &amp;gt;&amp;gt; /etc/pacman.d/mirrorlist#echo -e &quot;\\n## China mirrors\\nhttps://mirrors.ustc.edu.cn/archlinux/\\$repo/os/\\$arch\\nhttps://mirrors.163.com/archlinux/\\$repo/os/\\$arch&quot; &amp;gt;&amp;gt; mirrorlistecho &quot;Change China Source Done&quot;#5.Install System#pacstrap /mnt base base-devel linux linux-firmware dhcpcd ntfs-3g dialog vim wireless_tools wpa_supplicant net-tools dosfstools opensshpacstrap /mnt base base-devel linux linux-firmware dhcpcd vim net-tools sudo grub efibootmgrecho &quot;Install Package Done&quot;#6.FSTABgenfstab -U -p /mnt &amp;gt;&amp;gt; /mnt/etc/fstabcat /mnt/etc/fstab#7.Enter New Systemarch-chroot /mntæ‰§è¡Œå®Œæˆè¯¥è„šæœ¬åï¼ŒUSBè®¾å¤‡ä¸Šå·²ç»å®‰è£…å¥½Arch LinuxåŸºæœ¬ç³»ç»Ÿï¼Œä¸‹ä¸€æ­¥éœ€è¦åšä¸€äº›å¼•å¯¼é…ç½®ã€ç”¨æˆ·å¯†ç åŠè‡ªåŠ¨ç™»å½•è®¾ç½®ï¼Œå› ä¸ºè¿™äº›éœ€è¦åœ¨å·²ç»å®‰è£…å¥½çš„ç³»ç»Ÿä¸Šæ‰§è¡Œï¼Œå› æ­¤éœ€è¦å†ç¼–å†™ä¸€ä¸ªè„šæœ¬#8.Locale and Langecho -e &quot;en_US.UTF-8 UTF-8\\nzh_CN.UTF-8 UTF-8\\n&quot; &amp;gt; /etc/locale.genlocale-genecho -e &quot;LANG=en_US.UTF-8\\nLC_TYPE=en_US.UTF-8&quot; &amp;gt; /etc/locale.confln -sf /usr/share/zoneinfo/Asia/Shanghai /etc/localtimehwclock --systohc --localtime#9.Machine infoecho &quot;MCOS&quot; &amp;gt; /etc/hostnameecho -e &#39;127.0.0.1 localhost\\n::1 localhost\\n127.0.1.1 mcos.localdomain mcos&#39; &amp;gt;&amp;gt; /etc/hostssed -i &#39;/^HOOKS/cHOOKS=(base udev block keyboard autodetect modconf filesystems fsck)&#39; /etc/mkinitcpio.confmkinitcpio -Psystemctl enable dhcpcdsystemctl enable sshdecho &quot;Create New initramfs Done&quot;#10.Install GRUBecho &quot;Install Grub&quot;lsblkread -p &quot;Select Your USB Disk:&quot; DISKgrub-install --target=i386-pc /dev/${DISK}grub-install --target=x86_64-efi --efi-directory=/boot/efi --removable --recheckgrub-mkconfig -o /boot/grub/grub.cfgcp -v /usr/share/grub/{unicode.pf2,ascii.pf2} /boot/grub/cp -v /usr/share/locale/en\\@quot/LC_MESSAGES/grub.mo /boot/grub/locale/en.moecho &quot;Install Grub Done&quot;#11.Setup Autologinecho &quot;Autologin&quot;mkdir /etc/systemd/system/getty@tty1.service.d/cd /etc/systemd/system/getty@tty1.service.d/echo -e &quot;[Service]\\nExecStart=\\nExecStart=-/usr/bin/agetty --autologin miner --noclear %I 38400 linux&quot; &amp;gt; autologin.conf#12. Initialize User and passwordecho &quot;Initialize the Users&quot;echo &quot;Set Root passwd:&quot;passwduseradd -m -G wheel,audio,video,optical,storage minerecho &quot;Set miner passwd:&quot;passwd minerread -p &quot;Do you want VISUDO? Enter Y or N&quot; VXif [[ ${VX} = Y ]]; then visudofi## %wheel ALL=(ALL) ALL## $wheel ALL=(ALL) NOPASSWD: ALLecho &quot;User initialization is complete&quot;read -p &quot;Do you want to poweroff? Enter Y to shutdown:&quot; CXif [[ ${CX} = Y ]]; then poweroffelse exitfiåˆ°è¿™ä¸€æ­¥å¯ä»¥USBå¯åŠ¨ç³»ç»Ÿå¹¶ç™»å½•äº†ï¼Œè¿˜æœ‰ä¸€æ­¤åŸºäºç”¨æˆ·çš„é…ç½®å’Œè½¯ä»¶å®‰è£…ï¼Œè¿™ä¸€æ­¥å¯ä»¥è‡ªä¸»å®šåˆ¶ï¼Œæ¯”å¦‚å®‰è£…ä¸šåŠ¡è½¯ä»¶ä»€ä¹ˆçš„â€¦#13. Install Openbox# éœ€è¦åœ¨ç™»å½•ç”¨æˆ·ä¸‹æ“ä½œsudo pacman -Sy xorg-server xorg-xinit xterm openbox # å®‰è£…å­—ä½“sudo pacman -S noto-fonts-cjk python python-pip# å®‰è£…æ‰©å±•å­—ä½“sudo pacman -S ttf-dejavu ttf-liberation wqy-zenhei ttf-arphic-ukai ttf-arphic-uming mkdir -p ~/.config/openboxcp /etc/xdg/openbox/* ~/.config/openbox/echo &quot;xterm -hold -e cal&quot; &amp;gt;&amp;gt; ~/.config/openbox/autostartecho &quot;exec openbox-session&quot; &amp;gt; ~/.xinitrcecho &quot;#Auto startx&quot;echo &quot;if [ -z \\&quot;\\$DISPLAY\\&quot; ] &amp;amp;&amp;amp; [ -n \\&quot;\\$XDG_VTNR\\&quot; ] &amp;amp;&amp;amp; [ \\&quot;\\$XDG_VTNR\\&quot; -eq 1 ]; then&quot;echo &quot; exec startx&quot;echo &quot;fi&quot;#14. Install environmentsudo pacman -S python python-pippip install psutil GPUtil tabulateä¸€åˆ‡å®‰è£…å®Œæ¯•åï¼Œå°†USBç›˜å†…å®¹åˆ¶æˆimgç£ç›˜é•œåƒï¼ŒMac/Linuxç³»ç»Ÿä¸­å¯ä»¥ç”¨ddå‘½ä»¤æˆ–è€…å®‰è£…é•œåƒåˆ¶ä½œè½¯ä»¶dd if=/dev/sdb1 of=./archlinux.img bs=10mç„¶åæ¢ä¸Šå…¶å®ƒç©ºUç›˜å‡å¯ä»¥ç”¨è¿™ä¸ªimgæ–‡ä»¶å†™å…¥ï¼Œå› ä¸ºUç›˜å†™å…¥é€Ÿåº¦è¾ƒæ…¢ï¼Œå¯ä»¥å‡ ä¸ªUSBå£æ’æ»¡Uç›˜ç„¶åå¤šæ¡å‘½ä»¤å¹¶è¡Œå†™å…¥ï¼Œå¤§å¤§ç¼©çŸ­åˆ¶ä½œæ—¶é—´åˆ°è¿™ä¸€æ­¥ï¼Œå¯èƒ½æœ‰äººä¼šè¯´ï¼šâ€œä¹Ÿå¯ä»¥ä¸ç¼–å†™è„šæœ¬å•Šï¼Œæˆ‘åªè¦åœ¨è™šæ‹Ÿæœºé‡ŒæŠŠç³»ç»Ÿåˆ¶ä½œå¥½ï¼Œå†åˆ¶æˆé•œåƒå°±è¡Œã€‚â€ æ²¡é”™ï¼åˆ¶ä½œè„šæœ¬çš„ç›®çš„ä¸»è¦æ˜¯ä¸ºäº†æ–¹ä¾¿ç»´æŠ¤å’Œåˆ†å‘ï¼Œä»è„šæœ¬å°±å¯ä»¥å¾ˆæ¸…æ¥šçŸ¥é“åœ¨ç³»ç»ŸåŸºç¡€ä¸Šåšäº†å“ªäº›è®¾ç½®å’Œå°è£…ï¼Œåç»­è¦æ›´æ”¹é›†æˆçš„è½¯ä»¶ï¼Œæˆ–è€…å‡çº§ä¹‹ç±»åªéœ€è¦ä¿®æ”¹è„šæœ¬å°±è¡Œï¼Œä¸éœ€è¦ä¸€ç›´è™šæ‹Ÿæœºé•œåƒå’Œimgæ–‡ä»¶ï¼Œåˆ†å‘æ–‡ä»¶ä½“ç§¯ä¼šå¤§å¤§ç¼©å°" }, { "title": "Canal Server Config", "url": "/posts/canal-server-config/", "categories": "", "tags": "", "date": "2019-10-11 00:00:00 +0800", "snippet": "canalæ˜¯ä¸€æ¬¾MySQLå¢é‡æ—¥å¿—è§£æå¹¶æä¾›è®¢é˜…&amp;amp;æ¶ˆè´¹æ¶ˆæ¯ä¸­é—´ä»¶ï¼Œé€šè¿‡é…ç½®canalä¼ªè£…ä¸ºMySQLçš„SlaveèŠ‚ç‚¹ï¼Œæ¥æ”¶è§£æMySQLçš„åŒæ­¥æ—¥å¿—å°†å…¶è½¬åŒ–ä¸ºç›¸åº”æ¶ˆæ¯ç³»ç»Ÿæ¶ˆæ¯ï¼ŒåŸå§‹ä½¿ç”¨åœºæ™¯æ˜¯åšä¸ºotterä¸­é—´ä»¶çš„ä¸€éƒ¨åˆ†ï¼Œåæ¥æˆä¸ºç‹¬ç«‹å¼€æºé¡¹ç›®ï¼Œå·²ç»è´¡çŒ®ç»™ApacheåŸºé‡‘ä¼šã€‚canalå¸¸è§ä½¿ç”¨åœºæ™¯æœ‰4ç§ï¼Œé™¤åšä¸ºotterç»„ä»¶å¤–ï¼Œè¿˜å¯ä»¥åšä¸º ç¼“å­˜åŒæ­¥è§¦å‘æ¶ˆæ¯ è‡ªåŠ¨å¡«å……æ•°æ®åº“æ‹‰é“¾è¡¨ åšä¸ºå®æ—¶ç»Ÿè®¡æ•°æ®æºcanalåœ¨å¤§æ•°æ®åœºæ™¯è¾ƒä¸ºå¸¸ç”¨ï¼ˆä¸Šé¢ç¬¬4ä¸ªåœºæ™¯ï¼‰ï¼Œé€šè¿‡è®¢é˜…ä¸šåŠ¡MySQLåº“çš„æ•°æ®å˜æ›´å¹¶è½¬åŒ–ä¸ºkafkaæ¶ˆæ¯ï¼Œå†ç”±Flinkè®¡ç®—ç¨‹åºè¿›è¡Œå®æ—¶è®¡ç®—ï¼Œå¯ä»¥è¾ƒå¥½æ»¡è¶³ä¸šåŠ¡æ–¹å®æ—¶æ•°ä»“å»ºè®¾éœ€æ±‚ã€‚æ‹‰å–æ‰€éœ€dockeré•œåƒè¿™æ¬¡åœ¨dockerå®¹å™¨éƒ¨ç½²ä¸€ä¸ªcanal serveråšä¸ºå¼€å‘ç¯å¢ƒdocker pull canal/canal-serverdocker pull mysql_master:5.7.1åœ¨MySQLä¸­é…ç½®canalç”¨æˆ·docker exec -it mysql_master bashCREATE USER canal IDENTIFIED BY &#39;canal&#39;;GRANT SELECT, SHOW VIEW, REPLICATION SLAVE, REPLICATION CLIENT ON *.* TO &#39;canal&#39;@&#39;%&#39;;FLUSH PRIVILEGES;å¯åŠ¨canal serverdocker run --name canal-server \\ -e canal.instance.master.address=10.50.9.55:3406 \\ -e canal.instance.dbUsername=canal \\ -e canal.instance.dbPassword=canal \\ -p 11111:11111 \\ -d canal/canal-server:v1.1.4./run_server.sh -e canal.admin.manager=10.50.9.55:8089 \\ -e canal.admin.port=11110 \\ -e canal.admin.user=admin \\ -e canal.admin.passwd=******canal.propertiesä¹Ÿå¯ä»¥æŠŠé…ç½®å†™åˆ°é…ç½®æ–‡ä»¶ä¸­ï¼Œç„¶åå¯åŠ¨æ—¶æŒ‡å®šé…ç½®æ–‡ä»¶å¯åŠ¨########################################################## common argument ############################################################### tcp bind ipcanal.ip =# register ip to zookeepercanal.register.ip =canal.port = 11111canal.metrics.pull.port = 11112# canal instance user/passwdcanal.user = canalcanal.passwd = E3619321C1A937C46A0D8BD1DAC39F93B27D4458# canal admin configcanal.admin.manager = 127.0.0.1:8089canal.admin.port = 11110canal.admin.user = admincanal.admin.passwd = 4ACFE3202A5FF5CF467898FC58AAB1D615029441canal.zkServers =# flush data to zkcanal.zookeeper.flush.period = 1000canal.withoutNetty = false# tcp, kafka, RocketMQcanal.serverMode = tcp# flush meta cursor/parse position to filecanal.file.data.dir = ${canal.conf.dir}canal.file.flush.period = 1000## memory store RingBuffer size, should be Math.pow(2,n)canal.instance.memory.buffer.size = 16384## memory store RingBuffer used memory unit size , default 1kbcanal.instance.memory.buffer.memunit = 1024 ## meory store gets mode used MEMSIZE or ITEMSIZEcanal.instance.memory.batch.mode = MEMSIZEcanal.instance.memory.rawEntry = true## detecing configcanal.instance.detecting.enable = false#canal.instance.detecting.sql = insert into retl.xdual values(1,now()) on duplicate key update x=now()canal.instance.detecting.sql = select 1canal.instance.detecting.interval.time = 3canal.instance.detecting.retry.threshold = 3canal.instance.detecting.heartbeatHaEnable = false# support maximum transaction size, more than the size of the transaction will be cut into multiple transactions deliverycanal.instance.transaction.size = 1024# mysql fallback connected to new master should fallback timescanal.instance.fallbackIntervalInSeconds = 60# network configcanal.instance.network.receiveBufferSize = 16384canal.instance.network.sendBufferSize = 16384canal.instance.network.soTimeout = 30# binlog filter configcanal.instance.filter.druid.ddl = truecanal.instance.filter.query.dcl = falsecanal.instance.filter.query.dml = falsecanal.instance.filter.query.ddl = falsecanal.instance.filter.table.error = falsecanal.instance.filter.rows = falsecanal.instance.filter.transaction.entry = false# binlog format/image checkcanal.instance.binlog.format = ROW,STATEMENT,MIXED canal.instance.binlog.image = FULL,MINIMAL,NOBLOB# binlog ddl isolationcanal.instance.get.ddl.isolation = false# parallel parser configcanal.instance.parser.parallel = true## concurrent thread number, default 60% available processors, suggest not to exceed Runtime.getRuntime().availableProcessors()#canal.instance.parser.parallelThreadSize = 16## disruptor ringbuffer size, must be power of 2canal.instance.parser.parallelBufferSize = 256# table meta tsdb infocanal.instance.tsdb.enable = truecanal.instance.tsdb.dir = ${canal.file.data.dir:../conf}/${canal.instance.destination:}canal.instance.tsdb.url = jdbc:h2:${canal.instance.tsdb.dir}/h2;CACHE_SIZE=1000;MODE=MYSQL;canal.instance.tsdb.dbUsername = canalcanal.instance.tsdb.dbPassword = canal# dump snapshot interval, default 24 hourcanal.instance.tsdb.snapshot.interval = 24# purge snapshot expire , default 360 hour(15 days)canal.instance.tsdb.snapshot.expire = 360# aliyun ak/sk , support rds/mqcanal.aliyun.accessKey =canal.aliyun.secretKey =########################################################## destinations ##############################################################canal.destinations =# conf root dircanal.conf.dir = ../conf# auto scan instance dir add/remove and start/stop instancecanal.auto.scan = truecanal.auto.scan.interval = 5canal.instance.tsdb.spring.xml = classpath:spring/tsdb/h2-tsdb.xml#canal.instance.tsdb.spring.xml = classpath:spring/tsdb/mysql-tsdb.xmlcanal.instance.global.mode = managercanal.instance.global.lazy = falsecanal.instance.global.manager.address = ${canal.admin.manager}#canal.instance.global.spring.xml = classpath:spring/memory-instance.xmlcanal.instance.global.spring.xml = classpath:spring/file-instance.xml#canal.instance.global.spring.xml = classpath:spring/default-instance.xml########################################################### MQ ###############################################################canal.mq.servers = 127.0.0.1:6667canal.mq.retries = 0canal.mq.batchSize = 16384canal.mq.maxRequestSize = 1048576canal.mq.lingerMs = 100canal.mq.bufferMemory = 33554432canal.mq.canalBatchSize = 50canal.mq.canalGetTimeout = 100canal.mq.flatMessage = truecanal.mq.compressionType = nonecanal.mq.acks = all#canal.mq.properties. =canal.mq.producerGroup = test# Set this value to &quot;cloud&quot;, if you want open message trace feature in aliyun.canal.mq.accessChannel = local# aliyun mq namespace#canal.mq.namespace =########################################################### Kafka Kerberos Info ###############################################################canal.mq.kafka.kerberos.enable = falsecanal.mq.kafka.kerberos.krb5FilePath = &quot;../conf/kerberos/krb5.conf&quot;canal.mq.kafka.kerberos.jaasFilePath = &quot;../conf/kerberos/jaas.conf&quot;" }, { "title": "CentOSä¸‹çš„dockerå®‰è£…ä¸é…ç½®", "url": "/posts/centos-docker-install&config/", "categories": "", "tags": "", "date": "2019-08-05 00:00:00 +0800", "snippet": "ç‰ˆæœ¬ CentOS 8.2docker-ceç»æµ‹è¯•yumé‡Œçš„dockeråŒ…ä¸èƒ½ç›´æ¥å®‰è£…ï¼Œç›´æ¥å®‰è£…çš„æ˜¯podman-dockeræ‰§è¡Œdockerå‘½ä»¤ä¼šæŠ›å‡ºå¦‚ä¸‹é”™è¯¯Emulate Docker CLI using podman. Create /etc/containers/nodocker to quiet msg./usr/bin/podman: symbol lookup error: /usr/bin/podman: undefined symbol: seccomp_notify_fdåˆ é™¤åŸæœ‰å®‰è£…ï¼Œé‡æ–°å®‰è£…é˜¿é‡Œæºçš„docker-cesudo yum remove docker# é…ç½®é˜¿é‡Œdocker-ceæºsudo yum-config-manager --add-repo http://mirrors.aliyun.com/docker-ce/linux/centos/docker-ce.repo# æ›´æ–°yumåŒ…sudo yum makecache fast# å®‰è£…docker-cesudo yum -y install docker-ce# å¯åŠ¨ docker æœåŠ¡ï¼Œå¦åˆ™dockerç›¸å…³å‘½ä»¤æ— æ³•æ‰§è¡Œsudo systemctl start docker## è®¾ç½® docker æœåŠ¡è‡ªå¯åŠ¨sudo systemctl enable dockeræ­¤æ—¶è¿è¡Œdockerå‘½ä»¤ä¼šæç¤ºæƒé™ä¸å¤Ÿï¼Œä½¿ç”¨sudoå€’æ˜¯å¯ä»¥äº†ï¼Œä½†æ˜¯å¯ä»¥é€šè¿‡ç®€å•çš„é…ç½®è®©æ™®é€šè´¦æˆ·ä¹Ÿèƒ½æ‰§è¡Œdockerå‘½ä»¤ï¼Œè¿™é‡Œä»¥adminè´¦æˆ·ä¸ºä¾‹ï¼Œè¦æ±‚è®¾ç½®çš„è´¦æˆ·æœ‰sudoæƒé™# æŸ¥çœ‹dockerç”¨æˆ·sudo cat /etc/group | grep docker# å¦‚æœæ˜¾ç¤ºå¦‚ä¸‹ä¿¡æ¯è¡¨ç¤ºå­˜åœ¨dockerç”¨æˆ·ï¼Œä¸€èˆ¬æ­£å¸¸å®‰è£…docker-ceéƒ½ä¼šåˆ›å»ºè¿™ä¸ªç”¨æˆ·# docker:x:987ll /var/run/docker.sock# æ˜¾ç¤ºå¦‚ä¸‹# srw-rw----, 1 root docker 0 8æœˆ 5 20:31 /var/run/docker.sock# å°†å½“å‰ç”¨æˆ·adminæ·»åŠ è‡³dockerç»„sudo gpasswd -a admin docker# åˆ·æ–°ç»„ä¿¡æ¯newgrp docker# æŸ¥çœ‹å½“å‰è´¦æˆ·æ‰€å±ç»„ä¿¡æ¯id# uid=1000(admin) gid=987(docker) groups=987(docker),10(wheel),1000(admin) å†ç”¨è¯¥ç”¨æˆ·è¾“å…¥dockerç›¸å…³å‘½ä»¤å°±ä¸å†æœ‰æƒé™æç¤ºäº†" }, { "title": "æ•°ä»“æŒ‡æ ‡ä½“ç³»å»ºè®¾", "url": "/posts/data-index-system/", "categories": "Data Warehouse", "tags": "", "date": "2019-07-11 17:11:00 +0800", "snippet": "ä¸ºä»€ä¹ˆè¦å»ºç«‹æŒ‡æ ‡ä½“ç³»ï¼Ÿæ•°æ®æŒ‡æ ‡ä½“ç³»è‚¯å®šå› ä¸ºå­˜åœ¨ä¸šåŠ¡ç—›ç‚¹è€Œäº§ç”Ÿçš„éœ€æ±‚ï¼Œæˆ‘ä»¬éœ€è¦çœ‹ä¸€ä¸‹ç—›ç‚¹æ˜¯å¦ä¸æŒ‡æ ‡ä½“ç³»èƒ½è§£å†³çš„å±äºåŒä¸€é—®é¢˜åŸŸç—›ç‚¹åˆ†æä» ä¸šåŠ¡ã€æŠ€æœ¯ã€äº§å“ ä¸‰ä¸ªè§’åº¦æ¥çœ‹ä¸šåŠ¡è§†è§’ä¸šåŠ¡åˆ†æåœºæ™¯ã€æŒ‡æ ‡ã€ç»´åº¦ä¸æ˜è§£æ•°æ®éœ€é¢‘ç¹å˜æ›´ï¼Œæ•°æ®å£å¾„ä¸ç»Ÿä¸€ã€å„ä¸šåŠ¡ç³»ç»Ÿæ•°æ®å‚å·®ä¸é½ç”¨æˆ·åˆ†æå…·ä½“ä¸šåŠ¡é—®é¢˜æ‰¾æ•°æ®ï¼Œæ ¸å¯¹æ•°æ®æˆæœ¬é«˜æŠ€æœ¯è§†è§’æŒ‡æ ‡å®šä¹‰å’Œå‘½åæ··ä¹±ï¼Œæ²¡æœ‰ä¸€ä¸ªç»Ÿä¸€è®¤çŸ¥ï¼ŒæŒ‡æ ‡ä¸å”¯ä¸€ï¼ŒæŒ‡æ ‡ç»´æŠ¤å£å¾„ä¸ä¸€è‡´ï¼Œä¸šåŠ¡å›¢é˜Ÿå’Œæ•°æ®å›¢é˜Ÿæœ‰è®¤è¯†åå·®æŒ‡æ ‡ç”Ÿäº§ï¼Œé‡å¤å»ºè®¾ï¼Œæ•°æ®æ±‡ç®—æˆæœ¬é«˜æŒ‡æ ‡æ¶ˆè´¹ã€å‡ºå£ä¸ç»Ÿä¸€ï¼Œé‡å¤è¾“å‡ºï¼Œè¾“å‡ºå£å¾„ä¸ä¸€è‡´äº§å“è§†è§’ç¼ºä¹ç³»ç»Ÿäº§å“åŒ–æ”¯æŒä»ç”Ÿäº§åˆ°æ¶ˆè´¹æ•°æ®æµæ²¡æœ‰ç³»ç»Ÿäº§å“å±‚é¢æ‰“é€šç®¡ç†ç›®æ ‡æŠ€æœ¯ç›®æ ‡ç»Ÿä¸€æŒ‡æ ‡å’Œç»´åº¦ç®¡ç†ã€æŒ‡æ ‡å‘½ä»¤ã€æŒ‡æ ‡å£å¾„ã€æ•°æ®æ¥æºï¼Œç»´åº¦å®šä¹‰è§„èŒƒã€ç»´åº¦å€¼ä¸€è‡´ä¸šåŠ¡ç›®æ ‡ç»Ÿä¸€æ•°æ®å‡ºå£ã€ç»Ÿä¸€åœºæ™¯è¦†ç›–äº§å“ç›®æ ‡æŒ‡æ ‡ä½“ç³»ç®¡ç†å·¥å…·è½åœ°ï¼ŒæŒ‡æ ‡ä½“ç³»å†…å®¹äº§å“åŒ–è½åœ°æ”¯æŒå†³ç­–ã€åˆ†æã€è¿è¥æ¨¡å‹æ¶æ„ åˆ’åˆ†ä¸šåŠ¡æ¿å— åˆ¶å®šè§„èŒƒå®šä¹‰ æ•°æ®åŸŸ ä¿®é¥°ç±»å‹ - ä¿®é¥°è¯ - æ´¾ç”ŸæŒ‡æ ‡ ä¸šåŠ¡è¿‡ç¨‹ - åŸå­æŒ‡æ ‡/åº¦é‡ ç»´åº¦ - ç»´åº¦å±æ€§ æ¨¡å‹è®¾è®¡ æ±‡æ€»äº‹å®è¡¨ æ˜ç»†ç»´åº¦äº‹å®è¡¨ ç»´åº¦è¡¨ " }, { "title": "è§£å†³æ–‡ä»¶å·²è¢«macOSä½¿ç”¨æ— æ³•æ‰“å¼€", "url": "/posts/mac-openfile/", "categories": "Mac, tip", "tags": "", "date": "2018-10-11 13:40:00 +0800", "snippet": "åœ¨macç³»ç»Ÿä½¿ç”¨è¿‡ç¨‹ä¸­æœ‰æ—¶ä¼šé‡åˆ°æƒ³æ‰“å¼€çš„æ–‡ä»¶æ— æ³•æ‰“å¼€çš„æƒ…å†µï¼Œè¿™æ—¶å€™ç³»ç»Ÿä¼šæç¤º å·²è¢«macOSä½¿ç”¨,ä¸èƒ½æ‰“å¼€æŒ‰å¦‚ä¸‹æ–¹å¼æ“ä½œå³å¯è§£å†³ é€‰ä¸­æƒ³è¦æ‰“å¼€çš„æ–‡ä»¶ï¼ŒæŒ‰ä¸€ä¸‹copyå¿«æ·é”® Command + c æ‰“å¼€åº”ç”¨ç¨‹åºç»ˆç«¯ æœ‰äº›ç³»ç»Ÿç‰ˆæœ¬åç§°ä¸º terminal è¾“å…¥ xattr -d com.apple.FinderInfo ï¼Œæ³¨æ„æœ€åæœ‰ä¸€ä¸ªç©ºæ ¼ ä¿æŒè¾“å…¥ç„¦ç‚¹åœ¨ç»ˆç«¯çª—å£ä¸­ï¼ŒæŒ‰ä¸‹ç²˜è´´å¿«æ·é”® Command + vï¼Œè¿™é‡Œåˆšåˆšå¤åˆ¶çš„æ–‡ä»¶è·¯å¾„ä¼šç²˜è´´åˆ°çª—å£ä¸­ æŒ‰ä¸‹ Enter æ‰§è¡Œè¾“å…¥çš„å‘½ä»¤è¿™æ ·å†å»æ‰“å¼€åˆšåˆšçš„æ–‡ä»¶ï¼Œå°±èƒ½æˆåŠŸæ‰“å¼€äº†" }, { "title": "Kafka å‘½ä»¤å®æˆ˜2", "url": "/posts/kafka-command/", "categories": "Big data, Kafka", "tags": "command", "date": "2018-06-22 01:29:00 +0800", "snippet": "Kafka è¿­ä»£å¾ˆå¿«ï¼Œæ–°ç‰ˆæœ¬åˆæœ‰ä¸å°‘å˜åŒ–ï¼ŒåŒäº‹å‘Šè¯‰æˆ‘å‡çº§å¥½äº†æ–°é›†ç¾¤ï¼Œé©¬ä¸Šæ¥ç»ƒç»ƒæµ‹è¯•ç¯å¢ƒzookeeper:æœåŠ¡å™¨åç§° mt-zookeeper-vip:218110.77.32.90 mt-zookeeper-410.77.32.91 mt-zookeeper-510.77.32.92 mt-zookeeper-610.77.32.2 mt-zookeeper-vipbroker-server10.7.31.15:2181,10.7.31.16:2181,10.7.31.17:218110.7.31.15:9092,10.7.31.16:9092,10.7.31.17:9092ç”Ÿäº§ç¯å¢ƒzookeeperæœåŠ¡å™¨åç§° mt-zookeeper-vip:2181broker-server10.33.36.101:9092,10.33.36.113:9092,10.33.40.117:9092PLAINTEXT://10.33.36.101:9092,PLAINTEXT://10.33.36.113:9092,PLAINTEXT://10.33.40.117:9092å¸¸ç”¨å‘½ä»¤cd kafka/# æ˜¾ç¤º topic åˆ—è¡¨bin/kafka-topics.sh --list \\ --zookeeper mt-zookeeper-vip:2181# åˆ›å»ºä¸€ä¸ª topicbin/kafka-topics.sh --create \\ --zookeeper mt-zookeeper-vip:2181 \\ --replication-factor 3 \\ --partitions 1 \\ --topic __connect-offsets# åˆ é™¤ä¸€ä¸ª topicbin/kafka-topics.sh --delete \\ --zookeeper mt-zookeeper-vip:2181 \\ --topic __connect-offsets# æ¶ˆè´¹ kafka æ¶ˆæ¯ï¼Œå¦‚æœåŠ ä¸Š --from-beginning å‚æ•°åˆ™ä»æœ€æ—©æ¶ˆæ¯å¼€å§‹æ¶ˆè´¹ï¼Œ# å¦åˆ™ç”±kafkaè®°å½•ä¸Šæ¬¡ä½ç½®åå¼€å§‹bin/kafka-console-consumer.sh \\ --zookeeper mt-zookeeper-vip:2181 \\ --topic bigDatamarket [--from-beginning]# ä»¥äº¤äº’æ–¹å¼å‘é€ä¸€æ¡ kafka æ¶ˆæ¯bin/kafka-console-producer.sh \\ --broker-list [broker server] \\ --topic [topic name]# æŸ¥çœ‹æŸ topic å½“å‰ offset å€¼bin/kafka-run-class.sh kafka.tools.GetOffsetShell \\ --broker-list [broker server] \\ --topic lbs_testè®¾ç½®offset# ...zookeeper.connect=mt-zookeeper-vip:2181group.id=dmp_stream# ...å‘½ä»¤è¡Œæ‰§è¡Œå¦‚ä¸‹bin/kafka-run-class.sh \\ kafka.tools.UpdateOffsetsInZK \\ latest \\ consumer.properties \\ dmp_task_resultapache canal æ¨é€çš„mysqlè®°å½•æ›´æ–°æ¶ˆæ¯ç»“æ„{ &quot;dmlType&quot;:&quot;update&quot;, &quot;pkMap&quot;:{ &quot;partyManageId&quot;:&quot;20765&quot; }, &quot;normalMap&quot;:{ &quot;goodsSourceCount&quot;:&quot;1612&quot;, &quot;stampDate&quot;:&quot;2017-07-27 10:11:29&quot;, &quot;updateDate&quot;:&quot;2017-07-27 10:11:29&quot;, &quot;goldDriverStatus&quot;:&quot;å·²å¼€é€š&quot; }}" }, { "title": "Apache DRUID éƒ¨ç½²åŠä½¿ç”¨", "url": "/posts/druid-started/", "categories": "Big data, Druid", "tags": "", "date": "2017-11-06 20:55:00 +0800", "snippet": "åˆå§‹è®¾ç½®ä¿®æ”¹æ—¶åŒºdruid/conf/druid/broker/jvm.config é‡Œçš„ UTC ä¿®æ”¹ä¸º Asia/ShanghaiHDFSæ•°æ®åŠ è½½æ”¯æŒä¿®æ”¹ druid/conf/druid/_common/common.runtime.properties , ç¡®ä¿ druid.extensions.loadList ä¸­æœ‰ druid-hdfs-storageï¼Œåœ¨ druid/conf/druid/_common/ ç›®å½•ä¸­æ·»åŠ ä»¥ä¸‹hadoopé…ç½®æ–‡ä»¶ çš„è½¯é“¾æ¥ core-site.xml, hdfs-site.xml, yarn-site.xml, mapred-site.xmlå¯åŠ¨åˆ†å¸ƒå¼æœåŠ¡æµ‹è¯•ç¯å¢ƒç¤ºä¾‹DRUID éƒ¨ç½²åœ¨åŒä¸€æœåŠ¡å™¨ jt-host-kvm-53# å¯åŠ¨ historicalnohup java `cat conf-quickstart/druid/historical/jvm.config | xargs` \\ -cp &quot;conf-quickstart/druid/_common:conf-quickstart/druid/historical:lib/*&quot; \\ io.druid.cli.Main server historical &amp;gt; log/historical.log 2&amp;gt;&amp;amp;1 &amp;amp;# å¯åŠ¨ brokernohup java `cat conf-quickstart/druid/broker/jvm.config | xargs` \\ -cp &quot;conf-quickstart/druid/_common:conf-quickstart/druid/broker:lib/*&quot; \\ io.druid.cli.Main server broker &amp;gt; log/broker.log 2&amp;gt;&amp;amp;1 &amp;amp;# å¯åŠ¨ coordinatornohup java `cat conf-quickstart/druid/coordinator/jvm.config | xargs` \\ -cp &quot;conf-quickstart/druid/_common:conf-quickstart/druid/coordinator:lib/*&quot; \\ io.druid.cli.Main server coordinator &amp;gt; log/coordinator.log 2&amp;gt;&amp;amp;1 &amp;amp;# å¯åŠ¨ overlordnohup java `cat conf-quickstart/druid/overlord/jvm.config | xargs` \\ -cp &quot;conf-quickstart/druid/_common:conf-quickstart/druid/overlord:lib/*&quot; \\ io.druid.cli.Main server overlord &amp;gt; log/overlord.log 2&amp;gt;&amp;amp;1 &amp;amp;# å¯åŠ¨ middleManagernohup java `cat conf-quickstart/druid/middleManager/jvm.config | xargs` \\ -cp &quot;conf-quickstart/druid/_common:conf-quickstart/druid/middleManager:lib/*&quot; \\ io.druid.cli.Main server middleManager &amp;gt; log/middleManager.log 2&amp;gt;&amp;amp;1 &amp;amp;é›†ç¾¤éƒ¨ç½²ç¤ºä¾‹å‚ç…§æµ‹è¯•ç¯å¢ƒå‘½ä»¤ï¼Œå°†è¿›ç¨‹éƒ¨ç½²åˆ°ä¸åŒæœåŠ¡å™¨ï¼Œæœ¬ä¾‹èµ„æºå—é™æ ¹æ®æœåŠ¡è´Ÿè½½è¿›è¡Œäº†éƒ¨åˆ†éš”ç¦» hosts role port big-elephant-1 kafka Â  big-elephant-4 broker,overlord Â  big-elephant-5 historical,coordinator,middleManager Â  å¯åŠ¨å®æ—¶æ•°æ®æ¶ˆè´¹è¿›ç¨‹nohup bin/tranquility kafka -configFile conf/yugong-status.json &amp;amp;æŸ¥çœ‹æ¶ˆè´¹è¿›ç¨‹ Logtail -f http://big-elephant-8:8090/druid/indexer/v1/task/[taskid]/logæ‰©å±•å·¥å…·Druid Dumbohttps://github.com/liquidm/druid-dumbo åœ¨HDFSä¸­éªŒè¯å®æ—¶ç”Ÿæˆçš„åŸå§‹æ•°æ®ã€‚ é‡å»ºä¸HDFSä¸­åŸå§‹æ•°æ®ä¸ä¸€è‡´çš„ç»†åˆ†ã€‚ å°†ç°æœ‰çš„æ®µæŠ˜å æˆæ›´é«˜çš„ç²’åº¦æ®µã€‚ç¤ºä¾‹é…ç½®æ–‡ä»¶è¿™ä¸ªç¤ºä¾‹ä»kafkaæ¶ˆæ¯ç³»ç»Ÿä¸­æ¶ˆè´¹æ¶ˆæ¯ï¼Œå°†æ¶ˆæ¯ä¸­çš„å€¼ä»¥åˆ†é’Ÿä¸ºæ—¶é—´çª—å£å•ä½ï¼Œmetric_codeå­—æ®µä¸ºç»´åº¦ï¼Œmetric_valueä¸ºåº¦é‡å­—æ®µè¿›è¡Œå€¼ç»Ÿè®¡ï¼Œç»Ÿè®¡åŒ…æ‹¬æœ€å¤§ã€æœ€å°ã€åˆè®¡ã€æ€»è®°å½•æ•°ï¼Œç›¸å½“äºå¢å¼ºç‰ˆæœ¬ WordCount ç¨‹åºã€‚{ &quot;dataSources&quot;: [{ &quot;spec&quot;: { &quot;dataSchema&quot;: { &quot;dataSource&quot;: &quot;metric_append&quot;, &quot;parser&quot;: { &quot;type&quot;: &quot;string&quot;, &quot;parseSpec&quot;: { &quot;timestampSpec&quot;: { &quot;format&quot;: &quot;yyyy-MM-dd HH:mm:ss.SSS&quot;, &quot;column&quot;: &quot;timestamp&quot; }, &quot;dimensionsSpec&quot;: { &quot;dimensions&quot;: [&quot;metric_code&quot;] }, &quot;columns&quot;: [&quot;metric_code&quot;, &quot;metric_value&quot;, &quot;timestamp&quot;] } }, &quot;granularitySpec&quot;: { &quot;type&quot;: &quot;uniform&quot;, &quot;queryGranularity&quot;: &quot;minute&quot; }, &quot;metricsSpec&quot;: [{ &quot;type&quot;: &quot;count&quot;, &quot;name&quot;: &quot;count&quot; }, { &quot;type&quot;: &quot;doubleSum&quot;, &quot;name&quot;: &quot;metric_sum&quot;, &quot;fieldName&quot;: &quot;metric_value&quot; }, { &quot;type&quot;: &quot;doubleMin&quot;, &quot;name&quot;: &quot;metric_min&quot;, &quot;fieldName&quot;: &quot;metric_value&quot; }, { &quot;type&quot;: &quot;doubleMax&quot;, &quot;name&quot;: &quot;metric_max&quot;, &quot;fieldName&quot;: &quot;metric_value&quot; }] }, &quot;tuningConfig&quot;: { &quot;maxRowsInMemory&quot;: &quot;10000&quot;, &quot;type&quot;: &quot;realtime&quot;, &quot;windowPeriod&quot;: &quot;PT30M&quot;, &quot;intermediatePersistPeriod&quot;: &quot;PT30M&quot; } }, &quot;properties&quot;: { &quot;topicPattern.priority&quot;: &quot;1&quot;, &quot;topicPattern&quot;: &quot;YugongMetricAppend&quot; } }, { &quot;spec&quot;: { &quot;dataSchema&quot;: { &quot;dataSource&quot;: &quot;metric_complete&quot;, &quot;parser&quot;: { &quot;type&quot;: &quot;string&quot;, &quot;parseSpec&quot;: { &quot;timestampSpec&quot;: { &quot;format&quot;: &quot;yyyy-MM-dd HH:mm:ss.SSS&quot;, &quot;column&quot;: &quot;timestamp&quot; }, &quot;dimensionsSpec&quot;: { &quot;dimensions&quot;: [&quot;metric_code&quot;] }, &quot;columns&quot;: [&quot;metric_code&quot;, &quot;metric_value&quot;, &quot;timestamp&quot;] } }, &quot;granularitySpec&quot;: { &quot;type&quot;: &quot;uniform&quot;, &quot;queryGranularity&quot;: &quot;minute&quot; }, &quot;metricsSpec&quot;: [{ &quot;type&quot;: &quot;count&quot;, &quot;name&quot;: &quot;count&quot; }, { &quot;type&quot;: &quot;doubleSum&quot;, &quot;name&quot;: &quot;metric_sum&quot;, &quot;fieldName&quot;: &quot;metric_value&quot; }, { &quot;type&quot;: &quot;doubleMin&quot;, &quot;name&quot;: &quot;metric_min&quot;, &quot;fieldName&quot;: &quot;metric_value&quot; }, { &quot;type&quot;: &quot;doubleMax&quot;, &quot;name&quot;: &quot;metric_max&quot;, &quot;fieldName&quot;: &quot;metric_value&quot; }] }, &quot;tuningConfig&quot;: { &quot;maxRowsInMemory&quot;: &quot;10000&quot;, &quot;type&quot;: &quot;realtime&quot;, &quot;windowPeriod&quot;: &quot;PT30M&quot;, &quot;intermediatePersistPeriod&quot;: &quot;PT30M&quot; } }, &quot;properties&quot;: { &quot;topicPattern.priority&quot;: &quot;1&quot;, &quot;topicPattern&quot;: &quot;YugongMetricComplete&quot; } }, { &quot;spec&quot;: { &quot;dataSchema&quot;: { &quot;dataSource&quot;: &quot;yugong_writers&quot;, &quot;parser&quot;: { &quot;type&quot;: &quot;string&quot;, &quot;parseSpec&quot;: { &quot;format&quot;: &quot;json&quot;, &quot;timestampSpec&quot;: { &quot;format&quot;: &quot;yyyy-MM-dd HH:mm:ss.SSS&quot;, &quot;column&quot;: &quot;createtime&quot; }, &quot;dimensionsSpec&quot;: { &quot;dimensions&quot;: [&quot;metricCode&quot;, &quot;metricDate&quot;] } } }, &quot;granularitySpec&quot;: { &quot;type&quot;: &quot;uniform&quot;, &quot;queryGranularity&quot;: &quot;minute&quot; }, &quot;metricsSpec&quot;: [{ &quot;type&quot;: &quot;count&quot;, &quot;name&quot;: &quot;count&quot; }] }, &quot;tuningConfig&quot;: { &quot;maxRowsInMemory&quot;: &quot;10000&quot;, &quot;type&quot;: &quot;realtime&quot;, &quot;windowPeriod&quot;: &quot;PT30M&quot;, &quot;intermediatePersistPeriod&quot;: &quot;PT30M&quot; } }, &quot;properties&quot;: { &quot;topicPattern.priority&quot;: &quot;1&quot;, &quot;topicPattern&quot;: &quot;YugongWrite*&quot; } }], &quot;properties&quot;: { &quot;zookeeper.connect&quot;: &quot;10.33.35.192:2181,10.33.35.194:2181,10.33.35.196:2181&quot;, &quot;zookeeper.timeout&quot;: &quot;PT20S&quot;, &quot;druid.selectors.indexing.serviceName&quot;: &quot;druid/overlord&quot;, &quot;druid.discovery.curator.path&quot;: &quot;/druid/discovery&quot;, &quot;kafka.zookeeper.connect&quot;: &quot;10.33.35.192:2181,10.33.35.194:2181,10.33.35.196:2181&quot;, &quot;kafka.group.id&quot;: &quot;tranquility-k&quot;, &quot;consumer.numThreads&quot;: &quot;5&quot;, &quot;commit.periodMillis&quot;: &quot;15000&quot;, &quot;reportDropsAsExceptions&quot;: &quot;false&quot; }}ä»¥SQLæ–¹å¼è®¿é—®DURIDæ•°æ®é¦–å…ˆä¸‹è½½æ‰€éœ€åŒ…è¿›è¡ŒéªŒè¯æµ‹è¯•java -cp lib/calcite-core-1.2.0-incubating.jar:lib/avatica-1.8.0.jar:lib/calcite-linq4j-1.2.0-incubating.jar:lib/mysql-connector-java-5.1.25.jar:lib/sqlline-1.4.0-SNAPSHOT-jar-with-dependencies.jar sqlline.SqlLineè¿æ¥druidjava -cp lib/jackson-annotations-2.8.0.jar:lib/jackson-core-2.8.1.jar:lib/jackson-databind-2.8.1.jar:lib/guava-11.0.2.jar:lib/calcite-core-1.2.0-incubating.jar:lib/calcite-linq4j-1.2.0-incubating.jar:lib/calcite-avatica-1.2.0-incubating.jar:lib/calcite-druid-1.13.0.jar:lib/sqlline-1.4.0-SNAPSHOT-jar-with-dependencies.jar sqlline.SqlLineæˆ–è€…java -cp lib/avatica-1.10.0.jar:lib/calcite-core-1.13.0.jar:lib/calcite-druid-1.13.0.jar:lib/calcite-linq4j-1.13.0.jar:lib/commons-compiler-2.7.6.jar:lib/commons-lang3-3.2.jar:lib/guava-18.0.jar:lib/jackson-annotations-2.8.0.jar:lib/jackson-core-2.8.1.jar:lib/jackson-databind-2.8.1.jar:lib/janino-2.7.6.jar:lib/joda-time-2.8.1.jar:lib/sqlline-1.4.0-SNAPSHOT-jar-with-dependencies.jar sqlline.SqlLineç„¶å!connect jdbc:calcite:schemaFactory=org.apache.calcite.adapter.druid.DruidSchemaFactory;schema.url=http://big-elephant-4:8082;schema.coordinatorUrl=http://big-elephant-5:8081;caseSensitive=mysql admin adminæ‰§è¡ŒSQLæŸ¥è¯¢select sum(count) as v from metric_append where __time &amp;gt; TIMESTAMP &#39;2017-08-10 00:00:00&#39; and metric_code=&#39;lj.publishcargo.any.amount&#39; group by metric_codeselect metric_sum from metric_complete where __time &amp;gt; TIMESTAMP &#39;2017-08-10 00:00:00&#39; and metric_code=&#39;lj.publishcargo.any.amount&#39; order by __time desc limit 1" }, { "title": "YARN ç”Ÿäº§é›†ç¾¤åŠå…¬ç¯å¢ƒæ— æ³•è®¿é—®", "url": "/posts/yarn-rest-api/", "categories": "Big data, Yarn", "tags": "security", "date": "2017-08-30 19:40:00 +0800", "snippet": "å…¬å¸å‡ºäºå®‰å…¨è€ƒè™‘ï¼Œé™†ç»­åœ¨åŠå…¬ç½‘ç»œç¦ç”¨å¯¹ç”Ÿäº§ç³»ç»Ÿçš„ç›´æ¥è®¿é—®ï¼Œå¯¹ç”Ÿäº§ç³»ç»Ÿæ‰€æœ‰æ“ä½œå¿…é¡»å…ˆç™»å½•è·³æ¿æœºï¼Œå†é€šè¿‡è·³æ¿æœºå¯¹ç”Ÿäº§ç³»ç»Ÿè®¿é—®ã€‚åŸæ¥ç›´æ¥è®¿é—®Yarn Web UIæ¥è·Ÿè¸ªä»»åŠ¡æ‰§è¡Œæƒ…å†µçš„æ–¹å¼å·²ç»æ— ç”¨äº†ã€‚å¹¸å¥½Yarnæä¾›äº†åŸºäºHTTP Apiçš„æ–¹å¼è®¿é—®ï¼Œä¸‹é¢å¼€å§‹æèµ·â€¦ æ ¹æ®å®˜ç½‘æ–‡æ¡£è¦æ±‚ç¼–å†™jsonæ ¼å¼å†…å®¹å­˜å‚¨åˆ°jsonæ–‡ä»¶ï¼Œè¿™é‡Œåä¸º yarn-rest-request.json å°†è¯¥æ–‡ä»¶ä¿å­˜åˆ°è·³æ¿æœº scp yarn-rest-request.json admin@[server_host]:~/ åœ¨è·³æ¿æœºä¸Šæ‰§è¡Œå¦‚ä¸‹å‘½ä»¤ï¼Œè¿™é‡Œçš„åŸŸååŠç«¯å£ä¿®æ”¹ä¸ºå®é™…åŸŸåå’Œç«¯å£ curl -L -H&#39;Content-Type: application/json&#39; \\ -XPOST \\ --data-binary @yarn-rest-request.json \\ http://big-elephant-3:8088/ws/v1/cluster/apps ç„¶åå°±å¯ä»¥çœ‹åˆ°æœåŠ¡å™¨è¿”å›çš„ä¿¡æ¯äº†ï¼Œå¦‚æœ‰å¿…è¦å¯ä»¥å°†è¿”å›ç»“æœä¿å­˜åˆ°æ–‡ä»¶ä¾¿äºåç»­ä½¿ç”¨ã€‚ å¦‚æœè·³æ¿æœºæ— æ³•ä¿å­˜æ–‡ä»¶æ‰§è¡Œå‘½ä»¤ç­‰æ“ä½œï¼Œä½¿ç”¨iTerm2è½¯ä»¶é…ç½®å¥½éš§é“ç©¿é€å³å¯ä¸Šä¼ yarn-rest-request.jsonæ–‡ä»¶åˆ°ç”Ÿäº§æœåŠ¡å™¨ï¼Œåé¢æŒ‰ç…§ç¬¬3æ­¥å¼€å§‹æ‰§è¡Œå³å¯" }, { "title": "YARN Web UI ä¸èƒ½æŸ¥çœ‹", "url": "/posts/yarn-unauthorized/", "categories": "Big data, Yarn", "tags": "", "date": "2017-08-30 19:40:00 +0800", "snippet": "è®¿é—®YARN Web UIåœ°å€æ—¶ï¼Œé¡µé¢å‡ºç°å¦‚ä¸‹æç¤ºï¼šYou (User dr.who) are not authorized to view application application_xxxxç»å¤šæ¬¡ç¿»æ—¥å¿—ï¼Œç¿»æ–‡æ¡£åï¼Œå¾—çŸ¥éœ€è¦å…³æ³¨å¦‚ä¸‹é…ç½®é¡¹ï¼Œä¸å®é™…ç¯å¢ƒæ˜¯å¦ç›¸ç¬¦ã€‚Hadoopè¿ç»´è¿‡ç¨‹ä¸­ä¸ç»æ„é—´çš„é…ç½®ä¿®æ”¹å°±å¯èƒ½å¼•å‘ç§ç§é—®é¢˜ã€‚&amp;lt;property&amp;gt;Â Â  &amp;lt;name&amp;gt;hadoop.http.staticuser.user&amp;lt;/name&amp;gt;Â Â  &amp;lt;value&amp;gt;hadoop&amp;lt;/value&amp;gt;Â Â &amp;lt;/property&amp;gt;Â " }, { "title": "HBase å‘½ä»¤å®æˆ˜", "url": "/posts/hbase-command/", "categories": "Big data, HBase", "tags": "command", "date": "2017-07-10 09:40:00 +0800", "snippet": "è¿ç»´å‘Šè¯‰æˆ‘ï¼ŒHBaseé›†ç¾¤å·²ç»æ­å»ºå¥½äº†ï¼Œç°åœ¨æ¥å®æˆ˜ä¸€æŠŠnamespace åä¸º hbase çš„ namespaceï¼šç³»ç»Ÿå†…å»ºè¡¨ï¼ŒåŒ…æ‹¬ namespace å’Œ meta è¡¨ åä¸º default çš„ namespaceï¼šç”¨æˆ·å»ºè¡¨æ—¶æœªæŒ‡å®š namespace çš„è¡¨éƒ½åˆ›å»ºåœ¨æ­¤-- åˆ›å»ºnamespacecreate_namespaceÂ &#39;ai_ns&#39;-- åˆ é™¤namespacedrop_namespaceÂ &#39;ai_ns&#39;-- æŸ¥çœ‹namespacedescribe_namespaceÂ &#39;ai_ns&#39;-- åˆ—å‡ºæ‰€æœ‰namespacelist_namespace-- åœ¨namespaceä¸‹åˆ›å»ºè¡¨createÂ &#39;ai_ns:testtable&#39;,Â &#39;fm1&#39;-- æŸ¥çœ‹namespaceä¸‹çš„è¡¨list_namespace_tablesÂ &#39;ai_ns&#39;DDL-- æŸ¥çœ‹æœ‰å“ªäº›è¡¨list-- åˆ›å»ºè¡¨create &#39;YG_ODS:PARTY&#39;,{NAME =&amp;gt; &#39;0&#39;, VERSIONS =&amp;gt; 1},{NAME =&amp;gt; &#39;1&#39;, VERSIONS =&amp;gt; 2}-- åˆ é™¤è¡¨disable &#39;t1&#39;drop &#39;t1&#39;-- æŸ¥çœ‹è¡¨ç»“æ„describe &#39;t1&#39;-- ä¿®æ”¹è¡¨ç»“æ„ï¼ˆä¿®æ”¹è¡¨ç»“æ„å¿…é¡»å…ˆdisableï¼‰disable &#39;test1&#39;alter &#39;test1&#39;,{NAME=&amp;gt;&#39;body&#39;,TTL=&amp;gt;&#39;15552000&#39;},{NAME=&amp;gt;&#39;meta&#39;, TTL=&amp;gt;&#39;15552000&#39;}enableÂ &#39;test1&#39;privileges-- è¯­æ³• : grant &amp;lt;user&amp;gt; &amp;lt;permissions&amp;gt; &amp;lt;table&amp;gt; &amp;lt;column family&amp;gt; &amp;lt;column qualifier&amp;gt; å‚æ•°åé¢ç”¨é€—å·åˆ†éš”-- æƒé™ç”¨äº”ä¸ªå­—æ¯è¡¨ç¤ºï¼š &quot;RWXCA&quot;.-- READ(&#39;R&#39;), WRITE(&#39;W&#39;), EXEC(&#39;X&#39;), CREATE(&#39;C&#39;), ADMIN(&#39;A&#39;)-- ä¾‹å¦‚ï¼Œç»™ç”¨æˆ·â€˜test&#39;åˆ†é…å¯¹è¡¨t1æœ‰è¯»å†™çš„æƒé™ï¼Œgrant &#39;test&#39;,&#39;RW&#39;,&#39;t1&#39;-- æŸ¥çœ‹æƒé™-- è¯­æ³•ï¼šuser_permission &amp;lt;table&amp;gt;-- ä¾‹å¦‚ï¼ŒæŸ¥çœ‹è¡¨t1çš„æƒé™åˆ—è¡¨user_permission &#39;t1&#39;-- æ”¶å›æƒé™-- ä¸åˆ†é…æƒé™ç±»ä¼¼ï¼Œè¯­æ³•ï¼šrevoke &amp;lt;user&amp;gt; &amp;lt;table&amp;gt; &amp;lt;column family&amp;gt; &amp;lt;column qualifier&amp;gt;-- ä¾‹å¦‚ï¼Œæ”¶å›testç”¨æˆ·åœ¨è¡¨t1ä¸Šçš„æƒé™revoke &#39;test&#39;,&#39;t1&#39;DML-- æ·»åŠ æ•°æ®-- è¯­æ³•ï¼šput &amp;lt;table&amp;gt;,&amp;lt;rowkey&amp;gt;,&amp;lt;family:column&amp;gt;,&amp;lt;value&amp;gt;,&amp;lt;timestamp&amp;gt;-- ä¾‹å¦‚ï¼šç»™è¡¨t1çš„æ·»åŠ ä¸€è¡Œè®°å½•ï¼šrowkeyæ˜¯rowkey001ï¼Œfamily nameï¼šf1ï¼Œcolumn nameï¼šcol1ï¼Œvalueï¼švalue01ï¼Œtimestampï¼šç³»ç»Ÿé»˜è®¤put &#39;t1&#39;,&#39;rowkey001&#39;,&#39;f1:col1&#39;,&#39;value01&#39;-- æŸ¥è¯¢æŸè¡Œè®°å½•-- è¯­æ³•ï¼šget &amp;lt;table&amp;gt;,&amp;lt;rowkey&amp;gt;,[&amp;lt;family:column&amp;gt;,....]-- ä¾‹å¦‚ï¼šæŸ¥è¯¢è¡¨t1ï¼Œrowkey001ä¸­çš„f1ä¸‹çš„col1çš„å€¼get &#39;t1&#39;,&#39;rowkey001&#39;, &#39;f1:col1&#39;-- æˆ–è€…ï¼šget &#39;t1&#39;,&#39;rowkey001&#39;, {COLUMN=&amp;gt;&#39;f1:col1&#39;}-- æŸ¥è¯¢è¡¨t1ï¼Œrowke002ä¸­çš„f1ä¸‹çš„æ‰€æœ‰åˆ—å€¼get &#39;t1&#39;,&#39;rowkey001&#39;æ‰«æè¡¨-- è¯­æ³•ï¼šscan &amp;lt;table&amp;gt;, {COLUMNS =&amp;gt; [ &amp;lt;family:column&amp;gt;,.... ], LIMIT =&amp;gt; num}-- å¦å¤–ï¼Œè¿˜å¯ä»¥æ·»åŠ STARTROWã€TIMERANGEå’ŒFITLERç­‰é«˜çº§åŠŸèƒ½-- ä¾‹å¦‚ï¼šæ‰«æè¡¨t1çš„å‰5æ¡æ•°æ®scan &#39;t1&#39;,{LIMIT=&amp;gt;5}-- æŸ¥è¯¢è¡¨ä¸­çš„æ•°æ®è¡Œæ•°-- è¯­æ³•ï¼šcount &amp;lt;table&amp;gt;, {INTERVAL =&amp;gt; intervalNum, CACHE =&amp;gt; cacheNum}-- INTERVALè®¾ç½®å¤šå°‘è¡Œæ˜¾ç¤ºä¸€æ¬¡åŠå¯¹åº”çš„rowkeyï¼Œé»˜è®¤1000ï¼›CACHEæ¯æ¬¡å»å–çš„ç¼“å­˜åŒºå¤§å°ï¼Œé»˜è®¤æ˜¯10ï¼Œè°ƒæ•´è¯¥å‚æ•°å¯æé«˜æŸ¥è¯¢é€Ÿåº¦-- ä¾‹å¦‚ï¼ŒæŸ¥è¯¢è¡¨t1ä¸­çš„è¡Œæ•°ï¼Œæ¯100æ¡æ˜¾ç¤ºä¸€æ¬¡ï¼Œç¼“å­˜åŒºä¸º500count &#39;t1&#39;, {INTERVAL =&amp;gt; 10000, CACHE =&amp;gt; 50000}-- åˆ é™¤è¡Œä¸­çš„æŸä¸ªåˆ—å€¼-- è¯­æ³•ï¼šdelete &amp;lt;table&amp;gt;, &amp;lt;rowkey&amp;gt;,Â  &amp;lt;family:column&amp;gt; , &amp;lt;timestamp&amp;gt;,å¿…é¡»æŒ‡å®šåˆ—å-- ä¾‹å¦‚ï¼šåˆ é™¤è¡¨t1ï¼Œrowkey001ä¸­çš„f1:col1çš„æ•°æ®delete &#39;t1&#39;,&#39;rowkey001&#39;,&#39;f1:col1&#39;-- åˆ é™¤è¡Œ-- è¯­æ³•ï¼šdeleteall &amp;lt;table&amp;gt;, &amp;lt;rowkey&amp;gt;,Â  &amp;lt;family:column&amp;gt; , &amp;lt;timestamp&amp;gt;ï¼Œå¯ä»¥ä¸æŒ‡å®šåˆ—åï¼Œåˆ é™¤æ•´è¡Œæ•°æ®-- ä¾‹å¦‚ï¼šåˆ é™¤è¡¨t1ï¼Œrowk001çš„æ•°æ®deleteall &#39;t1&#39;,&#39;rowkey001&#39;-- åˆ é™¤è¡¨ä¸­çš„æ‰€æœ‰æ•°æ®-- è¯­æ³•ï¼š truncate &amp;lt;table&amp;gt;-- å…¶å…·ä½“è¿‡ç¨‹æ˜¯ï¼šdisable table -&amp;gt; drop table -&amp;gt; create table-- ä¾‹å¦‚ï¼šåˆ é™¤è¡¨t1çš„æ‰€æœ‰æ•°æ®truncate &#39;t1&#39;-- æŸ¥è¯¢æŒ‡å®šrowKeyå’ŒæŒ‡å®šåˆ—æ•°æ®get &#39;mofang:metric_today&#39;, &quot;\\x03\\xBC\\xD5\\x9E03dd85fb223cb2cbc203e518059aa558&quot;, { COLUMNS =&amp;gt; [ &#39;base&#39;, &#39;minutes&#39; ], FILTER =&amp;gt; &quot;ColumnRangeFilter(&#39;1111&#39;,true,&#39;1115&#39;,true)&quot;, LIMIT=&amp;gt;20 }-- è¿‡æ»¤å™¨ä½¿ç”¨scan &#39;mofang:metric_today&#39;, { COLUMNS =&amp;gt; [ &#39;base&#39;, &#39;minutes&#39; ], FILTER =&amp;gt; &quot;ColumnRangeFilter(&#39;1111&#39;,true,&#39;1115&#39;,true)&quot;, LIMIT=&amp;gt;20 }Sqoopå¯¼å…¥æ•°æ®åˆ°HBasesqoop import \\ --connect &#39;jdbc:mysql://10.7.13.48:8066/trade?tinyInt1isBit=false&amp;amp;useCompression=true&amp;amp;tcpRcvBuf=1024000000&amp;amp;useCursorFetch=true&amp;amp;defaultFetchSize=1000&#39; \\ --table Party \\ --hbase-create-table \\ --hbase-table ODS_PARTY:PARTY \\ --column-family 1 \\ --hbase-row-key partyId \\ --split-by stampDate \\ --username &#39;admin&#39; \\ --password ****** \\ -m 5sqoop import \\ --connect &#39;jdbc:mysql://10.33.60.38:3306/dataMarket?tinyInt1isBit=false&amp;amp;useCompression=true&amp;amp;tcpRcvBuf=1024000000&amp;amp;useCursorFetch=true&amp;amp;defaultFetchSize=1000&#39; \\ --table Person \\ --hbase-create-table \\ --hbase-table ODS_PARTY:PERSON \\ --column-family 1 \\ --hbase-row-key partyId \\ --split-by stampDate \\ --username &#39;dataMarket&#39; \\ --password ****** \\ -m 5æ‰§è¡Œå®ŒæˆåæŸ¥çœ‹è¡¨ç»“æ„root|-- partyId: integer (nullable = false)|-- partyType: string (nullable = true)|-- partyName: string (nullable = true)|-- mobileNumber: string (nullable = true)|-- mobileNumberIsActive: string (nullable = true)|-- email: string (nullable = true)|-- emailIsActive: string (nullable = true)|-- tradeType: string (nullable = true)|-- oldPartyId: integer (nullable = true)|-- starLevel: string (nullable = true)|-- inputDate: timestamp (nullable = true)|-- createDate: timestamp (nullable = true)|-- status: string (nullable = true)|-- stampDate: timestamp (nullable = false)" }, { "title": "Spark ç¨‹åºä¼˜åŒ–ä¸€ä¾‹", "url": "/posts/spark-sql-performance/", "categories": "Big data, Spark", "tags": "performance", "date": "2017-07-10 09:40:00 +0800", "snippet": "Spark SQL å¾ˆğŸ”¥ï¼Œå®˜æ–¹å®£ç§°å¼€å‘æ•ˆç‡å¤§å¹…æé«˜ï¼Œå¹¶ä¸”ç¨‹åºé€»è¾‘æ›´å®¹æ˜“ç†è§£ï¼Œç„¶è€Œå®é™…ä½¿ç”¨èµ·æ¥å´ä¹Ÿæœ‰è¿è¡Œæ•ˆç‡ä½ä¸‹ï¼Œä¼˜åŒ–æ‰‹æ®µåŒ®ä¹ç­‰ç¼ºç‚¹ã€‚ä¼ ç»Ÿæ•°æ®åº“é‡‡ç”¨SQLï¼Œæé«˜æŸ¥è¯¢é€Ÿåº¦å¾ˆå¤§ç¨‹åº¦ä¸Šä¾èµ–äºç´¢å¼•æ‰‹æ®µè¿›è¡ŒSQLä¼˜åŒ–ï¼Œè€ŒSpark SQLä¸­çš„è¡¨æ— æ³•ä½¿ç”¨ç´¢å¼•æŠ€æœ¯ã€‚Spark åº”ç”¨åŸºäºå†…å­˜è®¡ç®—ï¼Œå¯¹äºèšåˆç±»å‹è®¡ç®— shuffle è¿‡ç¨‹éš¾ä»¥é¿å…ï¼Œæ­¤æ—¶æ•°æ®ä¼ è¾“é€Ÿåº¦ä¸‹é™å‡ ä¸ªæ•°é‡çº§ã€‚åº”ç€é‡å‡å°‘ shuffle æ¬¡æ•°ä»¥åŠ shuffle æ•°æ®é‡ã€‚æ”¯æ’‘å…¬å¸å½“å‰ä¸šåŠ¡çš„ Spark ç¨‹åºè®¡ç®—é€Ÿåº¦ä¸è¾¾é¢„æœŸï¼Œå› æ­¤ç€æ‰‹è¿›è¡Œä¼˜åŒ–ã€‚ä¼˜åŒ–ç›®æ ‡ç¨³å®šæ€§ï¼Œèƒ½åŠ›ï¼Œé€Ÿåº¦ï¼Œèµ„æºå ç”¨ä¼˜åŒ–ç»“æœæ¯5åˆ†é’Ÿæ—¶é—´çª—å£æ•°æ®è®¡ç®—æ—¶é—´ç”± &amp;gt;90s ä¸‹é™è‡³ &amp;lt;30så®é™…ä¼˜åŒ–ç­–ç•¥ åˆ é™¤æ•°æ®ç±»ï¼Œå‡å°‘ shuffle è¿‡ç¨‹ä¸­åºåˆ—åŒ–ååºåˆ—åŒ–è€—æ—¶ï¼ŒåŒæ—¶å‡å°‘å†…å­˜å ç”¨ï¼Œåˆ é™¤BigScreenIndex case class transformation é˜¶æ®µå³è¿‡æ»¤æ‰ä¸å‚ä¸è®¡ç®—çš„æ•°æ®ï¼Œå³ä¼˜å…ˆè¿‡æ»¤æ•°æ®ã€‚ä¾‹ï¼šè¿‡æ»¤ dmlType = delete æˆ– dmlType = remove çš„æ•°æ® å‡å°‘è®¡ç®—æ¬¡æ•°ï¼Œé‡ç”¨è®¡ç®—ä¸­é—´ç»“æœã€‚ä¾‹ï¼šä¸šåŠ¡sql ä¸ topicå¯¹åº”å…³ç³»åªéœ€è¦è®¡ç®—ä¸€æ¬¡ å°½é‡å‡å°‘spark sqlçš„ä½¿ç”¨ï¼Œå› ä¸º spark sql ä¸ºåŠ¨æ€ç¼–è¯‘åŠ è½½æŠ€æœ¯ï¼Œè¿è¡Œä¸Šéœ€è¦èµ°åˆ†æå™¨ã€ä¼˜åŒ–å™¨ã€è½¬æ¢ä¸ºåŸç”ŸAPIé‚£å¥—é€»è¾‘ï¼Œæœ€åå®ç°è¿˜æ˜¯åŸºäºRDDæ•°æ®ç»“æ„ï¼Œåšä¸º7x24å°æ—¶è¿è¡Œçš„åº”ç”¨æ¥è¯´ï¼ŒèŠ‚çœçš„é‚£ç‚¹å¼€å‘æ—¶é—´å¾®ä¸è¶³é“ï¼Œç¤ºä¾‹ï¼šç”±äºSQLè¯­æ³•é™åˆ¶ï¼ŒåŸæœ‰ç¨‹åºé€»è¾‘ä½¿ç”¨äº†5æ¡SQLæ‰å®ç°ä¸šåŠ¡éœ€æ±‚ï¼Œæ”¹ä¸º streaming å¤„ç†ä»£ç åï¼Œä»…1æ¬¡æ•°æ®è½¬æ¢å°±å¾—åˆ°æ‰€å±æ•°æ®ç»“æ„è¯¦ç»†ä¸šåŠ¡é€»è¾‘åŠä¼˜åŒ–è¿‡ç¨‹ ä¸šåŠ¡æ•°æ®è®¡ç®— å¢é‡æ•°æ® topic list: select distinct topic from event_table å¢é‡æ•°æ®åˆå¹¶ SELECT title, type, smalltype, sum(valuelong) as valuelong FROM ( SELECT title, type, smalltype, valuelong FROM old_table UNION ALL SELECT title, type, smalltype, valuelong from increment_table ) t GROUP BY title, type, smalltype æŒ‡æ ‡æ¯”ç‡è®¡ç®— SELECT t1.title, t1.type, t1.smalltype, t1.valuelong, round((t1.valuelong / t2.valuelong) * 100) as valuedouble from merged_table t1 LEFT JOIN ( select t.type, nvl(t.smalltype,&#39;&#39;) as smalltype, sum(valuelong) as valuelong from merged_table t where t.type is not null group by t.type, t.smalltype ) t2 on t1.type = t2.type and nvl(t1.smalltype,&#39;&#39;) = t2.smalltype æ–°å¢åŠå˜æ›´è®°å½•åŒºåˆ† select o.bigscreendataid, n.title, n.type, n.smalltype, n.valuelong, n.valuedouble, if(o.bigscreendataid is null, &#39;append&#39;, if(n.valuelong!=o.valuelong, &#39;changed&#39;, if(nvl(n.valuedouble, 0) != nvl(o.valuedouble,0), &#39;changed&#39;, &#39;none&#39;) ) ) as status from new_table n left join jdbc_table o on nvl(n.title,&#39;&#39;) = nvl(o.title,&#39;&#39;) and nvl(n.type, &#39;&#39;) = nvl(o.type, &#39;&#39;) and nvl(n.smalltype, &#39;&#39;) = nvl(o.smalltype, &#39;&#39;) ä¼˜åŒ–åçš„ä»£ç  public class BigScreenData() { public BigScreenData() {}} å¿ƒå¾— åœ¨ä¸€æ¬¡mapé˜¶æ®µå³è½¬æ¢å¥½æ‰€éœ€è¦çš„å­—æ®µæ•°æ®ï¼Œä»¥ä¾¿é‡ç”¨ï¼Œè€Œä¸æ˜¯åœ¨ç”¨åˆ°çš„æ—¶å€™å†è®¡ç®—ï¼Œé€ æˆå¤šæ¬¡è®¡ç®—, ä¾‹å¦‚id, timestamp, åœ¨è½¬æ¢å‡ºnew RDD[Row]æ—¶å°±è®¡ç®—å¥½äº†ï¼Œåœ¨loadHDFS, å’ŒloadDBä¸­ç›´æ¥ä½¿ç”¨ï¼Œè€Œéåœ¨loadDBä¸­å†è®¡ç®—ä¸€æ¬¡ å®ç°æ•ˆæœç›¸åŒå‰æä¸‹ï¼Œé€‰æ‹©æ›´ä¼˜ç®—æ³• å…³æ³¨spark ui, å¯¹è¿è¡Œå‚æ•°è°ƒæ•´, driver, executor, memory, cores, receiver.maxRate" }, { "title": "Apache Sqoop å‘½ä»¤å®æˆ˜", "url": "/posts/sqoop-command/", "categories": "Big data, Sqoop", "tags": "command", "date": "2016-08-13 11:29:00 +0800", "snippet": "æœ€è¿‘ sqoop ç”¨å¾—æ¯”è¾ƒå¤šï¼Œåœ¨æ­¤æŠŠç”¨åˆ°çš„å‘½ä»¤è®°å½•ä¸€ä¸‹å®˜æ–¹æ–‡æ¡£åœ°å€ 1.4.6ï¼šhttp://sqoop.apache.org/docs/1.4.6/SqoopUserGuide.htmlåˆ›å»º Sqoop ä»»åŠ¡sqoop job --create append-import-goods_source_search -- \\ --options-file sqoop-conf/import-hdfs.conf \\ --append \\ --table GoodsSourceSearch \\ --target-dir /user/hive/warehouse/mirror.db/goods_source_search/ \\ --check-column inputDate \\ --incremental append \\ --password ******åˆ›å»º Sqoop å…¨é‡ä»»åŠ¡ï¼Œæ‰§è¡Œæ—¶è¦†ç›–å·²æœ‰æ•°æ®sqoop job --create import-auth_user -- \\ --options-file sqoop-conf/import-hive.conf \\ --table AuthUser \\ --hive-table auth_user \\ --password ******Sqoop å¢é‡å¯¼å…¥sqoop job --create append-import-call_record -- \\ --options-file sqoop-conf/import-hdfs.conf \\ --append \\ --table CallRecord \\ --target-dir /user/hive/warehouse/mirror.db/call_record/ \\ --check-column inputDate \\ --incremental append \\ --password ******å¯¼å…¥æ–‡ä»¶æ ¼å¼sqoopçš„hiveå¯¼å…¥ä½å±‚æ–‡ä»¶ç±»å‹åªæ”¯æŒtextfileæ ¼å¼ï¼Œhdfså¯¼å…¥åˆ™æ”¯æŒtextfileã€sequencefileã€avrofileä¸‰ç§æ ¼å¼ï¼Œå› æ­¤å¦‚æœå¸Œæœ›å¯¼å…¥æ•°æ®åˆ°hiveè¡¨æœ€ç®€å•çš„æ˜¯é€‰æ‹©textfileæ ¼å¼ï¼Œå¦‚æœå¯¹hiveè¡¨æ•°æ®å¤„ç†æ€§èƒ½æœ‰è¦æ±‚éœ€è¦è‡³å°‘ä¸¤æ­¥æ“ä½œï¼Œå¦‚æœhiveè¡¨é€‰æ‹©sequencefileæˆ–avrofileæ ¼å¼ï¼Œå¯ä»¥å‚æ•°æŒ‡å®šå¯¹åº”ç±»å‹åä½¿ç”¨hdfså¯¼å…¥ï¼Œç„¶åhiveè¡¨åˆ·æ–°å…ƒæ•°æ®ä½¿å…¶åŠ è½½æ–°å¯¼å…¥æ–‡ä»¶ï¼Œå¦‚æœä½¿ç”¨rcfile/orcfileæ ¼å¼ï¼Œå¯textfileæ ¼å¼å¯¼å…¥è¡¨åç”¨HIVEè¯­å¥â€insert into table testtable select * from textfile_tableâ€å¯¼å…¥ æˆ–è€…å¼€å‘Sqoopæ‰©å±•å®Œæˆå¯¹æ ¼å¼æ”¯æŒ ä½¿ç”¨avrofileç­‰æ ¼å¼æ—¶ï¼Œå…¶æ•°æ®è¡¨ç»“æ„ä¿¡æ¯æ˜¯å­˜å‚¨åœ¨è¯¥Hiveå…ƒæ•°æ®è¡¨å­—æ®µä¸­çš„ï¼ŒMySQLçš„varchar2ç±»å‹å­—æ®µæœ‰æœ€å¤§é•¿åº¦ï¼Œå½“æ•°æ®è¡¨çš„å­—æ®µå¤šäº†ä»¥åæ•´ä¸ªæ•°æ®è¡¨ç»“æ„æè¿°ä¿¡æ¯çš„å­—ç¬¦ä¸²é•¿åº¦å°†è¶…å‡ºMySQL varchar2ç±»å‹å­—æ®µæœ€å¤§é•¿åº¦ï¼Œè€Œä¸”ç”±äºMySQLä¸­è¡Œè®°å½•æ•°æ®é•¿åº¦ä¹Ÿå­˜åœ¨é™åˆ¶ï¼Œå®é™…æ•°æ®è¡¨ç»“æ„æè¿°å¯ç”¨é•¿åº¦è¿œè¿œä¸åˆ°varchar2æœ€å¤§é•¿åº¦ä¸Šé™ï¼Œå­—æ®µå¤šçš„æ•°æ®è¡¨å°†åœ¨å»ºè¡¨æ—¶å› ç»“æ„æè¿°ä¿¡æ¯è¢«æˆªæ–­æ— æ³•æ­£å¸¸è§£æï¼Œå®è·µä¸­æ­¤é—®é¢˜å¤šå‘äºSqoopè‡ªåŠ¨å¯¼å…¥å»ºè¡¨è¿‡ç¨‹ä¸­ã€‚åˆ†æä»¥ä¸Šä¸¤ç§æ–¹æ¡ˆï¼Œå…¶ä¸­sequencefileå’Œavrofileæ ¼å¼ioç­‰èµ„æºæ¶ˆè€—è¾ƒå°‘ï¼Œåªéœ€è¦å†™ä¸€æ¬¡hdfsç„¶ååŠ è½½æ•°æ®å³å¯ï¼Œrcfile,orcfileç›¸æ¯”è¾ƒè€Œè¨€å¤šä¸€æ¬¡æ ¼å¼è½¬æ¢å’Œå†™æ–‡ä»¶æ“ä½œï¼Œå¦‚æœè¡¨éœ€è¦å¤šæ¬¡æŸ¥è¯¢ä½¿ç”¨åˆ™ç‰ºç‰²å¯¼å…¥æ—¶é—´æ¢å–åç»­è¡¨æ•°æ®ä½¿ç”¨æ—¶çš„é«˜æ•ˆ åŒæ•°æ®é‡æ–‡ä»¶å¤§å°æ’åºï¼šsequencefile &amp;gt; textfile &amp;gt; avrofile &amp;gt; rcfile åŒæ•°æ®é‡æŸ¥è¯¢è´Ÿè½½æ’åºï¼štextfile &amp;gt; sequencefile &amp;gt; avrofile &amp;gt; rcfileåˆ›å»ºsqoopJobè¿½åŠ æ•°æ®åˆ°HDFS,åŒæ—¶å¯¹å·²æœ‰æ•°æ®åšæ›´æ–°:sqoop job --create increment-import-repport-goods_source --meta-connect jdbc:hsqldb:hsql://big-bigworker-6.100.idc.tf56:16000/sqoop -- --options-file sqoop-conf/import-hdfs.conf --table GoodsSource --target-dir /user/hive/warehouse/increment.db/report_goods_source/ --merge-key goodsSourceId --check-column updateDate --incremental lastmodified --password ******åˆ›å»ºsqoopJobåªæ˜¯è¿½åŠ æ•°æ®åˆ°HDFS,ä¸å¯¹ä¼šå·²æœ‰æ•°æ®åšæ›´æ–°sqoop job --create append-import-party_log -- --options-file sqoop-conf/import-hdfs.conf --append --table PartyLog --target-dir /user/hive/warehouse/mirror.db/party_log/ --check-column inputDate --incremental append --password ******sqoop job --list --meta-connect jdbc:hsqldb:hsql://big-bigworker-6.100.idc.tf56:16000/sqoop sqoop job --create increment-export-report-log_yunbao_lujing_app_dau -- --options-file sqoop-conf/export.conf --table QLujingAppDriverAndShipperDau --update-key inputDate --update-mode allowinsert --export-dir /hive/warehouse/increment.db/report_lujing_app_dau sqoop job --create merge-import-repport-red_packet_detail --meta-connect jdbc:hsqldb:hsql://big-bigworker-6.100.idc.tf56:16000/sqoop -- --options-file sqoop-conf/import-hdfs.conf --table DimParty --target-dir /user/hive/warehouse/report.db/red_packet_detail/ --merge-key redPacketDetailId --check-column updateDate --incremental lastmodified --password ******" }, { "title": "Apache Flume Configuration", "url": "/posts/flume-configuration/", "categories": "Big data, Flume", "tags": "", "date": "2016-08-13 01:29:00 +0800", "snippet": "Flume æ˜¯å¤§æ•°æ® Hadoop ç”Ÿæ€çš„æ—¥å¿—é›†æˆç»„ä»¶ï¼Œé€šè¿‡å®ƒå¯ä»¥å°†å…¶å®ƒæœåŠ¡å™¨ä¸Šçš„æ—¥å¿—æ–‡ä»¶é›†æˆåˆ° Hadoop HDFSã€HIVEã€ESç­‰ï¼ŒFlumeåŒ…å«ä¸‰å¤§ç»„ä»¶ï¼Œsourceã€ channelã€sinksourcessources è´Ÿè´£æ•°æ®çš„é‡‡é›†éƒ¨åˆ†ï¼Œåœ¨é…ç½®æ–‡ä»¶ä¸­ä»¥ â€œsource.â€ å¼€å¤´çš„å³æ˜¯ç›¸å…³é…ç½®ï¼Œé€šå¸¸å¯ä»¥é…ç½®å®ƒçš„ç±»å‹ï¼Œé‡‡é›†åé€å¾€å“ªäº› channels ï¼Œé«˜é˜¶ç‚¹çš„å¯ä»¥é…ç½® n ä¸ªæ‹¦æˆªå™¨ï¼Œå¯¹é‡‡é›†åˆ°çš„æ•°æ®è¿›è¡Œè¿‡æ»¤è½¬æ¢ç­‰ï¼Œå®˜æ–¹æä¾›äº†å¸¸è§çš„è¿‡æ»¤å™¨å®ç°ï¼Œç›´æ¥é…ç½®ç›¸å…³å‚æ•°å³å¯ï¼Œå¦‚æ— æ³•æ»¡è¶³éœ€æ±‚å¯ä»¥è‡ªå·±ç¼–å†™è¿‡æ»¤å™¨å®ç°æ›´çµæ´»åŠŸèƒ½ã€‚channelschannels é¡¾åæ€ä¹‰æ˜¯æ•°æ®é€šé“ï¼Œé‡‡é›†åˆ°çš„æ•°æ®ç”±æ­¤å‘é€åˆ°ä¸åŒæ¶ˆè´¹ç«¯ï¼Œå»ºè®®é‡‡ç”¨ memory ç±»å‹ï¼Œå…¶å®ç±»å‹å‡ä¼šä¸åŒç¨‹åº¦é™ä½åé‡ã€‚sinkssinks å°±æ˜¯æ¶ˆè´¹ç«¯ï¼Œæ¶ˆè´¹é‡‡é›†åˆ°çš„æ•°æ®ï¼Œé€šå¸¸æƒ…å†µå­˜åˆ° HDFSï¼Œé€šè¿‡å¯¹ç›®å½•åŠæ–‡ä»¶åœ°å€çš„è®¾è®¡å¯ä»¥ç›´æ¥å­˜ä¸ºHIVEç›®å½•ä¸‹çš„HDFSæ–‡ä»¶ï¼Œæ¯”èµ· type=hive çš„ sink æ›´å¿«ï¼Œä½†è¦æ³¨æ„ä½¿ç”¨å‰å¯¹HIVEå…ƒæ•°æ®è¡¨è¿›è¡Œåˆ·æ–°åŠ è½½è¿™äº›æ–‡ä»¶æ•°æ®ã€‚featuresFlumeé›†ç¾¤æ”¶é›†çš„æ—¥å¿—å‘é€åˆ°hdfsä¸Šå»ºç«‹æ–‡ä»¶å¤¹çš„æ—¶é—´ä¾æ®æ˜¯æ ¹æ® event æ—¶é—´ï¼Œæ—¢æ—¥å¿—ä¼ å…¥FlumeæœåŠ¡å™¨çš„æ—¶é—´ï¼Œæºä»£ç å®ç°ä¸Šæ˜¯ Clock.unixTime()ï¼Œæ‰€ä»¥å¦‚æœæƒ³è¦æ ¹æ®æ—¥å¿—è‡ªèº«ç”Ÿæˆçš„æ—¶é—´æ¥å»ºç«‹æ–‡ä»¶å¤¹çš„è¯ï¼Œéœ€è¦å¯¹ com.cloudera.flume.core.EventImpl ç±»çš„æ„é€ å‡½æ•°public EventImpl(byte[] s, long timestamp, Priority pri, long nanoTime, String host, Map&amp;lt;String, byte[]&amp;gt; fields)é‡å†™ï¼Œè§£ææ–¹æ³•å‚æ•° byte[] s çš„å†…å®¹å–å‡ºæ—¶é—´ï¼Œèµ‹å€¼ç»™ timestampï¼Œè¿™æ ·åœ¨ Flume sink é…ç½®æ–‡ä»¶ä¸­ timestamp æ‰å¯ä»¥ä½œä¸ºä¸€ä¸ªå­—æ®µè¢«è¯†åˆ«å’Œå¤„ç†ï¼Œç”±æ­¤è§£å†³æ ¹æ®æ—¥å¿—ç”Ÿæˆæ—¶é—´å­˜å‚¨ç­‰ç›¸å…³é—®é¢˜ã€‚ flumeçš„æ¡†æ¶ä¼šæ„é€  byte[] s é•¿åº¦ä¸º 0 çš„æ•°ç»„ï¼Œç”¨æ¥å‘é€ç±»ä¼¼ç®€å•éªŒè¯çš„ eventï¼Œæ‰€ä»¥åœ¨æŠ½å–æ—¥å¿—ç”Ÿæˆæ—¶é—´æ—¶éœ€è¦æ³¨æ„ s é•¿åº¦ä¸º 0 çš„é—®é¢˜ã€‚HDFS Sink é…ç½®å®ä¾‹############################################# producer config#############################################agent sectionproducer.sources = sproducer.channels = c c1 c2producer.sinks = r h es#source sectionproducer.sources.s.type =execproducer.sources.s.command = tail -f /usr/local/nginx/logs/test1.log#producer.sources.s.type = spooldir#producer.sources.s.spoolDir = /usr/local/nginx/logs/#producer.sources.s.fileHeader = trueproducer.sources.s.channels = c c1 c2producer.sources.s.interceptors = i#ä¸æ”¯æŒå¿½ç•¥å¤§å°å†™producer.sources.s.interceptors.i.regex = .*\\.(css|js|jpg|jpeg|png|gif|ico).*producer.sources.s.interceptors.i.type = org.apache.flume.interceptor.RegexFilteringInterceptor$Builder#ä¸åŒ…å«producer.sources.s.interceptors.i.excludeEvents = true############################################# hdfs config############################################producer.channels.c.type = memory#Timeout in seconds for adding or removing an eventproducer.channels.c.keep-alive= 30producer.channels.c.capacity = 10000producer.channels.c.transactionCapacity = 10000producer.channels.c.byteCapacityBufferPercentage = 20producer.channels.c.byteCapacity = 800000producer.sinks.r.channel = cproducer.sinks.r.type = avroproducer.sinks.r.hostname = 127.0.0.1producer.sinks.r.port = 10101############################################# hdfs config############################################producer.channels.c1.type = memory#Timeout in seconds for adding or removing an eventproducer.channels.c1.keep-alive= 30producer.channels.c1.capacity = 10000producer.channels.c1.transactionCapacity = 10000producer.channels.c1.byteCapacityBufferPercentage = 20producer.channels.c1.byteCapacity = 800000producer.sinks.h.channel = c1producer.sinks.h.type = hdfs#ç›®å½•ä½ç½®producer.sinks.h.hdfs.path = hdfs://127.0.0.1/tmp/flume/%Y/%m/%d#æ–‡ä»¶å‰ç¼€producer.sinks.h.hdfs.filePrefix=nginx-%Y-%m-%d-%Hproducer.sinks.h.hdfs.fileType = DataStream#æ—¶é—´ç±»å‹å¿…åŠ ï¼Œä¸ç„¶ä¼šæŠ¥é”™producer.sinks.h.hdfs.useLocalTimeStamp = trueproducer.sinks.h.hdfs.writeFormat = Text#hdfsåˆ›å»ºå¤šé•¿æ—¶é—´æ–°å»ºæ–‡ä»¶ï¼Œ0ä¸åŸºäºæ—¶é—´#Number of seconds to wait before rolling current file (0 = never roll based on time interval)producer.sinks.h.hdfs.rollInterval=0#hdfså¤šå¤§æ—¶æ–°å»ºæ–‡ä»¶ï¼Œ0ä¸åŸºäºæ–‡ä»¶å¤§å°#File size to trigger roll, in bytes (0: never roll based on file size)producer.sinks.h.hdfs.rollSize = 0#hdfsæœ‰å¤šå°‘æ¡æ¶ˆæ¯æ—¶æ–°å»ºæ–‡ä»¶ï¼Œ0ä¸åŸºäºæ¶ˆæ¯ä¸ªæ•°#Number of events written to file before it rolled (0 = never roll based on number of events)producer.sinks.h.hdfs.rollCount = 0#æ‰¹é‡å†™å…¥hdfsçš„ä¸ªæ•°#number of events written to file before it is flushed to HDFSproducer.sinks.h.hdfs.batchSize=1000#flumeæ“ä½œhdfsçš„çº¿ç¨‹æ•°ï¼ˆåŒ…æ‹¬æ–°å»ºï¼Œå†™å…¥ç­‰ï¼‰#Number of threads per HDFS sink for HDFS IO ops (open, write, etc.)producer.sinks.h.hdfs.threadsPoolSize=15#æ“ä½œhdfsè¶…æ—¶æ—¶é—´#Number of milliseconds allowed for HDFS operations, such as open, write, flush, close. This number should be increased if many HDFS timeout operations are occurring.producer.sinks.h.hdfs.callTimeout=30000ä¹±å…¥å‡ ä¸ª Hadoop HDFS ç›¸å…³é…ç½®åœ¨ Flume å‘ HDFS ç³»ç»ŸæŒç»­å†™å…¥æ•°æ®æ—¶ï¼ŒHDFSçš„ä¸€äº›é…ç½®ä¼šå½±å“å®é™…çš„ç›®å½•åŠæ–‡ä»¶ç”Ÿæˆï¼Œéœ€è¦åŠ å…¥æ³¨æ„hdfs.round=false#Should the timestamp be rounded down (if true, affects all time based escape sequences except %t)hdfs.roundValue=#Rounded down to the highest multiple of this (in the unit configured using hdfs.roundUnit), less than current time.hdfs.roundUnit=&#39;second&#39;#The unit of the round down value - second, minute or hour.ES Sink é…ç½®å®ä¾‹############################################# elasticsearch config############################################producer.channels.c2.type = memory#Timeout in seconds for adding or removing an eventproducer.channels.c2.keep-alive= 30producer.channels.c2.capacity = 10000producer.channels.c2.transactionCapacity = 10000producer.channels.c2.byteCapacityBufferPercentage = 20producer.channels.c2.byteCapacity = 800000producer.sinks.es.channel = c2producer.sinks.es.type = org.apache.flume.sink.elasticsearch.ElasticSearchSinkproducer.sinks.es.hostNames = 127.0.0.1:9300#Name of the ElasticSearch cluster to connect toproducer.sinks.es.clusterName = sunxucool#Number of events to be written per txn.producer.sinks.es.batchSize = 1000#The name of the index which the date will be appended to. Example â€˜flumeâ€™ -&amp;gt; â€˜flume-yyyy-MM-ddâ€™producer.sinks.es.indexName = flume_es#The type to index the document to, defaults to â€˜logâ€™producer.sinks.es.indexType = testproducer.sinks.es.serializer = org.apache.flume.sink.elasticsearch.ElasticSearchLogStashEventSerializer" }, { "title": "ElasticSearch å‘½ä»¤å®æˆ˜", "url": "/posts/es-command/", "categories": "Big data, ElasticSearch", "tags": "command", "date": "2016-08-13 01:29:00 +0800", "snippet": "è®°å½•ä¸€ä¸‹ elasticsearch é«˜é¢‘å‘½ä»¤æ·»åŠ åˆ é™¤æ¨¡ç‰ˆcurl -XDELETE &#39;http://[server_host]:9200/goods-source-log&#39;curl -XPUT &#39;http://[server_host]:9200/_template/goods-source-log&#39; -d &#39;@goods-source-log-v1.json&#39;åˆ é™¤ç´¢å¼•ä¼šå°†æ•´ä¸ªç´¢å¼•åŒ…æ‹¬æ•°æ®å…¨éƒ¨åˆ é™¤curl -XDELETE &#39;http://[server_host]:9200/goods-source-log&#39;æŸ¥æ‰¾æ•°æ®curl -XPOST &#39;http://[server_host]:9200/goods-source-log/_search?q=*&amp;amp;pretty&#39;" }, { "title": "Hive å‘½ä»¤å®æˆ˜", "url": "/posts/hive-command/", "categories": "Big data, Hive", "tags": "command", "date": "2016-07-28 11:29:00 +0800", "snippet": "å»ºè¡¨è¯­å¥-- åˆ›å»ºè¡¨create table test(id int, name string);-- åˆ›å»ºå¤–éƒ¨è¡¨create external table test(id int, name string) location `/user/yundao/test_table`-- æŒ‡å®šè¡Œåˆ†éš” row format delimited-- æŒ‡å®šåˆ—åˆ†éš” fields terminated by &#39;\\t&#39;-- æŒ‡å®šåˆ†åŒº partitioned by (pt string)-- æŒ‡å®šå­˜å‚¨æ ¼å¼ï¼Œå¯é€‰æ ¼å¼æœ‰-- textfile æ–‡æœ¬æ ¼å¼, é»˜è®¤å€¼-- sequencefile Hadoop API æä¾›çš„ä¸€ç§äºŒè¿›åˆ¶æ–‡ä»¶ï¼Œå®ƒå°†æ•°æ®ä»¥&amp;lt;key,value&amp;gt;çš„å½¢å¼åºåˆ—åŒ–åˆ°æ–‡ä»¶ä¸­ï¼Œç›¸æ¯”textfileç©ºé—´å ç”¨å°-- rcfile ä¸€ç§åˆ—å­˜çš„æ•°æ®æ ¼å¼ï¼Œåœ¨æ±‡æ€»è®¡ç®—æ—¶æœ‰æ€§èƒ½åŠ æˆï¼Œç›¸æ¯”textfileç©ºé—´å ç”¨å°-- orcfile rcfileçš„å‡çº§ç‰ˆæœ¬ stored as textfile;-- æŒ‡å®šå†…å®¹æ ¼å¼ROW FORMAT SERDE &#39;org.openx.data.jsonserde.JsonSerDe&#39;å®Œæ•´ç‰ˆä¾‹å­create external table logs_user_event( `type` int, `time` timestamp, code int, address string, phonemode string, os string, serialnumber string, uuid string, mac string, version string, sourcecode string, ip string, partyid bigint) row format serde &quot;org.openx.data.jsonserde.JsonSerDe&quot; with serdeproperties ( &quot;ignore.malformed.json&quot; = &quot;true&quot;, &quot;dots.in.keys&quot; = &quot;true&quot;)location &quot;/logs/user_event&quot;ä¿®æ”¹è¡¨çš„SerDeå±æ€§ALTER TABLE lujing_adapp_burry_point_delay SET SERDEPROPERTIES ( &quot;ignore.malformed.json&quot; = &quot;true&quot;);æ˜¾ç¤ºè¡¨ç»“æ„-- æ˜¾ç¤ºæ•°æ®åº“å·²æœ‰è¡¨show share.tables; -- æ˜¾ç¤ºè¡¨æè¿°desc tb_test;desc extended tb_test;desc formatted tb_test; -- ä¿®æ”¹å­—æ®µalter table tb_test change id id2 int comment &quot;æ³¨é‡Š&quot;;-- ä¿®æ”¹è¡¨æ³¨é‡Šalter table tb_test set TBLPROPERTIES(&#39;comment&#39;=&#39;æ¯å¤©å„çº¿è·¯æ‰¾è´§ä¼šå‘˜è¡¨&#39;);åŠ è½½æ•°æ®-- åŠ è½½æœ¬åœ°æ–‡ä»¶æ•°æ®, è¦†ç›–æ¨¡å¼ï¼Œå£°æ˜æ ¼å¼ä¸å®é™…æ ¼å¼ä¸åŒçš„æ•°æ®åŠ è½½åæ— æ³•æ­£ç¡®è¯»å–ï¼Œä¾‹å¦‚æ•°æ®æ ¼å¼ä¸ºtextæ ¼å¼ï¼Œ-- è¡¨æ ¼å¼ä¸ºsequencefile,rcfile,avrofileç­‰ï¼Œç›®å‰sqoopå¯¼å…¥åˆ°hiveåªæ”¯æŒtextfileæ ¼å¼ï¼Œ-- å¯¼å…¥åˆ°hdfsæ”¯æŒtextfile,sequencefile,avrofileä¸‰ç§æ ¼å¼*load data local inpath &#39;/home/yundao/test_data.txt&#39; overwrite into table test;-- åŠ è½½æœ¬åœ°æ–‡ä»¶æ•°æ®, è¿½åŠ æ¨¡å¼load data local inpath &#39;/home/yundao/test_data.txt&#39; into table test;-- åŠ è½½HDFSæ•°æ®, è¦†ç›–æ¨¡å¼load data inpath &#39;/user/yundao/test_data&#39; overwrite into table test;-- åŠ è½½HDFSæ•°æ®, è¿½åŠ æ¨¡å¼load data inpath &#39;/user/yundao/test_data&#39; into table test;-- ä»æŸ¥è¯¢æ’å…¥æ•°æ®, è¦†ç›–æ¨¡å¼insert overwrite table test_target select * from test_source;-- ä»æŸ¥è¯¢æ’å…¥æ•°æ®, è¿½åŠ æ¨¡å¼insert into table test_target select * from test_source;-- åŠ è½½æ•°æ®åˆ°åˆ†åŒºï¼ŒæœŸä¸­test_sourceè¡¨å¿…é¡»æœ‰ä¸test_targetåˆ†åŒºåŒååˆ—insert into table test_target PARTITION (pt=&#39;[åˆ†åŒºå]&#39;) select * from test_source;-- å½“test_sourceè¡¨æ²¡æœ‰åä¸ºptçš„åˆ—æ—¶insert into table test_target PARTITION (pt=&#39;[åˆ†åŒºå]&#39;) select *, &#39;2016-07-28&#39; as pt from test_source;-- å°†æŸ¥è¯¢ç»“æœæ’å…¥å¤šä¸ªè¡¨æˆ–HDFSç›®å½•from test_insert1insert overwrite local directory &#39;/home/yundao/hive&#39; select * insert overwrite directory &#39;/user/yundao/export_test&#39; select value;å¯¼å‡ºæ•°æ®-- å¯¼å‡ºåˆ°æœ¬åœ°ç›®å½•insert overwrite local directory &#39;party_route&#39; row format delimited fields terminated by &#39;\\t&#39; select * from party_route order by to_party_id, take_month desc, total_value desc;å¯¼å‡ºåˆ°hdfsç›®å½•åªéœ€è¦å»æ‰ç¬¬ä¸€è¡Œä¸­çš„â€™localâ€™å…³é”®å­—è¡¨åˆ†åŒº(PARTITION)-- åˆ›å»ºåˆ†åŒºè¡¨create table test1(dummy int) partitioned by(pt string); -- åˆ›å»ºå¤šåˆ†åŒºè¡¨create table test1(dummy int) partitioned by(ptm string, ptd string); -- åˆ›å»ºé™æ€åˆ†åŒºalter table test1 add partition (pt=&quot;201507&quot;);alter table test1 add partition (ptm=&quot;201507&quot;, ptd=&quot;01&quot;); -- åˆ›å»ºåŠ¨æ€åˆ†åŒº-- ä»å·²æœ‰çš„æ•°æ®åŠ è½½å¹¶è‡ªåŠ¨åˆ›å»ºåˆ†åŒºset hive.exec.dynamic.partition=true;set hive.exec.dynamic.partition.mode=nonstrict; insert overwrite table test1 partition(pt) select *,substr(create_date,1,6) as pt from source_table; -- åˆ—å‡ºè¡¨åˆ†åŒºshow partitions test1; -- åˆ é™¤è¡¨åˆ†åŒºalter table test1 drop partition(pt=&quot;201507&quot;);-- å‡½æ•°&amp;amp;UDF/UDAF/UDTF-- ä¸´æ—¶å‡½æ•°add jar hive-udf.jar;create temporary function tf as &#39;com.tf56.yundao.udf.PartySpeedUDF&#39;;-- åˆ é™¤ä¸´æ—¶å‡½æ•°drop temporary function tf;delete jar hive-udf.jar; -- åˆ—å‡ºå·²æ·»åŠ çš„jarlist jar; -- æ°¸ä¹…å‡½æ•°(é€‚ç”¨æ•°æ®åº“èŒƒå›´å†…ä½¿ç”¨)use share;create function share.row_num as &#39;com.tf56.yundao.udf.RowNumberUDF&#39; using jar &#39;hdfs://ns1/user/yundao/udf.jar&#39;; -- æ˜¾ç¤ºå‡½æ•°åˆ—è¡¨show functions; -- æ˜¾ç¤ºå‡½æ•°æè¿°desc function to_date;desc function extended to_date;æŸ¥è¯¢æ’åºä¸‰ä¸ªå…³é”®å­—è¯´æ˜å¦‚ä¸‹ distribute byï¼šæ§åˆ¶ç€åœ¨mapé˜¶æ®µå¦‚ä½•åˆ†åŒºï¼ŒæŒ‰ç…§ä»€ä¹ˆå­—æ®µè¿›è¡Œåˆ†åŒºï¼Œé‡ç‚¹è€ƒè™‘å‡è¡¡è´Ÿè½½é¿å…å€¾æ–œ sort byï¼šæ¯ä¸ªreduceæŒ‰ç…§sort by å­—æ®µè¿›è¡Œæ’åºï¼Œreduceçš„æ•°é‡æŒ‰ç…§é»˜è®¤çš„æ•°é‡æ¥è¿›è¡Œï¼Œå½“ç„¶å¯ä»¥æŒ‡å®šã€‚æœ€ç»ˆå¯ä»¥è¿›è¡Œå½’å¹¶æ’åºå¾—å‡ºç»“æœã€‚é€‚ç”¨äºæ•°æ®é‡æ¯”è¾ƒå¤§çš„æ’åºåœºæ™¯ã€‚ order byï¼šreduceåªæœ‰ä¸€ä¸ªï¼Œåœ¨ä¸€ä¸ªreduceä¸­å®Œæˆæ’åºï¼Œä½¿ç”¨äºæ•°æ®é‡å°çš„åœºæ™¯æˆ–è€…å¯¹æœ€åç»“æœæ’åºã€‚mapjoinåº”ç”¨åœºæ™¯ï¼š1.å…³è”æ“ä½œä¸­æœ‰ä¸€å¼ è¡¨éå¸¸å° 2.ä¸ç­‰å€¼çš„é“¾æ¥æ“ä½œselect /*+ mapjoin(A)*/ f.a,f.b from A t join B f on ( f.a=t.a and f.ftime=20110802)ç‰¹æ®Šæ•°æ®ç»“æ„Arrayã€Mapã€Structå¤åˆæ•°æ®ç»“æ„çš„å¸¸ç”¨å‡½æ•°-- array_contains - æ•°ç»„ä¸­æ˜¯å¦åŒ…å«æŒ‡å®šå€¼select * from rc_coupon where array_contains([1,2,3,4], type);-- explode - å±•å¼€æ•°ç»„ä¸ºè¡Œselect explode(split(&#39;hello world&#39;, &#39; &#39;)); -- posexplode - å±•å¼€æ•°ç»„ä¸ºè¡Œ, å¹¶æ·»åŠ åºå·åˆ—select posexplode(split(&#39;hello world&#39;, &#39; &#39;));viewâ€¦å¸¸ç”¨å†…ç½®å‡½æ•°å­—ç¬¦ä¸²æ“ä½œ-- lpad - å·¦å¡«å……è¡¥é½é•¿åº¦select lpad(&#39;hi&#39;, 3, &#39;?&#39;) from dual; -- rpad - å³å¡«å……è¡¥é½é•¿åº¦select rpad(&#39;hi&#39;, 3 , &#39;.&#39;) from dual; -- sentences - åˆ†è¯,å°†å­—ç¬¦ä¸²åˆ†è¯ä¸ºæ•°ç»„åˆ—è¡¨select sentences(&quot;hello world&quot;) from dual;select sentences(&quot;hello,world&quot;) from dual; -- str_to_map - å­—ç¬¦ä¸²è½¬mapï¼Œdelimiter1 - mapå…ƒç´ åˆ†éš”ç¬¦ï¼Œdelimiter2 - mapé”®å€¼åˆ†éš”ç¬¦str_to_map(text, delimiter1, delimiter2) - Creates a map by parsing textselect str_to_map(&#39;key1:val1,key2:val2&#39;, &#39;,&#39;, &#39;:&#39;) from dual; -- translate - è½¬æ¢å­—ç¬¦translate(&#39;abcdef&#39;, &#39;adc&#39;, &#39;19&#39;) returns &#39;1b9ef&#39; replacing &#39;a&#39; with &#39;1&#39;, &#39;d&#39; with &#39;9&#39; and removing &#39;c&#39; from the input stringselect translate(&#39;abcdef&#39;, &#39;adc&#39;, &#39;19&#39;) from dual;ucase, upper - å°å­—è½¬å¤§å†™lcase - å¤§å†™è½¬å°å†™bin - 2è¿›åˆ¶è¡¨ç¤ºhex - 16è¿›åˆ¶è¡¨ç¤ºxpath, xpath_boolean, xpath_double, xpath_float, xpath_int - ç”¨äºxml, htmlæœç´¢è®¡ç®—çš„åˆ©å™¨ç»Ÿè®¡å‡½æ•°-- percentile - ç™¾åˆ†å€¼è®¡ç®—select percentile(price, array(0.3,0.5,0.7)) from trade;-- percentile_approx - ç™¾åˆ†å€¼è®¡ç®—(è¿‘ä¼¼)select percentile_approx(price, array(0.3,0.5,0.7), 100000000) from trade;-- histogram_numeric - ç›´æ–¹å›¾è®¡ç®—select histogram_numeric(price, 10) from trade; -- lag - åä¸€æ¡è®°å½•å€¼select p1.p_mfgr, p1.p_name, p1.p_size, p1.p_size - lag(p1.p_size,1,p1.p_size) over( distribute by p1.p_mfgr sort by p1.p_name) as delt from part p1 join part p2 on p1.p_partkey = p2.p_partkey -- lead - å‰ä¸€æ¡è®°å½•å€¼select lead(id), id from dual; -- ngrams - å‚è§n-gramç®—æ³•ngrams(array&amp;lt;&amp;gt;, int N, int K, int pf)-- è®¡ç®—twitterä¸­æŸä¸¤ä¸ªè¯åŒæ—¶å‡ºç°çš„é¢‘ç‡çš„ top 100 --SELECT ngrams(sentences(lower(tweet)), 2, 100 [, 1000]) FROM twitter; -- stack* - ??select stack(1, id) from dual; -- std - è®¡ç®—æ ‡å‡†å·®select std(column1) from dual;select stddev(column1) from dual;select stddev_pop(column1) from dual; -- var_pop, variance - è®¡ç®—æ–¹å·®ç”¨äºJSONçš„å‡½æ•°-- get_json_object - å­—ç¬¦ä¸²è½¬jsonå¯¹è±¡select get_json_object(line, &#39;$.type&#39;) from ext_passport limit 10; -- json_tuple - jsonå­—ç¬¦ä¸²è½¬tupleselect min(t.date), max(t.date) from ext_passport lateral view json_tuple(line, &#39;type&#39;, &#39;date&#39;) t as type, date;çª—å£å‡½æ•°-- sum, avg, min, maxï¼Œå…³é”®æ˜¯ç†è§£ROWS BETWEENå«ä¹‰,ä¹Ÿå«åšWINDOWå­å¥-- sum - åˆè®¡SELECT cookieid, createtime, pv, SUM(pv) OVER(PARTITION BY cookieid ORDER BY createtime) AS pv1, -- é»˜è®¤ä¸ºä»èµ·ç‚¹åˆ°å½“å‰è¡Œ SUM(pv) OVER(PARTITION BY cookieid ORDER BY createtime ROWS BETWEEN UNBOUNDED PRECEDING AND CURRENT ROW) AS pv2, --ä»èµ·ç‚¹åˆ°å½“å‰è¡Œï¼Œç»“æœåŒpv1 SUM(pv) OVER(PARTITION BY cookieid) AS pv3, --åˆ†ç»„å†…æ‰€æœ‰è¡Œ SUM(pv) OVER(PARTITION BY cookieid ORDER BY createtime ROWS BETWEEN 3 PRECEDING AND CURRENT ROW) AS pv4, --å½“å‰è¡Œ+å¾€å‰3è¡Œ SUM(pv) OVER(PARTITION BY cookieid ORDER BY createtime ROWS BETWEEN 3 PRECEDING AND 1 FOLLOWING) AS pv5, --å½“å‰è¡Œ+å¾€å‰3è¡Œ+å¾€å1è¡Œ SUM(pv) OVER(PARTITION BY cookieid ORDER BY createtime ROWS BETWEEN CURRENT ROW AND UNBOUNDED FOLLOWING) AS pv6 ---å½“å‰è¡Œ+å¾€åæ‰€æœ‰è¡Œ FROM lxw1234;cookieid createtime pv pv1 pv2 pv3 pv4 pv5 pv6-----------------------------------------------------------------------------cookie1 2015-04-10 1 1 1 26 1 6 26cookie1 2015-04-11 5 6 6 26 6 13 25cookie1 2015-04-12 7 13 13 26 13 16 20cookie1 2015-04-13 3 16 16 26 16 18 13cookie1 2015-04-14 2 18 18 26 17 21 10cookie1 2015-04-15 4 22 22 26 16 20 8cookie1 2015-04-16 4 26 26 26 13 13 4-----------------------------------------------------------------------------å„åˆ—è®¡ç®—é€»è¾‘è¯´æ˜ï¼š pv1: åˆ†ç»„å†…ä»èµ·ç‚¹åˆ°å½“å‰è¡Œçš„pvç´¯ç§¯ï¼Œå¦‚ï¼Œ11å·çš„pv1=10å·çš„pv+11å·çš„pv, 12å·=10å·+11å·+12å· pv2: åŒpv1 pv3: åˆ†ç»„å†…(cookie1)æ‰€æœ‰çš„pvç´¯åŠ  pv4: åˆ†ç»„å†…å½“å‰è¡Œ+å¾€å‰3è¡Œï¼Œå¦‚ï¼Œ11å·=10å·+11å·ï¼Œ 12å·=10å·+11å·+12å·ï¼Œ 13å·=10å·+11å·+12å·+13å·ï¼Œ 14å·=11å·+12å·+13å·+14å· pv5: åˆ†ç»„å†…å½“å‰è¡Œ+å¾€å‰3è¡Œ+å¾€å1è¡Œï¼Œå¦‚ï¼Œ14å·=11å·+12å·+13å·+14å·+15å·=5+7+3+2+4=21 pv6: åˆ†ç»„å†…å½“å‰è¡Œ+å¾€åæ‰€æœ‰è¡Œï¼Œå¦‚ï¼Œ13å·=13å·+14å·+15å·+16å·=3+2+4+4=13ï¼Œ14å·=14å·+15å·+16å·=2+4+4=10å¦‚æœä¸æŒ‡å®šROWS BETWEEN,é»˜è®¤ä¸ºä»èµ·ç‚¹åˆ°å½“å‰è¡Œ;å¦‚æœä¸æŒ‡å®šORDER BYï¼Œåˆ™å°†åˆ†ç»„å†…æ‰€æœ‰å€¼ç´¯åŠ ;å…³é”®æ˜¯ç†è§£ROWS BETWEENå«ä¹‰,ä¹Ÿå«åšWINDOWå­å¥ï¼šPRECEDINGï¼šå¾€å‰FOLLOWINGï¼šå¾€åCURRENT ROWï¼šå½“å‰è¡ŒUNBOUNDEDï¼šèµ·ç‚¹ï¼ŒUNBOUNDED PRECEDING è¡¨ç¤ºä»å‰é¢çš„èµ·ç‚¹ï¼Œ UNBOUNDED FOLLOWINGï¼šè¡¨ç¤ºåˆ°åé¢çš„ç»ˆç‚¹å…¶ä»–AVGï¼ŒMINï¼ŒMAXï¼Œå’ŒSUMç”¨æ³•ä¸€æ ·ã€‚-- avg - å‡å€¼ï¼Œå•†å“æ—¥å‡ä»·å˜åŒ–æ›²çº¿select goods_id, avg(price) over(partition by goods_id,to_date(create_time) order by create_time) as price_avgfrom goods-- min - æœ€å°å€¼ï¼Œå•†å“æ—¥æœ€ä½ä»·å˜åŒ–æ›²çº¿select goods_id, min(price) over(partition by goods_id,to_date(create_time) order by create_time) as price_minfrom goods-- max - æœ€å¤§å€¼ ...JDBCæ“ä½œå‡½æ•°CREATE TEMPORARY FUNCTION dboutput AS &#39;org.apache.hadoop.hive.contrib.genericudf.example.GenericUDFDBOutput&#39;;select dboutput( &#39;jdbc:mysql://10.33.64.15:3306/report&#39;, &#39;admin&#39;, &#39;******&#39;, &#39;INSERT INTO QLujingAppDriverAndShipperDau( inputDate, driverAppDau, adAppDau ) VALUES (?,?,?)&#39;, input_date, driverapp_dau, adapp_dau) from increment.report_lujing_app_dau; GenericUDFDBOutputæ˜¯hiveè‡ªå¸¦å‡½æ•°,èƒ½åœ¨shellé‡Œç›´æ¥ä½¿ç”¨ï¼Œä½†æ˜¯hueé‡Œä¸ä¼šåŠ è½½è¿™ä¸ªjar,éœ€è¦æ·»åŠ åˆ°AUX_JARS_PATH=[jar]æˆ–è€…åœ¨HIVE_HOMEç›®å½•ä¸‹æ–°å¢ä¸€ä¸ªauxlibç›®å½•ï¼Œå°†è¯¥jaræ”¾åˆ°è¿™ä¸ªç›®å½•ä¸‹,é‡å¯hiveæœåŠ¡åï¼Œæ‰èƒ½æ­£å¸¸ä½¿ç”¨; ç½‘ä¸Šçš„åœ¨hueé‡Œé…ç½®ä¿®æ”¹è¾…åŠ©jarè·¯å¾„ï¼Œå¯èƒ½å¯¼è‡´è®©shellä¸­Hiveç›¸å…³å‘½ä»¤ä¸èƒ½æ­£å¸¸å·¥ä½œã€‚" }, { "title": "Apache Flume ç®€å•ä»‹ç»", "url": "/posts/flume-introduce/", "categories": "Big data, Flume", "tags": "", "date": "2016-06-24 18:39:00 +0800", "snippet": "ç®€ä»‹Flumeæ˜¯Clouderaå…¬å¸ç ”å‘çš„é«˜å¯ç”¨ã€å¯é ã€åˆ†å¸ƒå¼æ—¥å¿—é‡‡é›†ç³»ç»Ÿã€‚Flumeç”±1~nä¸ªAgentç»„æˆï¼Œæ¯ä¸ªAgentéƒ¨ç½²åˆ°ä¸€ä¸ªä¸»æœºä¸­ï¼ŒAgentç”±ä¸‰å¤§éƒ¨ä»¶æ„æˆFlumeç»„ä»¶ç»“æ„å›¾Flumeç³»ç»Ÿæœ‰å¦‚ä¸‹ç‰¹ç‚¹ ç”±1 ~ nä¸ªAgentç»„æˆï¼Œæ¯ä¸ªAgentéƒ¨ç½²åˆ°ä¸€ä¸ªä¸»æœºä¸­ ä¸€ä¸ªAgentå°±æ˜¯ä¸€ä¸ªJVMè¿›ç¨‹ï¼ŒåŒ…å«Sourceã€Sinkã€Channelä¸‰ç»„ä»¶ï¼ŒSourceè´Ÿè´£æ—¥å¿—è¯»å–ï¼ŒChannelè´Ÿè´£æ•°æ®æš‚å­˜ï¼ŒSinkè´Ÿè´£æ•°æ®å†™å…¥ Sourceã€Channelã€Sinkæä¾›å¤šç§ç±»å‹ï¼Œä¸åŒç±»å‹ç»„ä»¶å¯ä»¥é€šè¿‡ç¼–å†™çš„é…ç½®æ–‡ä»¶è‡ªç”±ç»„åˆï¼Œä¾‹å¦‚Channelç±»å‹åˆ†ä¸ºMemoryã€Diskç­‰ï¼ŒSinkåˆ†ä¸ºHDFSï¼ŒHBaseç­‰ ä¸€ä¸ªä¸»æœºä¸éœ€è¦éƒ¨ç½²å¤šä¸ªAgentï¼Œä¸€ä¸ªAgentå¯ä»¥é…ç½®å¤šä¸ªSourceï¼Œå¯¹åº”ä¸åŒçš„æ—¥å¿—ç±»å‹æˆ–è€…æ—¥å¿—è·¯å¾„ Sourceæ”¶é›†åˆ°çš„æ—¥å¿—æ•°æ®è¢«å°è£…ä¸ºEventï¼Œå¯èƒ½æ˜¯æ—¥å¿—è®°å½•ï¼Œæˆ–è€…avroå¯¹è±¡ï¼Œç”±å…·ä½“é…ç½®æ–‡ä»¶é…ç½®ï¼Œåç»­Channelä¸­æš‚å­˜ä¹Ÿæ˜¯Events ä¸åŒç±»å‹æˆ–è€…è·¯å¾„çš„æ—¥å¿—ï¼Œå³å¯ä»¥èµ°å„è‡ªä¸åŒçš„Channelï¼Œä¹Ÿå¯ä»¥åˆå¹¶åˆ°åŒä¸€ä¸ªChannelä¸­å» ä¸€ä¸ªChannelå¯ä»¥è¿æ¥ä¸€ä¸ªSinkï¼Œä¹Ÿå¯ä»¥è¿æ¥å¤šä¸ªä¸åŒSinkï¼Œç”šè‡³Sinkå¯ä»¥è¿æ¥åˆ°å¦å¤–ä¸€ä¸ªSourceï¼Œå½“ä¸€ä¸ªSinkè¿æ¥åˆ°å¦å¤–ä¸€ä¸ªSourceæ—¶ï¼Œå¯ä»¥è§†ä¸ºå»ºç«‹äº†ä¸€ä¸ªå¤šçº§æ—¥å¿—æµ ä¸‰å¤§ç»„ä»¶å‡å¯ä»¥å¼€å‘è‡ªå®šä¹‰ç±»å‹ï¼Œç”±äºå·²ç»é¢„ç•™æ‰©å±•æ¥å£å’Œé‡‡ç”¨Javaè¯­è¨€ï¼Œå®ç°èµ·æ¥è¾ƒä¸ºå®¹æ˜“Flumeæ„æˆçš„å¤šçº§æ—¥å¿—æµChannelç»„ä»¶æ˜¯Flumeæ¶æ„è®¾è®¡ç‰¹ç‚¹ï¼ŒFan-inã€Fan-outå¾—ä»¥å®ç°ï¼Œèµ‹äºæ•´ä¸ªç³»ç»Ÿçµæ´»æ€§ã€‚åŒæ—¶è¿™ç§çµæ´»æ€§å¹¶éæ²¡æœ‰ä»£ä»·ï¼š Channelçš„è®¾è®¡åœ¨ä½¿ç”¨å†…å­˜çš„æƒ…å†µä¸‹ä¾æ®æ—¥å¿—æ•°æ®å¤šå°‘ä¼šæ¶ˆè€—å†…å­˜ï¼Œæ¢ç”¨ç£ç›˜ç±»å‹Channelä¼ è¾“é€Ÿåº¦å¤§å¹…ä¸‹é™ Eventçš„è®¾è®¡ä¸ºåŸºäºç®€å•çš„æ‰©å±•åŠŸèƒ½æä¾›å¾ˆå¥½åˆ‡å…¥ç‚¹ï¼Œä½†åŒæ—¶ä¹Ÿå¸¦æ¥åºåˆ—åŒ–ååºåˆ—åŒ–çš„è¿ç®—å¼€é”€å’Œå†…å­˜å ç”¨å¢åŠ åŸºäºä»¥ä¸Šä¼˜ç¼ºç‚¹ï¼Œå¯çŸ¥Flumeæ»¡è¶³ä»¥ä¸‹åœºæ™¯ å¯¹æ—¥å¿—ä¼ è¾“å®æ—¶æ€§è¦æ±‚ä¸é«˜ (å—æš‚å­˜æ¶æ„å½±å“) åœ¨ä½¿ç”¨æ—¥å¿—æ•°æ®æ—¶ï¼Œä¸éœ€è¦è¿›è¡Œè¿‡äºå¤æ‚çš„å¤„ç†ï¼ˆæœ¬è´¨åªå¯¹å•è®°å½•è¿›è¡Œå¤„ç†ï¼‰ å•ä¸»æœºæ—¥å¿—é‡çº§ä¸ä¼šè¿‡å¤§ï¼ˆæ‰€æœ‰åŠŸèƒ½éƒ¨ä»¶å‡åœ¨åŒä¸€ä¸»æœºï¼‰" }, { "title": "Data Warehouse Base", "url": "/posts/data-warehouse-base/", "categories": "Data Warehouse", "tags": "updating", "date": "2016-02-18 00:00:00 +0800", "snippet": " OLTPï¼šè”æœºäº‹åŠ¡å¤„ç† OLAPï¼šè”æœºåˆ†æå¤„ç†DatawarehouseODSï¼šOperation Data Storeæ•°æ®è´´æºå±‚ï¼Œé€šå¸¸ç›´æ¥ä¿å­˜ä»å¤–éƒ¨å¯¼å…¥çš„æ•°æ®ï¼Œä¸åšä»»ä½•å¤„ç†DWDï¼šData Warehouse Detailæ•°æ®æ˜ç»†å±‚ï¼Œå¯¹ODSå±‚çš„æ•°æ®è¿›è¡Œæ¸…æ´—ï¼Œè¿‡æ»¤æ‰è„æ•°æ®ã€å¦‚ç¼ºå¤±å…³é”®å€¼ï¼Œæˆ–æ•°æ®å€¼æ˜æ˜¾é”™è¯¯ç­‰ï¼Œå½¢æˆå¯ç”¨çš„å¹²å‡€æ•°æ®å¦ä¸€æ–¹é¢å¯ä»¥å°†ODSå±‚çš„ä¸åŒæ¥æºçš„æ•°æ®æŒ‰ç…§è§„èŒƒç»Ÿä¸€åï¼Œä½¿å…¶å…·æœ‰ä¸€è‡´çš„æ•°æ®æ ¼å¼å’Œè§„èŒƒï¼Œä¿å­˜åˆ°åŒä¸€å¤„ä»“åº“ä¹Ÿä¾¿äºç»Ÿä¸€è®¡ç®—DM/DWM/DWBï¼šData Warehouse Basisæ•°æ®åŸºç¡€å±‚ï¼Œä¹Ÿæœ‰ç§°DM DWMï¼ˆData Warehouse Middleï¼‰ä¿å­˜è½»åº¦æ±‡æ€»æ•°æ®ï¼Œå±äºDWDå‘DWSè¿‡æ¸¡å±‚æ¬¡ï¼Œæé«˜æ•°æ®å¤ç”¨åº¦DWSï¼šData Warehouse Serviceä»¥ä¸»é¢˜åŸŸå»ºç«‹çš„å®½è¡¨ï¼Œéƒ½æ˜¯å·²ç»æ±‡æ€»å¥½çš„æ•°æ®ï¼ŒæŒ‰ç…§ä¸šåŠ¡åˆ’åˆ†ï¼Œç”Ÿæˆå­—æ®µæ¯”è¾ƒå¤šçš„å®½è¡¨ï¼Œæä¾›åç»­ä¸šåŠ¡æŸ¥è¯¢ï¼Œå¦‚OLAPåˆ†æå’Œæ•°æ®åˆ†å‘ADSï¼šApplication Data Serviceåº”ç”¨æ•°æ®æœåŠ¡å±‚ï¼Œå¯ç›´æ¥ç”¨äºåº”ç”¨çš„æ•°æ®ï¼Œé€šå¸¸æ”¾åˆ°Redisã€ESç­‰èƒ½æ»¡è¶³å¿«é€Ÿå“åº”çš„æ•°æ®å­˜å‚¨ä¸­ï¼Œé‡ç‚¹æ»¡è¶³æŸ¥è¯¢æ€§èƒ½è¦æ±‚Data Modelæ•°æ®æ¨¡å‹ï¼Œå°†æ•°æ®æŒ‰ç…§ä¸€å®šç†è®ºæ€æƒ³è¿›è¡Œæ‹†åˆ†ã€ç»„åˆã€ä½¿å…¶å½¢æˆä¸€ç³»åˆ—æ•°æ®ç»“æ„ï¼Œå¯ä»¥æ›´å®¹æ˜“ã€é«˜æ•ˆæ»¡è¶³æœ€ç»ˆå·¥ä½œç›®æ ‡å¹¶å…·å¤‡æœ‰å¾ˆå¥½çš„æ‰©å±•æ€§ï¼Œè¿™ä¸ªè®¾è®¡è¿‡ç¨‹å¯ç§°ä¹‹ä¸ºæ•°æ®å»ºæ¨¡ã€‚ä¾‹å¦‚ä¸ºæ»¡è¶³ä¸šåŠ¡äº‹åŠ¡çš„ä¸šåŠ¡è¡¨å»ºæ¨¡ï¼Œæœ‰ä¸‰èŒƒå¼ç†è®ºã€‚ä¸ºæ»¡è¶³åˆ†æçš„æ•°æ®ä»“åº“å»ºæ¨¡ï¼Œæœ‰ç»´åº¦å»ºæ¨¡ç†è®ºã€‚ æœªå®Œå¾…ç»­â€¦" }, { "title": "Mysql Find Root Password", "url": "/posts/mysql-find-root-password/", "categories": "Database, MySQL", "tags": "", "date": "2016-02-05 00:00:00 +0800", "snippet": "ä¸ªäººå¼€å‘æœºä¸Šçš„MySQLï¼Œå› ä¸ºé•¿æœŸä¸ç”¨rootç”¨æˆ·å¯†ç å·²ç»å¿˜è®°äº†ï¼Œç°åœ¨éœ€è¦åˆ›å»ºä¸€ä¸ªæ–°ç”¨æˆ·éœ€è¦æ‰¾å›rootç”¨æˆ·å¯†ç è¿›è¡Œæ“ä½œmacOS ç³»ç»Ÿä¸‹æ‰¾å›ç®¡ç†å¯†ç ä»¥macæ“ä½œç³»ç»Ÿä¸ºä¾‹ï¼Œæ¼”ç¤ºæ“ä½œæ­¥éª¤ åœ¨â€™ç³»ç»Ÿåå¥½è®¾ç½®â€™ä¸­å…³é—­mysqlæœåŠ¡ æ‰“å¼€ç»ˆç«¯ä¾æ¬¡è¾“å…¥å¦‚ä¸‹å‘½ä»¤cd /usr/local/mysql/bin# éœ€è¦rootæƒé™æ‰§è¡Œç›¸å…³æ“ä½œsudo su./mysqld_safe --skip-grant-tables &amp;amp;./mysqlè¿›å…¥MySQLå‘½ä»¤è¡Œåè¾“å…¥å¦‚ä¸‹MySQLå‘½ä»¤flush privileges;set password for &#39;root&#39;@&#39;localhost&#39; = password(&#39;123456&#39;);exit;å®Œæˆå¯†ç è®¾ç½®åæµ‹è¯•ä¸€ä¸‹, ç”¨æ–°å¯†ç ç™»å½•MySQLï¼ŒæˆåŠŸç™»å…¥ï¼Œæ¥ä¸‹æ¥å°±å¯ä»¥æ­£å¸¸æ¨¡å¼å¯åŠ¨mysqlæœåŠ¡äº†./mysql -u root -p123456 è¿™é‡Œå¯†ç è®¾ç½®ä¸º123456æ˜¯æ–¹ä¾¿å¼€å‘æœºæµ‹è¯•ï¼Œåœ¨æ­£å¼é¡¹ç›®ä¸­ä¸è¦ä½¿ç”¨è¿™ç±»ç®€å•å¯†ç " }, { "title": "æŠ›å¼ƒIDEä»å‘½ä»¤è¡Œæ‰§è¡ŒMySQLè„šæœ¬", "url": "/posts/mysql-sql-scripts/", "categories": "Database, MySQL", "tags": "develop", "date": "2016-01-20 12:16:00 +0800", "snippet": "åœ¨å‘½ä»¤è¡Œè®©MySQLæ‰§è¡Œå·²ç»ç¼–å†™å¥½çš„SQLè„šæœ¬ï¼Œæ¯”å¦‚æ‰¹é‡æ•°æ®æ’å…¥ï¼Œæˆ–è€…æ›´æ–°ç­‰ä¸‹é¢æ˜¯åŸºæœ¬ä¿¡æ¯ MySQL IP: 192.168.0.100 MySQL Port: 3306 æ•°æ®åº“å: test ç”¨æˆ·åï¼šdev è„šæœ¬åï¼šcreate-tables.sqlmysql -h192.168.0.100 -udev -p -Dtest&amp;lt;create-tables.sql ä¸Šé¢å‘½ä»¤è¦æ±‚æ‰§è¡Œæœºä¸Šå·²ç»å®‰è£…å¥½MySQLå®¢æˆ·ç«¯å¦‚æœä¸å¸Œæœ›å®‰è£…MySQLå®¢æˆ·ç«¯åˆ™éœ€è¦ç™»å½•mysqlæœåŠ¡å™¨scp create-tables.sql admin@192.168.0.100:~/ssh admin@192.168.0.100mysql -udev -p -Dtest&amp;lt;create-tables.sql éœ€è¦æœ‰MySQLæœåŠ¡å™¨ç™»å½•æƒé™å¹¶ä¸”çŸ¥é“ç”¨æˆ·åå’Œå¯†ç ï¼Œä¸€èˆ¬æ­£è§„å…¬å¸ç¯å¢ƒæœ‰ç‚¹éš¾æ‹¿åˆ°æƒé™" }, { "title": "å¼€æºé•œåƒç«™æ”¶å½•", "url": "/posts/open-source-mirror/", "categories": "Mac, software", "tags": "develop, environment", "date": "2016-01-15 12:03:00 +0800", "snippet": "æœ‰ä¸€å®šæ—¶æ•ˆæ€§ï¼Œä»…ä¾›å‚è€ƒå¼€æºç½‘ç«™é•œåƒï¼šæœç‹å¼€æºé•œåƒç«™ï¼šhttp://mirrors.sohu.com/ç½‘æ˜“å¼€æºé•œåƒç«™ï¼šhttp://mirrors.163.com/å¼€æºä¸­å›½ï¼šhttp://mirrors.oschina.net/é¦–éƒ½åœ¨çº¿ç§‘æŠ€è‚¡ä»½æœ‰é™å…¬å¸ï¼šhttp://mirrors.yun-idc.com/é˜¿é‡Œäº‘å¼€æºé•œåƒï¼šhttp://mirrors.aliyun.com/LUPAï¼šhttp://mirror.lupaworld.com/å¸¸å·è´ç‰¹åº·å§†è½¯ä»¶æŠ€æœ¯æœ‰é™å…¬å¸(åŸcn99ï¼‰ï¼šhttp://centos.bitcomm.cn/å¤§å­¦æ ¡å›­é•œåƒï¼šä¸­å±±å¤§å­¦é•œåƒï¼šhttp://mirror.sysu.edu.cn/å±±ä¸œç†å·¥å¤§å­¦ï¼šhttp://mirrors.sdutlinux.org/å“ˆå°”æ»¨å·¥ä¸šå¤§å­¦ï¼šhttp://run.hit.edu.cn/ä¸­å›½åœ°è´¨å¤§å­¦ï¼šhttp://cugbteam.org/å¤§è¿ç†å·¥å¤§å­¦ï¼šhttp://mirror.dlut.edu.cn/è¥¿å—æ—ä¸šå¤§å­¦ http://cs3.swfu.edu.cn/cs3guide.htmlåŒ—äº¬åŒ–å·¥å¤§å­¦ï¼ˆä»…æ•™è‚²ç½‘å¯ä»¥è®¿é—®ï¼‰ï¼ŒåŒ…å« CentOS é•œåƒï¼šhttp://ubuntu.buct.edu.cn/å¤©æ´¥å¤§å­¦ï¼šhttp://mirror.tju.edu.cn/è¥¿å—å¤§å­¦ï¼šhttp://linux.swu.edu.cn/swudownload/Distributions/é’å²›å¤§å­¦ï¼šhttp://mirror.qdu.edu.cn/å—äº¬å¸ˆèŒƒå¤§å­¦ï¼šhttp://mirrors.njnu.edu.cn/å¤§è¿ä¸œè½¯ä¿¡æ¯å­¦é™¢ï¼š http://mirrors.neusoft.edu.cn/æµ™æ±Ÿå¤§å­¦ï¼šhttp://mirrors.zju.edu.cn/å…°å·å¤§å­¦ï¼šhttp://mirror.lzu.edu.cn/å¦é—¨å¤§å­¦ï¼šhttp://mirrors.xmu.edu.cn/åŒ—äº¬ç†å·¥å¤§å­¦ï¼šhttp://mirror.bit.edu.cn (IPv4 only), http://mirror.bit6.edu.cn (IPv6 only)åŒ—äº¬äº¤é€šå¤§å­¦ï¼šhttp://mirror.bjtu.edu.cn (IPv4 only), http://mirror6.bjtu.edu.cn (IPv6 only), http://debian.bjtu.edu.cn (IPv4+IPv6)ä¸Šæµ·äº¤é€šå¤§å­¦ï¼šhttp://ftp.sjtu.edu.cn/ (IPv4 only), http://ftp6.sjtu.edu.cn (IPv6 only)æ¸…åå¤§å­¦ï¼šhttp://mirrors.tuna.tsinghua.edu.cn/ (IPv4+IPv6), http://mirrors.6.tuna.tsinghua.edu.cn/ (IPv6 only), http://mirrors.4.tuna.tsinghua.edu.cn/ (IPv4 only)ä¸­å›½ç§‘å­¦æŠ€æœ¯å¤§å­¦ï¼šhttp://mirrors.ustc.edu.cn/ (IPv4+IPv6), http://mirrors4.ustc.edu.cn/, http://mirrors6.ustc.edu.cn/ä¸œåŒ—å¤§å­¦ï¼šhttp://mirror.neu.edu.cn/ (IPv4 only), http://mirror.neu6.edu.cn/ (IPv6 only)åä¸­ç§‘æŠ€å¤§å­¦ï¼šhttp://mirrors.hust.edu.cn/, http://mirrors.hustunique.com/ç”µå­ç§‘æŠ€å¤§å­¦ï¼šhttp://ubuntu.uestc.edu.cn/ç”µå­ç§‘å¤§å‡èšå·¥ä½œå®¤(Raspbianå•ä¸€ç³»ç»Ÿé•œåƒ) http://raspbian.cnssuestc.org/ç”µå­ç§‘å¤§æ˜Ÿè¾°å·¥ä½œå®¤(å°‘æ•°å°ä¼—å‘å¸ƒç‰ˆé•œåƒ) http://mirrors.stuhome.net/PyPi é•œåƒè±†ç“£ï¼šhttp://pypi.douban.com/å±±ä¸œç†å·¥å¤§å­¦ï¼šhttp://pypi.sdutlinux.org/ä¸­å±±å¤§å­¦ï¼šhttp://mirror.sysu.edu.cn/pypi/V2EXï¼šhttp://pypi.v2ex.com/simple/RubyGems é•œåƒä¸­å±±å¤§å­¦ï¼šhttp://mirror.sysu.edu.cn/rubygems/å±±ä¸œç†å·¥å¤§å­¦ï¼šhttp://ruby.sdutlinux.org/æ·˜å®ç½‘ï¼šhttp://ruby.taobao.org/npm é•œåƒcnpmjsï¼šhttp://cnpmjs.org/" }, { "title": "Java Open Source Library", "url": "/posts/java-open-source-library/", "categories": "Java, Library", "tags": "updating", "date": "2016-01-10 11:58:00 +0800", "snippet": "è®°å½•ä¸€æ³¢å¼€æºåº“åç§°åŠç”¨é€”ä»‹ç» åŒ… åç§° æè¿° com.sun.jersey jersey-* Restfulæ¡†æ¶ com.github.jsqlparser jsqlparser SQLè¯æ³•åˆ†æ com.github.scopt scopt_2.11 SCALAå‘½ä»¤è¡Œå‚æ•°è§£æ com.yammer.metrics metrics-core ç³»ç»Ÿæ´å¯Ÿåº“ io.dropwizard.metrics metrics-* ç³»ç»Ÿæ´å¯Ÿåº“ï¼Œä¸Šé¢è¿™ä¸ªåº“çš„å‡çº§ç‰ˆæœ¬3.xç‰ˆæœ¬ net.jpountz.lz4 lz4 lz4æ•°æ®å‹ç¼©ï¼Œé€Ÿåº¦æœ€å¿« net.sf.jopt-simple jopt-simple java å‘½ä»¤è¡Œå‚æ•°è§£æ net.sf.opencsv opencsv CSVæ–‡ä»¶è¯»å†™ net.sf.py4j py4j python ä¸ javaäº’ç›¸è®¿é—® net.sf.serfj serfj rest freamwork org.apache.commons commons-compress zipå‹ç¼©ä¸è¯»å– org.apache.curator curator-* Curatoræ˜¯Netflixå…¬å¸å¼€æºçš„ä¸€ä¸ªZookeeperå®¢æˆ·ç«¯ï¼Œä¸Zookeeperæä¾›çš„åŸç”Ÿå®¢æˆ·ç«¯ç›¸æ¯”ï¼ŒCuratorçš„æŠ½è±¡å±‚æ¬¡æ›´é«˜ï¼Œç®€åŒ–äº†Zookeeperå®¢æˆ·ç«¯çš„å¼€å‘é‡ã€‚ org.apache.ivy ivy ä¾èµ–ç®¡ç† org.aspectj aspectjweaver AOPä¾èµ–åŒ… org.beanshell bsh-core åŠ¨æ€æ‰§è¡Œjavaä»£ç  org.codehaus.janino janino è¶…çº§å°ä½†åˆè¶…çº§å¿«çš„Javaç¼–è¯‘å™¨ï¼Œè¢«æ•´åˆåˆ°apache commons jclé¡¹ç›®å’ŒJBoss Rules/Droolsé¡¹ç›® org.bouncycastle bcprov-jdk15on ä¸€ç§ç”¨äº Java å¹³å°çš„å¼€æ”¾æºç çš„è½»é‡çº§å¯†ç æœ¯åŒ…ã€‚å®ƒæ”¯æŒå¤§é‡çš„å¯†ç æœ¯ç®—æ³•ï¼Œå¹¶æä¾› JCE 1.2.1 çš„å®ç°ã€‚å› ä¸º Bouncy Castle è¢«è®¾è®¡æˆè½»é‡çº§çš„ï¼Œæ‰€ä»¥ä» J2SE 1.4 åˆ° J2MEï¼ˆåŒ…æ‹¬ MIDPï¼‰å¹³å°ï¼Œå®ƒéƒ½å¯ä»¥è¿è¡Œã€‚å®ƒæ˜¯åœ¨ MIDP ä¸Šè¿è¡Œçš„å”¯ä¸€å®Œæ•´çš„å¯†ç æœ¯åŒ…ã€‚ org.codehaus.jettison jettison jsonå¤„ç†åŒ… org.glassfish.hk2 hk2-* IoC/DI å®¹å™¨æ¡†æ¶ org.hamcrest hamcrest-* ç”¨äºæµ‹è¯•çš„åŒ¹é…å™¨æ¡†æ¶ org.objenesis objenesis ä¸ä½¿ç”¨æ„é€ æ–¹æ³•åˆ›å»ºJavaå¯¹è±¡ stax stax è§£æXML xalan xalan XSLTè½¬æ¢å™¨ æœªå®Œå¾…ç»­â€¦" }, { "title": "Spring 7ç§äº‹åŠ¡ä¼ æ’­", "url": "/posts/spring-transaction/", "categories": "Java, Spring", "tags": "develop", "date": "2016-01-07 11:42:00 +0800", "snippet": " PROPAGATION_REQUIRED å¦‚æœå½“å‰æ²¡æœ‰äº‹åŠ¡ï¼Œå°±æ–°å»ºä¸€ä¸ªäº‹åŠ¡ï¼Œå¦‚æœå·²ç»å­˜åœ¨ä¸€ä¸ªäº‹åŠ¡ä¸­ï¼ŒåŠ å…¥åˆ°è¿™ä¸ªäº‹åŠ¡ä¸­ã€‚è¿™æ˜¯æœ€å¸¸è§çš„é€‰æ‹©ã€‚ PROPAGATION_SUPPORTS æ”¯æŒå½“å‰äº‹åŠ¡ï¼Œå¦‚æœå½“å‰æ²¡æœ‰äº‹åŠ¡ï¼Œå°±ä»¥éäº‹åŠ¡æ–¹å¼æ‰§è¡Œã€‚ PROPAGATION_MANDATORY ä½¿ç”¨å½“å‰çš„äº‹åŠ¡ï¼Œå¦‚æœå½“å‰æ²¡æœ‰äº‹åŠ¡ï¼Œå°±æŠ›å‡ºå¼‚å¸¸ã€‚ PROPAGATION_REQUIRES_NEW æ–°å»ºäº‹åŠ¡ï¼Œå¦‚æœå½“å‰å­˜åœ¨äº‹åŠ¡ï¼ŒæŠŠå½“å‰äº‹åŠ¡æŒ‚èµ·ã€‚ PROPAGATION_NOT_SUPPORTED ä»¥éäº‹åŠ¡æ–¹å¼æ‰§è¡Œæ“ä½œï¼Œå¦‚æœå½“å‰å­˜åœ¨äº‹åŠ¡ï¼Œå°±æŠŠå½“å‰äº‹åŠ¡æŒ‚èµ·ã€‚ PROPAGATION_NEVER ä»¥éäº‹åŠ¡æ–¹å¼æ‰§è¡Œï¼Œå¦‚æœå½“å‰å­˜åœ¨äº‹åŠ¡ï¼Œåˆ™æŠ›å‡ºå¼‚å¸¸ã€‚ PROPAGATION_NESTED å¦‚æœå½“å‰å­˜åœ¨äº‹åŠ¡ï¼Œåˆ™åœ¨åµŒå¥—äº‹åŠ¡å†…æ‰§è¡Œã€‚å¦‚æœå½“å‰æ²¡æœ‰äº‹åŠ¡ï¼Œåˆ™æ‰§è¡Œä¸ PROPAGATION_REQUIRED ç±»ä¼¼çš„æ“ä½œã€‚" }, { "title": "macä½¿ç”¨æŠ€å·§1", "url": "/posts/mac-tip1/", "categories": "Mac, tip", "tags": "", "date": "2015-12-23 20:55:00 +0800", "snippet": "åœ¨Finderä¸­æ˜¾ç¤ºç³»ç»Ÿéšè—æ–‡ä»¶å’Œæ–‡ä»¶å¤¹defaults write com.apple.finder AppleShowAllFiles -boolean true ; killall Finderåœ¨Finderä¸­æ¢å¤ç³»ç»Ÿéšè—æ–‡ä»¶å’Œæ–‡ä»¶å¤¹defaults write com.apple.finder AppleShowAllFiles -boolean false ; killall Finderä¸ºæ™®é€šé.å¼€å¤´çš„æ–‡ä»¶æˆ–æ–‡ä»¶å¤¹åŠ ä¸Šéšè—å±æ€§ï¼Œåœ¨Finderä¸­ä¸å¯è§chflags hidden æ–‡ä»¶å|ç›®å½•åchflags nohidden æ–‡ä»¶å|ç›®å½•åOS Xä¸­çš„ftp ç›´æ¥åœ¨å‘½ä»¤è¡Œä½¿ç”¨ï¼Œæ‰“å¼€ç»ˆç«¯è¾“å…¥ftp anonymous@ftp.mozilla.orgï¼Œæˆ–è€…ä½¿ç”¨sftpé€šè¿‡sshå®Œæˆftpçš„åŠŸèƒ½ï¼Œä¾‹å¦‚sftp user@10.10.10.11ã€‚ ä½¿ç”¨ç¬¬ä¸‰æ–¹å·¥å…·ï¼Œæ¯”å¦‚FileZillaï¼Œç”¨æ³•å’Œwindowsç±»ä¼¼ã€‚ åˆ©ç”¨OS XåŸç”Ÿftpå·¥å…·ï¼Œä» Finder èœå•æ ä¸­è¿›å…¥â€œå‰å¾€ - è¿æ¥æœåŠ¡å™¨â€¦â€ï¼Œè¾“å…¥ FTP æœåŠ¡å™¨åœ°å€ï¼ˆå¦‚ï¼šftp://ftp.mozilla.orgï¼‰ç‚¹å‡»åœ°å€æ å³ä¾§çš„ + å·æŒ‰é’®å¯ä»¥å°†å½“å‰åœ°å€åŠ å…¥â€œä¸ªäººæ”¶è—æœåŠ¡å™¨â€ç‚¹å‡»â€œè¿æ¥â€æŒ‰é’®ï¼ŒæŒ‰ç…§æç¤ºè¿›è¡Œèº«ä»½éªŒè¯æˆåŠŸåå³å¯è¿æ¥åˆ° FTP æœåŠ¡å™¨ã€‚historyæ‰“å¼€ç»ˆç«¯è¾“å…¥historyï¼Œæ‰€æœ‰çš„å†å²å‘½ä»¤éƒ½ä¼šæ˜¾ç¤ºå‡ºæ¥ï¼Œæƒ³æ‰¾æŸä¸€æ¡æ‰§è¡Œè¿‡çš„å‘½ä»¤ï¼Œè¿˜å¯ä»¥è¿™æ ·ï¼šhistory|grep apacheæ‰¾åˆ°å·¦è¾¹çš„å‘½ä»¤ç¼–å·ï¼ˆä¾‹å¦‚æ˜¯1001ï¼‰ï¼Œåœ¨ç»ˆç«¯è¾“å…¥ï¼š!1001å°±å¯ä»¥æ‰§è¡ŒåŸæ¥é‚£æ¡å‘½ä»¤äº†ã€‚Spotlightæ³¨é‡ŠOS Xçš„æ–‡ä»¶ç³»ç»Ÿæä¾›äº†Spotlightæ³¨é‡ŠåŠŸèƒ½ï¼Œå¯ä»¥å¸®åŠ©ç”¨æˆ·æ›´æœ‰é’ˆå¯¹æ€§çš„å®šä½æ–‡ä»¶ã€‚é€‰ä¸­ä¸€ä¸ªæ–‡ä»¶æˆ–æ–‡ä»¶å¤¹ï¼Œcommand+Iæ‰“å¼€ç®€ä»‹ï¼Œåœ¨Spotlightæ³¨é‡ŠåŠŸèƒ½ä¸­åŠ å…¥è‡ªå·±ç‰¹å®šçš„å…³é”®è¯ã€‚å…³æ‰ç®€ä»‹çª—å£ï¼Œå‘¼å‡ºSpotlightå¹¶è¾“å…¥åˆšæ‰çš„å…³é”®è¯ï¼Œå¯ä»¥å‡†ç¡®å®šä½åˆ°å…·å¤‡ç›¸å…³å…³é”®è¯æ³¨é‡Šçš„æ–‡ä»¶æˆ–æ–‡ä»¶å¤¹ã€‚ä½¿ç”¨sipså‘½ä»¤æ‰¹é‡å¤„ç†å›¾ç‰‡å¦‚æœä½ æƒ³æ‰¹é‡ä¿®æ”¹ä¸€æ‰¹å›¾ç‰‡ï¼ˆå°ºå¯¸ã€æ—‹è½¬ã€åè½¬ç­‰ï¼‰ï¼Œä½†æ˜¯ä½ æœ‰ä¸ä¼šæˆ–æ²¡æœ‰PSï¼Œæ€ä¹ˆåŠå‘¢ï¼Ÿä½¿ç”¨sipså‘½ä»¤å¯ä»¥é«˜æ•ˆå®Œæˆè¿™äº›åŠŸèƒ½ï¼Œä¾‹å¦‚ï¼š# æŠŠå½“å‰ç”¨æˆ·å›¾ç‰‡æ–‡ä»¶å¤¹ä¸‹çš„æ‰€æœ‰JPGå›¾ç‰‡å®½åº¦ç¼©å°ä¸º800pxï¼Œé«˜åº¦æŒ‰æ¯”ä¾‹ç¼©æ”¾sips -Z 800 ~/Pictures/*.JPG# é¡ºæ—¶é’ˆæ—‹è½¬90Ëšsips -r 90 ~/Pictures/*.JPG# å‚ç›´åè½¬sips -f vertical ~/Pictures/*.JPGæ›´å¤šå‘½ä»¤å¯ä»¥ç”¨sips -hæŸ¥çœ‹ã€‚å¿«é€Ÿä¾¿ç­¾é€‰ä¸­è¦ä¿ç•™çš„æ–‡æœ¬ï¼Œç„¶åæŒ‰ä¸‹å¿«æ·é”® Shift + Command + yå¤šæ–‡ä»¶æ–‡ä»¶å¤¹æ“ä½œåœ¨windowsä¸­å¤§å®¶ç»å¸¸é€‰ä¸­å¤šä¸ªæ–‡ä»¶ï¼Œå³é”®-å±æ€§å¯ä»¥æŸ¥çœ‹è¿™äº›æ–‡ä»¶çš„å¤§å°ã€‚åœ¨Macé‡ŒåŒæ ·çš„æ“ä½œï¼ˆé€‰ä¸­å¤šä¸ªæ–‡ä»¶ï¼Œå³é”®-æ˜¾ç¤ºç®€ä»‹ï¼‰ï¼Œå¼¹å‡ºçš„æ˜¯å„ä¸ªæ–‡ä»¶æˆ–æ–‡ä»¶å¤¹çš„ç®€ä»‹ï¼Œè¿™è®©å¾ˆå¤šç«¥é´å›°æƒ‘ä¸è§£ã€‚å…¶å®æˆ‘ä»¬åªè¦åœ¨ç‚¹å³é”®çš„åŒæ—¶æŒ‰ä½optioné”®ï¼Œæ˜¾ç¤ºç®€ä»‹å°±ä¼šå˜æˆæ˜¾ç¤ºæ£€æŸ¥å™¨ï¼Œç‚¹å‡»æ˜¾ç¤ºæ£€æŸ¥å™¨å³å¯æŸ¥çœ‹å’Œæ“ä½œæ‰¹é‡æ–‡ä»¶ã€‚å¦å¤–ï¼Œæˆ‘è¿˜ç»å¸¸ç”¨è¿™ç§æ–¹å¼æµè§ˆå›¾ç‰‡ï¼Œæ¯”å¦‚é€‰ä¸­å¤šå¼ å›¾ç‰‡ï¼Œoption+å³é”®ï¼Œé€‰ä¸­â€œå¹»ç¯ç‰‡æ˜¾ç¤ºxxé¡¹â€ï¼Œå°±å¯ä»¥å…¨å±æµè§ˆå›¾ç‰‡äº†ã€‚å¿«æ·é”®: Option + Command + i å’Œ Option + Command + yè„šæœ¬ç­‰ç¨‹åºæ‰§è¡Œè€—æ—¶æŸ¥çœ‹æ¯”å¦‚ä½ æƒ³çŸ¥é“åœ¨ç»ˆç«¯æ‰§è¡Œçš„æŸä¸ªç¨‹åºè€—æ—¶å¤šä¹…ï¼Œå¯¹CPUç­‰çš„ä½¿ç”¨æƒ…å†µï¼Œå¯ä»¥è¾“å…¥ï¼štime python fib.pyè¾“å‡ºç»“æœï¼špython fib.py 0.02s user 0.02s system 50% cpu 0.094 totalMacä¸‹çš„å¿«é€Ÿç¿»è¯‘OS Xæä¾›äº†ä¸‰æŒ‡è½»æ‹æŸ¥æ‰¾çš„åŠŸèƒ½ï¼Œä»€ä¹ˆæ„æ€å‘¢ï¼ŸæŠŠå…‰æ ‡ç§»åˆ°ä¸€ä¸ªå•è¯ä¸Šé¢ï¼Œæ— éœ€é€‰ä¸­ï¼Œä¸‰æŒ‡è½»æ‹ï¼Œç³»ç»Ÿå°±ä¼šå¼¹å‡ºè¯å…¸æ˜¾ç¤ºç›¸å…³å•è¯çš„é‡Šä¹‰ï¼Œéå¸¸æ–¹ä¾¿ã€‚è¯¥åŠŸèƒ½å¯ä»¥åœ¨ç³»ç»Ÿåå¥½è®¾ç½®-è§¦æ§æ¿é‡Œè¿›è¡Œè®¾ç½®ã€‚" }, { "title": "The rename command", "url": "/posts/linux-rename-cmd/", "categories": "Linux", "tags": "command", "date": "2015-12-22 17:23:00 +0800", "snippet": "Linux ä¸­ rename å‘½ä»¤å¯ä»¥å¯¹ç›®å½•æˆ–æ–‡ä»¶è¿›è¡Œæ”¹åï¼ŒSqoopä¼šæŠŠå·²ç»å®Œæˆä¼ è¾“çš„æ–‡ä»¶æ”¹ååŠ ä¸Š.COMPLETEDåç¼€æ¥åŒºåˆ†æ˜¯å¦éœ€è¦å¤„ç†ï¼Œå½“æˆ‘ä»¬åšBUGå¤ç°è°ƒè¯•æ—¶ï¼Œéœ€è¦å†æ¬¡ä¼ è¾“è¿™æ‰¹æ–‡ä»¶ï¼Œè¿™æ—¶å¯ä»¥ç”¨æ–‡ä»¶æ”¹åå»æ‰.COMPLETEDåç¼€çš„æ–¹å¼å®ç°ï¼Œç„¶è€Œä¸€ä¸ªä¸€ä¸ªæ–‡ä»¶æ”¹åæ•ˆç‡æ˜¾ç„¶å¤ªä½ï¼Œrenameå‘½ä»¤å¯ä»¥æ”¯æŒæ‰¹é‡æ”¹åå°†æ‰€æœ‰å­ç›®å½•ä¸­ç¬¦åˆ_2015-12-22_.log.COMPLETEDåç§°çš„æ–‡ä»¶åä¸­çš„.log.COMPLETEDæ”¹ä¸º.logå…ˆçœ‹çœ‹ç›®å½•ç»“æ„åŠæ–‡ä»¶åè§„å¾‹$ tree ././â”œâ”€â”€ task0001...â”‚Â Â  â”œâ”€â”€ 12398374_2015-12-21_37652.log.COMPLETEDâ”‚Â Â  â”œâ”€â”€ 12398374_2015-12-21_38273.log.COMPLETEDâ”‚Â Â  â”œâ”€â”€ 13627779_2015-12-22_41826.log.COMPLETEDâ”‚Â Â  â”œâ”€â”€ 13627778_2015-12-22_37652.log.COMPLETEDâ”‚Â Â  â”œâ”€â”€ 18028345_2015-12-22_38273.log.COMPLETEDâ”‚Â Â  â”œâ”€â”€ 18028345_2015-12-22_41826.log.COMPLETED...â”œâ”€â”€ task0002...â”‚Â Â  â”œâ”€â”€ 12398374_2015-12-21_37652.log.COMPLETEDâ”‚Â Â  â”œâ”€â”€ 12398374_2015-12-21_38273.log.COMPLETEDâ”‚Â Â  â”œâ”€â”€ 13627779_2015-12-22_41826.log.COMPLETEDâ”‚Â Â  â”œâ”€â”€ 13627778_2015-12-22_37652.log.COMPLETEDâ”‚Â Â  â”œâ”€â”€ 18028345_2015-12-22_38273.log.COMPLETEDâ”‚Â Â  â”œâ”€â”€ 18028345_2015-12-22_41826.log.COMPLETED...å¯ä»¥çœ‹åˆ°åŒä¸€å¤©çš„æ–‡ä»¶åˆ†åˆ°ä¸åŒæ–‡ä»¶å¤¹ï¼Œå¹¶ä¸”æ¯ä¸ªæ–‡ä»¶å¤¹éƒ½æœ‰å¤šå¤©çš„æ•°æ®ï¼Œæˆ‘åªéœ€è¦ä¿®æ”¹ä»Šå¤©çš„æ•°æ®è®©Sqoopé‡å‘ä»Šå¤©çš„æ—¥å¿—å³å¯ï¼Œå› æ­¤å‘½ä»¤è¡Œéœ€è¦è¿›è¡Œä¸€äº›åŒ¹é…è¿‡æ»¤æ‰§è¡Œæ”¹åå‘½ä»¤$ rename .log.COMPLETED .log */*_2015-12-22_*.log.COMPLETEDsuccessful!æŸ¥çœ‹ä¸€ä¸‹æ–‡ä»¶åæ˜¯å¦æ›´æ”¹æ­£ç¡®$ tree ././â”œâ”€â”€ task0001...â”‚Â Â  â”œâ”€â”€ 12398374_2015-12-21_37652.log.COMPLETEDâ”‚Â Â  â”œâ”€â”€ 12398374_2015-12-21_38273.log.COMPLETEDâ”‚Â Â  â”œâ”€â”€ 13627779_2015-12-22_41826.logâ”‚Â Â  â”œâ”€â”€ 13627778_2015-12-22_37652.logâ”‚Â Â  â”œâ”€â”€ 18028345_2015-12-22_38273.logâ”‚Â Â  â”œâ”€â”€ 18028345_2015-12-22_41826.log...â”œâ”€â”€ task0002...â”‚Â Â  â”œâ”€â”€ 12398374_2015-12-21_37652.log.COMPLETEDâ”‚Â Â  â”œâ”€â”€ 12398374_2015-12-21_38273.log.COMPLETEDâ”‚Â Â  â”œâ”€â”€ 13627779_2015-12-22_41826.logâ”‚Â Â  â”œâ”€â”€ 13627778_2015-12-22_37652.logâ”‚Â Â  â”œâ”€â”€ 18028345_2015-12-22_38273.logâ”‚Â Â  â”œâ”€â”€ 18028345_2015-12-22_41826.log...æ‰§è¡ŒæˆåŠŸï¼" }, { "title": "linuxå‘½ä»¤è¡Œæ¨¡å¼å¸¸ç”¨å¿«æ·é”®", "url": "/posts/linux-edit-cmd/", "categories": "Linux", "tags": "command", "date": "2015-12-17 10:43:00 +0800", "snippet": "linuxå‘½ä»¤è¡Œæ¨¡å¼å¸¸ç”¨å¿«æ·é”®Ctrl + u å‰ªåˆ‡å…‰æ ‡å‰çš„å†…å®¹Ctrl + k å‰ªåˆ‡å…‰æ ‡åˆ°è¡Œæœ«çš„å†…å®¹Ctrl + v ç²˜è´´Ctrl + e ç§»åŠ¨å…‰æ ‡åˆ°è¡Œæœ«Ctrl + a ç§»åŠ¨å…‰æ ‡åˆ°è¡Œé¦–Alt + f è·³å‘ä¸‹ä¸€ä¸ªç©ºæ ¼Alt + b è·³å›ä¸Šä¸€ä¸ªç©ºæ ¼Alt + backspace åˆ é™¤å‰ä¸€ä¸ªå•è¯Ctrl + w&amp;lt;/kbc&amp;gt; å‰ªåˆ‡å…‰æ ‡å‰ä¸€ä¸ªå•è¯Shift + Insert å‘ç»ˆç«¯å†…ç²˜è´´æ–‡æœ¬" }, { "title": "Hive ä»»åŠ¡è°ƒä¼˜å‚æ•°", "url": "/posts/hive-task-performance/", "categories": "Big data, Hive", "tags": "performance", "date": "2015-10-23 13:40:00 +0800", "snippet": "æœ€è¿‘åœ¨åš Hive é›†ç¾¤æ­å»ºé…ç½®ï¼Œè®°å½•å¯¹ä»»åŠ¡æ‰§è¡Œæ€§èƒ½å½±å“è¾ƒå¤§çš„å‚æ•°#æ¯ä¸ªMapæœ€å¤§è¾“å…¥å¤§å°set mapred.max.split.size=256000000;#ä¸€ä¸ªèŠ‚ç‚¹ä¸Šsplitçš„è‡³å°‘çš„å¤§å° set mapred.min.split.size.per.node=100000000; #ä¸€ä¸ªäº¤æ¢æœºä¸‹splitçš„è‡³å°‘çš„å¤§å°set mapred.min.split.size.per.rack=100000000; #æ‰§è¡ŒMapå‰è¿›è¡Œå°æ–‡ä»¶åˆå¹¶set hive.input.format=org.apache.hadoop.hive.ql.io.CombineHiveInputFormat;#åœ¨Map-onlyçš„ä»»åŠ¡ç»“æŸæ—¶åˆå¹¶å°æ–‡ä»¶set hive.merge.mapfiles = true; #åœ¨Map-Reduceçš„ä»»åŠ¡ç»“æŸæ—¶åˆå¹¶å°æ–‡ä»¶set hive.merge.mapredfiles = true; #åˆå¹¶æ–‡ä»¶çš„å¤§å°set hive.merge.size.per.task = 256000000; #å½“è¾“å‡ºæ–‡ä»¶çš„å¹³å‡å¤§å°å°äºè¯¥å€¼æ—¶ï¼Œå¯åŠ¨ä¸€ä¸ªç‹¬ç«‹çš„map-reduceä»»åŠ¡è¿›è¡Œæ–‡ä»¶mergeset hive.merge.smallfiles.avgsize=16000000; " }, { "title": "ä¿®æ”¹macå¯åŠ¨å°(dock)", "url": "/posts/mac-dock/", "categories": "Mac, tip", "tags": "", "date": "2015-10-21 18:55:00 +0800", "snippet": "mac dockæ’åˆ—æ˜¯å›ºå®š4è¡Œ7åˆ—å¸ƒå±€ï¼Œåˆšå¼€å§‹ä½¿ç”¨æ²¡æ„Ÿè§‰æœ‰ä»€ä¹ˆä¸å¦¥ï¼Œåæ¥å®‰è£…åº”ç”¨å¤šäº†dockå˜æˆä¸¤é¡µï¼Œå¾ˆå¤šæ—¶é—´éœ€è¦åœ¨dockä¸­æ»‘åŠ¨ç¿»é¡µæ‰èƒ½æ‰¾åˆ°æ‰€éœ€åº”ç”¨ï¼Œè¿™æ—¶å€™å°±æƒ³ç€èƒ½ä¸èƒ½æ§åˆ¶docké¡µæ•°åœ¨ä¸¤é¡µï¼Œç¬¬ä¸€é¡µæ˜¾ç¤ºç³»ç»Ÿé»˜è®¤åº”ç”¨ï¼Œç¬¬äºŒé¡µæ˜¾ç¤ºè‡ªå·±å®‰è£…çš„åº”ç”¨ã€‚å°†å¤šä¸ªåº”ç”¨åˆå¹¶åˆ°å›¾æ ‡å¤¹æ˜¯ä¸€ä¸ªåŠæ³•ï¼Œä½†æ˜¯è¿™æ ·ä¸€æ¥éœ€è¦å¤šä¸€æ¬¡ç‚¹å‡»æ‰èƒ½è®¿é—®åº”ç”¨ï¼Œèƒ½ä¸èƒ½é€šè¿‡ä¿®æ”¹æ¯é¡µæ’åˆ—çš„å›¾æ ‡æ•°æ¥å®ç°å‘¢ï¼Œç»è¿‡ä¸€ç•ªæŸ¥æ‰¾ï¼Œæœç„¶æ˜¯æœ‰åŠæ³•å¯ä»¥å®ç°çš„ã€‚æ‰“å¼€Terminalï¼ˆç»ˆç«¯ï¼‰ï¼Œè¾“å…¥å¦‚ä¸‹å‘½ä»¤ä¿®æ”¹å›¾æ ‡åˆ—æ•°å’Œå›¾æ ‡è¡Œæ•°ä¿®æ”¹å›¾æ ‡åˆ—æ•°ï¼Œæœ€åçš„çš„æ•°å­—å³ä¸ºæƒ³è¦çš„åˆ—æ•°ï¼Œå¯ä»¥æŒ‰éœ€ä¿®æ”¹defaults write com.apple.dock springboard-columns -int 7ä¿®æ”¹å›¾æ ‡è¡Œæ•°ï¼Œæœ€åçš„æ•°å­—å³ä¸ºè¡Œæ•°ï¼Œå¯ä»¥æŒ‰éœ€ä¿®æ”¹defaults write com.apple.dock springboard-rows -int 5é‡ç½®å›¾æ ‡æ’åˆ—é¡ºåº (å¯é€‰æ“ä½œï¼Œä¼šå¯¼è‡´å›¾æ ‡æ’åˆ—é¡ºåºåŠåˆ†ç±»è¿˜åŸ)defaults write com.apple.dock ResetLaunchPad -bool TRUEé‡å¯Dockç”Ÿæ•ˆkillall Dockå¦‚æœæƒ³è¦æ¢å¤ç³»ç»Ÿé»˜è®¤è®¾ç½®ï¼Œå¯ä»¥æ‰§è¡Œå¦‚ä¸‹ä»£ç defaults write com.apple.dock springboard-columns Defaultdefaults write com.apple.dock springboard-rows Defaultdefaults write com.apple.dock ResetLaunchPad -bool TRUEkillall Dock" }, { "title": "SQL Joins", "url": "/posts/sql-join-img/", "categories": "Database, SQL Language", "tags": "develop, image", "date": "2015-09-17 21:09:00 +0800", "snippet": "SQL ä¸­çš„ joins å…³è”ï¼Œç”¨ä¸€å¼ å›¾æ¥è¯´æ˜ç™½" }, { "title": "ERP Web2 BigData", "url": "/posts/erp-web2-bigdata/", "categories": "Big data", "tags": "develop, image", "date": "2015-09-17 21:09:00 +0800", "snippet": "ERP Web2 BigData å¯¹æ¯”å›¾" }, { "title": "macç³»ç»Ÿç‰¹æ®Šç¬¦å·è¾“å…¥", "url": "/posts/mac-symbol/", "categories": "Mac, tip", "tags": "", "date": "2015-08-10 20:55:00 +0800", "snippet": " OS Xä¸‹çš„ç‰¹æ®Šå­—ç¬¦è¾“å…¥æœ‰å¾ˆå¤šå¿«æ·é”® å¹¶ä¸”ä¸ç”¨ä¾èµ–ç¬¬ä¸‰æ–¹è¾“å…¥æ³• ç›´æ¥å¯ç”¨éå¸¸æ–¹ä¾¿ è¯´æ˜ å¿«æ·é”® å­—ç¬¦ ç¾å…ƒ Shift + 4 $ ç¾åˆ† Option + 4 Â¢ è‹±é•‘ Option + 3 Â£ äººæ°‘å¸ Option + y Â¥ æ¬§å…ƒ Shift + Option + 2 â‚¬ æ³¢æŠ˜å· Option + - æˆ– Shift + Option + - â€“ â€” çœç•¥å· Option + ; â€¦ çº¦ç­‰äº Option + x â‰ˆ åº¦ Shift + Option + 8 â€¢ é™¤å· Option + / Ã· æ— ç©·å¤§ Option + 5 âˆ å°äºç­‰äº Option + , â‰¤ å¤§äºç­‰äº Option + . â‰¥ ä¸ç­‰äº Option + = â‰  æ­£è´Ÿ Shift + Option + = Â± åœ†å‘¨ç‡Pi Option + p Ï€ å¹³æ–¹æ ¹ Option + v âˆš æ€»å’Œ Option + w âˆ‘ å•†æ ‡Trademark Option + 2 â„¢ æ³¨å†Œ Option + r Â® ç‰ˆæƒ Option + g Â© " }, { "title": "Hadoop Yarn Basis", "url": "/posts/hadoop-yarn-basis/", "categories": "Big data, Hadoop", "tags": "architecture", "date": "2015-07-21 00:00:00 +0800", "snippet": "Hadoop åŒ…å«ä¸‰å¤§ç»„ä»¶åˆ†åˆ«æ˜¯ï¼šHDFSï¼ˆåˆ†å¸ƒå¼æ–‡ä»¶ç³»ç»Ÿï¼‰ã€MRï¼ˆåˆ†å¸ƒå¼è®¡ç®—å¼•æ“ï¼‰ã€YARNï¼ˆåˆ†å¸ƒå¼èµ„æºç®¡ç†ï¼‰YARN to be continueâ€¦" }, { "title": "Hadoop MR Basis", "url": "/posts/hadoop-mr-basis/", "categories": "Big data, Hadoop", "tags": "", "date": "2015-07-15 00:00:00 +0800", "snippet": "Hadoop åŒ…å«ä¸‰å¤§ç»„ä»¶åˆ†åˆ«æ˜¯ï¼šHDFSï¼ˆåˆ†å¸ƒå¼æ–‡ä»¶ç³»ç»Ÿï¼‰ã€MRï¼ˆåˆ†å¸ƒå¼è®¡ç®—å¼•æ“ï¼‰ã€YARNï¼ˆåˆ†å¸ƒå¼èµ„æºç®¡ç†ï¼‰MR (MapReduce)MRæ˜¯Hadoopä¸­çš„è®¡ç®—æ¨¡å‹ï¼Œä¸»è¦ç”±ä¸‰ä¸ªé˜¶æ®µç»„æˆï¼šMap &amp;gt; shuffle &amp;gt; Reduceã€‚Mapé˜¶æ®µæ˜¯å¯¹æ•°æ®è¿›è¡Œæ‹†åˆ†(split)ï¼Œå°†æ•°æ®è½¬åŒ–ä¸ºé”®å€¼å¯¹ï¼›Reduceæ˜¯åˆå¹¶ï¼Œå°†å…·æœ‰ç›¸åŒçš„Keyçš„Valueè¿›è¡Œèšåˆï¼Œæœ€ç»ˆè¾“å‡ºå…¨éƒ¨èšåˆä¹‹åçš„ç»“æœã€‚shuffleé˜¶æ®µåŒ…å«Map shuffleå’ŒReduce shuffleã€‚Map shuffleå³æ˜¯åœ¨Mapç«¯çš„shuffleï¼ŒReduce shffleå³æ˜¯åœ¨Reduceç«¯çš„shuffleï¼Œæˆ‘ä»¬åœ¨ç¼–å†™MRç¨‹åºæ—¶ï¼Œåªéœ€è¦ç¼–å†™Mapé€»è¾‘ä»£ç å’ŒReduceé€»è¾‘ä»£ç ï¼Œshuffleæ˜¯ç”±ç³»ç»Ÿè‡ªåŠ¨å®ç°ã€‚Map shuffle å¯¹ Mapæ‹†åˆ†å¥½çš„é”®å€¼å¯¹è¿›è¡Œåˆ†åŒºï¼Œå°†åŒä¸€åˆ†åŒºçš„æ•°æ®è¿›è¡Œèšåˆã€æ’åºï¼Œå¾—åˆ°çš„ç»“æœæŒ‰ç…§ä¸€ä¸ªåˆ†åŒºä¸€ä¸ªæ–‡ä»¶å†™å…¥ç£ç›˜ã€‚Reduce shuffle è¯»å– Map shuffleå†™å¥½çš„åˆ†åŒºæ–‡ä»¶ï¼Œå°†å¤šä¸ªåˆ†åŒºæ–‡ä»¶æŒ‰ç…§ç›¸åŒ key å€¼è¿›è¡Œèšåˆï¼Œå½¢æˆä¸€ä¸ªä¸ªé”®å€¼å¯¹ï¼Œæ‰€ä¸åŒçš„æ˜¯è¿™æ¬¡çš„å€¼å…¶å®æ˜¯å¤šä¸ªå€¼ç»„æˆçš„æ•°ç»„ã€‚è¿™äº›ç»“æœå°†åšä¸ºReduceé˜¶æ®µçš„è¾“å…¥å‚æ•°è¿›è¡Œå¤„ç†ã€‚" }, { "title": "Hadoop HDFS Basis", "url": "/posts/hadoop-hdfs-basis/", "categories": "Big data, Hadoop", "tags": "architecture", "date": "2015-07-11 00:00:00 +0800", "snippet": "Hadoop åŒ…å«ä¸‰å¤§ç»„ä»¶åˆ†åˆ«æ˜¯ï¼šHDFSï¼ˆåˆ†å¸ƒå¼æ–‡ä»¶ç³»ç»Ÿï¼‰ã€MRï¼ˆåˆ†å¸ƒå¼è®¡ç®—å¼•æ“ï¼‰ã€YARNï¼ˆåˆ†å¸ƒå¼èµ„æºç®¡ç†ï¼‰HDFSHDFSï¼ˆHadoop Distributed File Systemï¼‰ï¼Œåä¸ºHadoopåˆ†å¸ƒå¼æ–‡ä»¶ç³»ç»Ÿï¼Œå…·æœ‰é«˜å®¹é”™ã€é«˜ååé‡ã€å®¹æ˜“æ‰©å±•ã€é«˜å¯é æ€§ çš„ç‰¹å¾ï¼Œæ˜¯Hadoopç”Ÿæ€é‡è¦çš„å­˜å‚¨ç³»ç»Ÿã€‚HDFSæ˜¯ä¸»ä»ç»“æ„çš„åˆ†å¸ƒå¼ç³»ç»Ÿï¼Œä¸€ä¸ªå…¸å‹çš„HDFSç³»ç»ŸåŒ…å«ä¸€ä¸ªNamenodeå’Œå‡ ä¸ªDatanodeç»„æˆï¼Œç”¨æˆ·é€šè¿‡Clientå’Œç›¸åº”çš„é…ç½®åŒNamenodeå’ŒDatanodeäº¤äº’è®¿é—®æ–‡ä»¶ç³»ç»Ÿ.HDFSä»¥æ•°æ®å—ä¸ºåŸºæœ¬å­˜å‚¨å•ä½ï¼Œä¸€ä¸ªæ•°æ®å—çš„é»˜è®¤å¤§å°ver1.xä¸º64mï¼Œver2.xä¸º128mï¼Œver3.xä¸º256mï¼Œå†™å…¥HDFSçš„æ–‡ä»¶åœ¨å†™æ»¡ä¸€ä¸ªæ•°æ®å—åå†å†™ä¸‹ä¸€ä¸ªæ•°æ®å—ï¼ŒNamenodeNamenodeä¿å­˜å‘½åç©ºé—´ä¿¡æ¯ï¼ŒåŒ…å«äº†ç³»ç»Ÿçš„æ–‡ä»¶ç›®å½•æ ‘ã€æ–‡ä»¶/ç›®å½•ä¿¡æ¯ä»¥åŠæ–‡ä»¶çš„æ•°æ®å—ç´¢å¼•ã€‚åŒæ—¶è¿˜ä¿å­˜æœ‰æ•°æ®å—ä¸æ•°æ®èŠ‚ç‚¹çš„å¯¹åº”å…³ç³»ï¼Œè¿™éƒ¨åˆ†ä½¿ç”¨æ—¶å¸¸é©»å†…å­˜ä¸­ï¼Œç”±å¯åŠ¨æ—¶åŠ¨æ€æ„å»ºï¼Œä¸ºé¿å…å…³æœºæ–­ç”µåçš„æ•°æ®ä¸¢å¤±åœ¨ç£ç›˜ä¸Šè‚¯å®šä¹Ÿæœ‰å­˜å‚¨ï¼Œè¿™å°±æ˜¯ä¸¤ä¸ªé‡è¦æ–‡ä»¶fsimageåŠeditlogã€‚Namenodeæ”¯æŒHAï¼Œæ­¤æ—¶å…±ä¸¤ä¸ªèŠ‚ç‚¹ï¼Œä¸€ä¸ªæ˜¯Active Namenodeï¼Œä¸€ä¸ªæ˜¯Standby Namenodeã€‚Active Namenodeè´Ÿè´£å¤„ç†HDFSç³»ç»Ÿçš„æ‰€æœ‰å®¢æˆ·ç«¯è¯·æ±‚ï¼Œè¯»å†™å“åº”ã€ä¸Datanodeé€šè®¯ç­‰ã€‚Standby Namenodeä¼šå®æ—¶åŒæ­¥(é€šè¿‡JournalNode)Active Namenodeçš„å‘½åç©ºé—´æ•°æ®ï¼Œä¿æŒä¸Standby Namenodeä¸€è‡´ï¼Œä¸€ä½†å‘ç° Active Namenodeå‡ºç°æ•…éšœï¼ŒStandby Namenodeä¼šå‡çº§æˆActive Namenodeä¿éšœé›†ç¾¤åŠŸèƒ½æ­£å¸¸è¿è¡Œã€‚fsimage &amp;amp; editlogfsimageä¿å­˜æˆªæ­¢æŸä¸ªæ—¶åˆ»çš„å…¨é‡å‘½åç©ºé—´çš„æ•°æ®ä¿¡æ¯ï¼Œè€Œeditlogä¿å­˜æ­¤æ—¶åˆ»ä¹‹åä¸€ç³»åˆ—å˜æ›´å’Œä¿®æ”¹ï¼Œå°†ä¸¤è€…åˆå¹¶å°±å¯ä»¥å¾—åˆ°æˆªæ­¢å½“å‰æ—¶åˆ»çš„å‘½åç©ºé—´æœ€ç»ˆçŠ¶æ€ã€‚fsimageç›¸å½“äºå…¨é‡æ•°æ®ï¼Œä¿å­˜çš„æ˜¯æœ€ç»ˆçŠ¶æ€ï¼Œeditlogç›¸å½“äºæ˜¯æµæ°´æ•°æ®ä¿å­˜äº†è¿‡ç¨‹çŠ¶æ€ï¼Œå¯çŸ¥editlogæ–‡ä»¶å¤§å°æ˜¯éšç€ç³»ç»Ÿä½¿ç”¨æ—¶é—´ä¸æ–­å¢é•¿çš„ï¼Œä¸ºäº†é¿å…æ–‡ä»¶è¿‡å¤§å¿…é¡»åœ¨ä¸€ä¸ªå‘¨æœŸåå°†editlogé‡Œçš„è®°å½•ä¸fsimageè¿›è¡Œåˆå¹¶ï¼Œæ–°æˆä¸€ä¸ªæ–°çš„fsimageæ–‡ä»¶ã€‚åœ¨éHAæ¶æ„ä¸­fsimageå’Œeditlogæ–‡ä»¶çš„åˆå¹¶ç”±Namenodeå®Œæˆï¼Œåœ¨HAæ¶æ„ä¸­åˆå¹¶æ“ä½œå¯ç”±å¤‡ä»½èŠ‚ç‚¹å®Œæˆï¼Œå¤‡ä»½èŠ‚ç‚¹åœ¨è¿è¡Œæ—¶ä¸æ–­åŒæ­¥editlogæ–‡ä»¶è®°å½•(JournalNodeæœºåˆ¶)ï¼Œåœ¨åˆé€‚çš„æ—¶é—´è¿›è¡Œfsimageå’Œeditlogæ–‡ä»¶çš„åˆå¹¶ï¼Œç„¶åå°†åˆå¹¶åçš„fsimageåŒæ­¥ç»™æ´»åŠ¨èŠ‚ç‚¹ï¼Œæ´»åŠ¨èŠ‚ç‚¹æ£€éªŒåæ›¿æ¢æ—§çš„fsimageæ–‡ä»¶å¹¶è¿›è¡ŒåŠ è½½ï¼Œæ´»åŠ¨èŠ‚ç‚¹çš„å·¥ä½œæ›´è½»æ¾ã€ç³»ç»Ÿè¿è¡Œæ›´é¡ºç•…äº†ã€‚JournalNodeJournalNodeæ˜¯åœ¨é›†ç¾¤ä¸­å¯åŠ¨çš„é€»è¾‘èŠ‚ç‚¹ï¼Œé€šå¸¸æ˜¯åœ¨æŸäº›Datanodeä¸Šå¯åŠ¨çš„è¿›ç¨‹ï¼ŒJournalNodeç›®çš„æ˜¯ä¸ºäº†è®©Standby Namenodeä¸Active Namenodeä¿æŒåŒæ­¥ï¼ŒActive Namenodeå¯¹å‘½åç©ºé—´æ‰€åšçš„ä¿®æ”¹ä¼šæŒä¹…åŒ–åˆ°editlogæ–‡ä»¶å½“ä¸­ï¼Œè€Œæ–‡ä»¶å¿…é¡»è¦åŒæ­¥åˆ°N-(N-1)/2ä¸ªJournalNodeèŠ‚ç‚¹æ‰èƒ½ä¿è¯å®‰å…¨æ€§ï¼Œæ¢è¨€ä¹‹é›†ç¾¤æœ‰3ä¸ªJournalNodeæœ€å¤šå……è®¸1ä¸ªæŒ‚æ‰ï¼Œæœ‰5ä¸ªJournalNodeæœ€å¤šå……è®¸2ä¸ªæŒ‚æ‰ï¼Œä¸€ä½†Active Namenodeå‡ºç°æ•…éšœï¼ŒStandby Namenodeå¯ä»¥ä»JournalNodeä¸­è¯»å–å…¨éƒ¨editlogï¼Œåˆ‡æ¢åˆ°Activeï¼Œä¿éšœå®‰å…¨çš„æ•…éšœè½¬ç§»ã€‚DatanodeDatanodeä¸»è¦åŠŸèƒ½æ˜¯è´Ÿè´£æ–‡ä»¶è¯»å†™ï¼Œä¼šæŒ‰ç…§ä¸€å®šé—´éš”å‘Namenodeå‘é€å¿ƒè·³ã€æ•°æ®å—æ±‡æŠ¥ä»¥åŠç¼“å­˜æ±‡æŠ¥ï¼›Namenodeåˆ™ä¼šå“åº”å¿ƒè·³åŒ…ï¼Œå“åº”ä¸­æœ‰å¯èƒ½å¸¦æœ‰åˆ›å»ºæ–‡ä»¶ã€åˆ é™¤æ–‡ä»¶æˆ–è€…å¤åˆ¶æ–‡ä»¶çš„å‘½ä»¤ã€‚å†™æ–‡ä»¶ç®€ç•¥æµç¨‹ è°ƒç”¨Clientçš„APIåˆ›å»ºæ–‡ä»¶å‡†å¤‡å¼€å§‹å†™æ–‡ä»¶ Clinetå‘Namenodeå‘é€è¯·æ±‚åˆ›å»ºæ–‡ä»¶ Namenodeé¦–å…ˆå¯¹è¯·æ±‚è¿›è¡Œåˆæ³•æ€§éªŒè¯ Namenodeæ ¹æ®æœ€æ–°çš„DatanodeçŠ¶æ€ä¿¡æ¯ï¼ˆç½‘ç»œå»¶æ—¶ã€è´Ÿè½½ã€å¯ç”¨ç£ç›˜ç©ºé—´ï¼‰ç­‰ä¿¡æ¯ï¼Œç»™Clientè¿”å›åˆ›å»ºçš„æ–‡ä»¶IDåŠæ‰€åœ¨èŠ‚ç‚¹ã€æ•°æ®å—ç´¢å¼•ç­‰ä¿¡æ¯ clienté€šè¿‡è¿”å›ä¿¡æ¯å»ºç«‹ä¸Datanodeçš„é€šè®¯ æˆåŠŸåClinetä¸Datanodeå»ºç«‹æµå¼é€šé“å¹¶å¼€å§‹å†™å…¥æ–‡ä»¶æ•°æ® å†™å…¥å®ŒæˆåClientå…³é—­ä¸Datanodeçš„ç½‘ç»œé“¾æ¥ DatanodeæŒ‰ç…§å¤åˆ¶ç­–ç•¥å°†åˆšåˆšå†™å…¥çš„æ–‡ä»¶å¤åˆ¶åˆ°å¦å¤–ä¸¤ä¸ªèŠ‚ç‚¹ï¼ˆé»˜è®¤2å‰¯æœ¬ï¼‰è¯»æ–‡ä»¶ç®€ç•¥æµç¨‹ è°ƒç”¨Clientçš„APiå‡†å¤‡å¼€å§‹è¯»æ–‡ä»¶ Clientå‘Namenodeå‘é€è¯·æ±‚è¯»å–æ–‡ä»¶(HadoopRPC) NamenodeæŸ¥è¯¢å‘½ä»¤ç©ºé—´ï¼Œå¦‚æœæ²¡æœ‰æ‰¾åˆ°æ–‡ä»¶åˆ™è¿”å›å¼‚å¸¸ï¼Œå¦‚æœæ‰¾åˆ°æ–‡ä»¶åˆ™æ ¹æ® æ–‡ä»¶ &amp;gt; æ•°æ®å— &amp;gt; Datanode çš„ç´¢å¼•å°†æ•°æ®è¿”å› Client ä¸ Datanode è¿›è¡Œç½‘ç»œé€šè®¯ ç½‘ç»œé€šè®¯æˆåŠŸåï¼ŒClient ä¸ Datanode å»ºç«‹æµå¼é€šé“è¯»å–æ–‡ä»¶æ•°æ® å®Œæˆåå…³é—­ Client ä¸ Datanode çš„æµå¼é€šé“ Datanode å°†æœ¬æ¬¡è®¿é—®æƒ…å†µè®°å½•å¹¶ä¸ŠæŠ¥Namenodeé«˜å®¹é”™æ€§Namenodeæ”¯æŒHAé™ä½å•ç‚¹æ•…éšœé£é™©ï¼Œæ–‡ä»¶3å‰¯æœ¬æœºåˆ¶ä¿éšœä¸ä¼šç”±äºä¸ªåˆ«DatanodeèŠ‚ç‚¹æ•…éšœå¯¼è‡´æ–‡ä»¶ä¸¢å¤±é«˜ååé‡æ–‡ä»¶è¯»å†™IOåœ¨Clientä¸Datanodeä¹‹é—´è¿›è¡Œï¼Œç”±äºDatanodeé€šå¸¸æœ‰å¤šä¸ªå¯ä»¥å‡æ‘Šè´Ÿè½½ï¼Œä¸€ä¸ªæ–‡ä»¶åˆ†ä¸ºå¤šä¸ªæ•°æ®å—ä¹Ÿå¯ä»¥æ”¯æŒå¹¶è¡Œè¯»å–ï¼Œæ–‡ä»¶æ•°æ®è¯»å†™åŸºäºæµå¼æ¥å£æ‰§è¡Œæœ‰åˆ©äºæ‰¹é‡æ•°æ®å¤„ç†åŒæ—¶æé«˜äº†ååé‡å®¹æ˜“æ‰©å±•Datanodeæ”¯æŒæ¨ªå‘æ‰©å±•ï¼Œç”±æ­¤å¢åŠ å­˜å‚¨èƒ½åŠ›ã€‚Namenodeå¯ä»¥é€šè¿‡åˆ‡æ¢åˆ°Sandbyçš„æ–¹å¼è°ƒæ•´èŠ‚ç‚¹ç¡¬ä»¶é…ç½®ã€‚é«˜å¯é æ€§Namenode å‘½åç©ºé—´æ•°æ®éƒ½å†™å…¥ç£ç›˜æ–‡ä»¶fsimageï¼Œå­˜å‚¨å…¨é‡çš„å‘½åç©ºé—´æ•°æ®ï¼Œeditlogä¿å­˜å‘½åç©ºé—´ä¿®æ”¹æ—¥å¿—ï¼Œæ¯é—´éš”ä¸€æ®µæ—¶é—´å¯¹ä¸¤ä¸ªæ–‡ä»¶è¿›è¡Œåˆå¹¶ï¼Œäº§ç”Ÿæ–°çš„fsimageæ–‡ä»¶ã€‚JournalNodeåˆ†å¸ƒå¼å¤šè¿›ç¨‹åŒæ­¥Active Namenodeçš„editlogæ—¥å¿—ï¼Œåœ¨æ•…éšœè½¬ç§»è¿‡ç¨‹ä¸­ç”±JournalNodeä¿éšœeditlogçš„å®Œå…¨åŒæ­¥ï¼Œä¿éšœNamenodeçš„æ•…éšœè½¬ç§»ã€‚Datanodeä¸­å­˜å‚¨çš„æ–‡ä»¶é»˜è®¤å­˜å‚¨å¦å¤–2ä¸ªå‰¯æœ¬åˆ°å…¶å®ƒDatanodeï¼Œä¿éšœæ–‡ä»¶æ•°æ®ä¸ä¼šç”±ä¸ªåˆ«Datanodeæ•…éšœè€Œä¸¢å¤±ã€‚ã€‚ç§Ÿçº¦ç®¡ç†HDFSæ–‡ä»¶æ˜¯write-once-read-manyï¼Œå› æ­¤ä¸æ”¯æŒå®¢æˆ·ç«¯çš„å¹¶è¡Œå†™æ“ä½œï¼Œé‚£ä¹ˆè¿™é‡Œå°±éœ€è¦ä¸€ç§æœºåˆ¶ä¿è¯å¯¹HDFSæ–‡ä»¶çš„äº’æ–¥æ“ä½œã€‚HDFSä½¿ç”¨ç§Ÿçº¦ï¼ˆleaseï¼‰æœºåˆ¶æ¥å®ç°è¿™ä¸ªåŠŸèƒ½ï¼Œç§Ÿçº¦å°±æ˜¯HDFSç³»ç»Ÿç»™Clientä¸€æ®µæ—¶é—´å†…å¯¹æŸæ–‡ä»¶çš„ç‹¬å é”å®šï¼Œå®¢æˆ·ç«¯åœ¨å®Œæˆå†™å…¥æ“ä½œå…³é—­æ–‡ä»¶æ—¶å³é‡Šæ”¾ç§Ÿçº¦ï¼Œå¦‚æœåœ¨ç§Ÿçº¦æœŸé™å†…æœªå®Œæˆæ“ä½œï¼Œåˆ™éœ€è¦è¿›è¡Œç»­çº¦ï¼Œå¦åˆ™ä¼šç”±HDFSæ”¶å›ç§Ÿçº¦ä»è€Œå†™å…¥å¤±è´¥ã€‚ ç§Ÿçº¦æœ‰è½¯é™åˆ¶ï¼ˆsoftLimitï¼‰å’Œç¡¬é™åˆ¶ï¼ˆhardLimitï¼‰ï¼Œè½¯é™åˆ¶ä¸ºé»˜è®¤60ç§’å¯ä»¥åœ¨é›†ç¾¤é…ç½®ä¸­è¿›è¡Œé…ç½®ï¼Œç¡¬é™åˆ¶ä¸º60åˆ†é’Ÿæ— æ³•æ›´æ”¹" }, { "title": "MySQLæ•°æ®å¤‡ä»½å‘½ä»¤mysqldump", "url": "/posts/mysqldump-cmd/", "categories": "Database, MySQL", "tags": "command", "date": "2015-06-11 14:48:00 +0800", "snippet": "MySQLæ•°æ®åº“æä¾›mysqldumpå‘½ä»¤è¿›è¡Œæ•°æ®å¤‡ä»½# å¤‡ä»½MySQLæ•°æ®åº“çš„å‘½ä»¤mysqldump -hhostname -uusername -ppassword databasename &amp;gt; backupfile.sql# å¤‡ä»½MySQLæ•°æ®åº“ä¸ºå¸¦åˆ é™¤è¡¨çš„æ ¼å¼ï¼Œèƒ½å¤Ÿè®©è¯¥å¤‡ä»½è¦†ç›–å·²æœ‰æ•°æ®åº“è€Œä¸éœ€è¦æ‰‹åŠ¨åˆ é™¤åŸæœ‰æ•°æ®åº“ã€‚mysqldump -â€“add-drop-table -uusername -ppassword databasename &amp;gt; backupfile.sql# ç›´æ¥å°†MySQLæ•°æ®åº“å‹ç¼©å¤‡ä»½mysqldump -hhostname -uusername -ppassword databasename | gzip &amp;gt; backupfile.sql.gz# å¤‡ä»½MySQLæ•°æ®åº“æŸä¸ª(äº›)è¡¨mysqldump -hhostname -uusername -ppassword databasename specific_table1 specific_table2 &amp;gt; backupfile.sql# åŒæ—¶å¤‡ä»½å¤šä¸ªMySQLæ•°æ®åº“mysqldump -hhostname -uusername -ppassword â€“databases databasename1 databasename2 databasename3 &amp;gt; multibackupfile.sql# ä»…ä»…å¤‡ä»½æ•°æ®åº“ç»“æ„mysqldump â€“no-data â€“databases databasename1 databasename2 databasename3 &amp;gt; structurebackupfile.sql# å¤‡ä»½æœåŠ¡å™¨ä¸Šæ‰€æœ‰æ•°æ®åº“mysqldump â€“all-databases &amp;gt; allbackupfile.sql# è¿˜åŸMySQLæ•°æ®åº“çš„å‘½ä»¤mysql -hhostname -uusername -ppassword databasename &amp;lt; backupfile.sql# è¿˜åŸå‹ç¼©çš„MySQLæ•°æ®åº“gunzip &amp;lt; backupfile.sql.gz | mysql -uusername -ppassword databasename# å°†æ•°æ®åº“è½¬ç§»åˆ°æ–°æœåŠ¡å™¨mysqldump -uusername -ppassword databasename | mysql â€“host=*.*.*.* -C databasename" }, { "title": "å®Œå…¨å¸è½½Inteliij IDEA", "url": "/posts/idea-uninstall/", "categories": "Mac, software", "tags": "idea", "date": "2015-06-09 13:22:00 +0800", "snippet": "åœ¨macç³»ç»Ÿä¸­å®‰è£…äº†ideaä¹‹åï¼Œå› ä¸ºå‡çº§æ›´æ¢ç‰ˆæœ¬ç­‰åŸå› éœ€è¦å¸è½½é‡è£…ï¼Œä½†æ˜¯å¦‚æœæ²¡æœ‰å¸è½½å¹²å‡€å®¹æ˜“å‡ºç°ä¸€äº›å¥‡æ€ªé—®é¢˜macç³»ç»Ÿæ ‡å‡†æ–¹å¼å¸è½½å°±æ˜¯åœ¨dockä¸­æŒ‰ç€åº”ç”¨å›¾æ ‡ä¸åŠ¨ï¼Œ3ç§’åå›¾æ ‡å·¦ä¸Šä¼šå‡ºç°ä¸€ä¸ª â€œXâ€ å·ï¼Œç‚¹å‡»å®ƒå°±å¯ä»¥åˆ é™¤è½¯ä»¶ï¼Œä½†æœ‰æ—¶å€™è¿™ä¸ª â€œXâ€ ä¸ä¼šå‡ºç°ï¼Œè¿™æ—¶å°±è¦ç¥­å‡º terminalå¤§æ³• äº†æ‰“å¼€ç»ˆç«¯ï¼Œè¾“å…¥å¦‚ä¸‹å‘½ä»¤cd /Applicationssudo rm -rf Inteliij\\ IDEA.appå½“åº”ç”¨åç§°åŒ…å«ç©ºæ ¼æ—¶ï¼Œå‘½ä»¤ä¸­éœ€è¦åœ¨ç©ºæ ¼é«˜åŠ ä¸Š \\ è¿›è¡Œè½¬ä¹‰å¤„ç†åº”ç”¨ä¸»ä½“åˆ é™¤åï¼Œå†åˆ é™¤åº”ç”¨è¿è¡Œæ—¶ç•™ä¸‹çš„é…ç½®ã€æ—¥å¿—ã€æ’ä»¶ç­‰å…¶å®ƒé—ç•™ç›®å½•ï¼Œç›®å½•ç”¨é€”å’Œè·¯å¾„è¯´æ˜å¦‚ä¸‹ï¼š Config: ~/Library/Preferences/IdeaIC13 System: ~/Library/Caches/IdeaIC13 Plugins: ~/Library/Application Support/IdeaIC13 Logs: ~/Library/Logs/IdeaIC13ä¸€å£æ°”å…¨éƒ¨åˆ é™¤rm -rf \\ ~/Library/Preferences/IdeaIC13\\ ~/Library/Caches/IdeaIC13\\ ~/Library/Application\\ Support/IdeaIC13\\ ~/Library/Logs/IdeaIC13" }, { "title": "vi vimä¸­çš„æ–‡æœ¬æ›¿æ¢", "url": "/posts/linux-vi-replace/", "categories": "Linux, vi/vim", "tags": "", "date": "2015-06-09 13:22:00 +0800", "snippet": "vi/vim æ˜¯Linuxä¸‹æ–‡ä»¶ç¼–è¾‘è½¯ä»¶ï¼Œå…¶ä¸­æ–‡æœ¬æ›¿æ¢åŠŸèƒ½ç»å¸¸ç”¨åˆ°ï¼Œå¦‚æœç†Ÿæ‚‰å¸¸ç”¨æ›¿æ¢å‘½ä»¤ï¼Œå·¥ä½œæ•ˆç‡å¤§å¹…æå‡# æ›¿æ¢å½“å‰è¡Œç¬¬ä¸€ä¸ª vivian ä¸º sky ï¼šs/vivian/sky/ # æ›¿æ¢å½“å‰è¡Œæ‰€æœ‰ vivian ä¸º sky ï¼šs/vivian/sky/g # æ›¿æ¢ç¬¬ n è¡Œå¼€å§‹åˆ°æœ€åä¸€è¡Œä¸­æ¯ä¸€è¡Œçš„ç¬¬ä¸€ä¸ª vivian ä¸º sky ï¼šnï¼Œ$s/vivian/sky/ # æ›¿æ¢ç¬¬ n è¡Œå¼€å§‹åˆ°æœ€åä¸€è¡Œä¸­æ¯ä¸€è¡Œæ‰€æœ‰ vivian ä¸º sky# n ä¸ºæ•°å­—ï¼Œè‹¥ n ä¸º .ï¼Œè¡¨ç¤ºä»å½“å‰è¡Œå¼€å§‹åˆ°æœ€åä¸€è¡Œ ï¼šnï¼Œ$s/vivian/sky/g # æ›¿æ¢æ¯ä¸€è¡Œçš„ç¬¬ä¸€ä¸ª vivian ä¸º skyï¼š%s/vivian/sky/ï¼ˆç­‰åŒäº ï¼šg/vivian/s//sky/ï¼‰ #ï¼ˆç­‰åŒäº ï¼šg/vivian/s//sky/gï¼‰ æ›¿æ¢æ¯ä¸€è¡Œä¸­æ‰€æœ‰ vivian ä¸º sky# å¯ä»¥ä½¿ç”¨ `#` ä½œä¸ºåˆ†éš”ç¬¦ï¼Œæ­¤æ—¶ä¸­é—´å‡ºç°çš„ / ä¸ä¼šä½œä¸ºåˆ†éš”ç¬¦ï¼š%s/vivian/sky/g# æ›¿æ¢å½“å‰è¡Œç¬¬ä¸€ä¸ª vivian/ ä¸º sky/ï¼šs#vivian/#sky/# #ï¼ˆä½¿ç”¨+ æ¥ æ›¿æ¢ / ï¼‰ï¼š /oradata/apras/æ›¿æ¢æˆ/user01/ï¼š%s+/oradata/apras/+/user01/apras1+apras1/ æœ¬ç¯‡ä¸­çš„æ›¿æ¢è¯­æ³•åŒæ ·é€‚ç”¨äºsedå‘½ä»¤å·¥å…·" }, { "title": "ä»Windowså¤åˆ¶åˆ°macçš„æ–‡æœ¬æ–‡ä»¶æ— æ³•æ‰“å¼€", "url": "/posts/mac-iconv-cmd/", "categories": "Mac, tip", "tags": "command", "date": "2015-05-28 11:02:00 +0800", "snippet": "ä»åŸæ¥çš„Windowsç³»ç»Ÿè¿ç§»è¿‡æ¥ä¸€äº›æ–‡æœ¬æ–‡ä»¶ï¼Œå‘ç°åœ¨macä¸Šæ‰“ä¸å¼€äº†ï¼Œä½†åœ¨Windowsä¸Šèƒ½æ­£å¸¸æ‰“å¼€ï¼Œåæ¥æŸ¥åˆ°åŸå› æ˜¯æ–‡ä»¶çš„ç¼–ç é—®é¢˜ï¼Œåœ¨ç®€ä½“ä¸­æ–‡ç¯å¢ƒä¸‹Windowsè®°äº‹æœ¬åˆ›å»ºçš„æ–‡æœ¬æ–‡ä»¶é»˜è®¤ä¸ºGBKç¼–ç ï¼Œmacä¸Šé»˜è®¤æ‰“å¼€ç¼–ç åˆ™ä¸ºUTF-8ï¼Œç”±äºç¼–ç ä¸æ­£ç¡®macä¼šç›´æ¥æç¤ºæ— æ³•æ‰“å¼€ã€‚è§£å†³åŠæ³•æœ‰ä¸¤ç§ï¼š åœ¨macä¸Šä¸è¦ç›´æ¥åŒå‡»æ–‡ä»¶æ‰“å¼€ï¼Œè€Œæ˜¯å…ˆåœ¨dockä¸­æˆ–è€…finderçš„åº”ç”¨ç¨‹åºä¸­æ‰“å¼€æ–‡æœ¬ç¼–è¾‘å™¨ï¼Œåœ¨åº”ç”¨å¼¹å‡ºçš„æ–‡ä»¶çª—å£ä¸­é€‰ä¸­è¦æ‰“å¼€çš„æ–‡ä»¶ï¼Œå¹¶ä¸”ç‚¹å‡»ä¸‹æ–¹çš„é€‰é¡¹æŒ‰é’®å¹¶åœ¨çº¯æ–‡æœ¬ç¼–ç :ä¸€æ é€‰æ‹©ä¸­æ–‡(GB 18030) ä½¿ç”¨macç³»ç»Ÿè‡ªå¸¦å‘½ä»¤iconvå°†æ–‡ä»¶è½¬ç ä¸ºUTF-8ç¼–ç ï¼Œä»¥åå°±å¯ä»¥ç›´æ¥æ‰“å¼€è¯¥æ–‡ä»¶äº†iconv è½¬æ¢å‘½ä»¤iconv -f GBK -t UTF-8 gbk.txt &amp;gt; utf8.txt-få‚æ•°åæ˜¯åŸæ–‡ä»¶ç¼–ç ï¼Œ-tå‚æ•°åæ˜¯è½¬æ¢åçš„ç¼–ç ï¼Œæ‰§è¡Œåå¾—åˆ°çš„å°±æ˜¯å¯ä»¥ç›´æ¥æ­£å¸¸æ‰“å¼€çš„æ–‡æœ¬æ–‡ä»¶äº†æƒ³çŸ¥é“iconvå‘½ä»¤æ”¯æŒå“ªäº›ç¼–ç æ ¼å¼ï¼Œå¯ä»¥æ‰§è¡Œä¸‹é¢å‘½ä»¤iconv -l æœ¬æ–‡é’ˆå¯¹Windows 7åŠæ›´æ—©ç‰ˆæœ¬çš„Windowsç³»ç»Ÿï¼ŒWindows 10åŠå…¶ä¹‹åç‰ˆæœ¬ä¿®æ”¹äº†é»˜è®¤å­˜å‚¨ç¼–ç ä¸ºUTF-8ï¼Œç»“æŸäº†ä¸€ç›´ä»¥æ¥çš„ç¼–ç é—®é¢˜" }, { "title": "Mysql Initializing", "url": "/posts/MySQL-initializing/", "categories": "Database, MySQL", "tags": "", "date": "2015-05-27 00:00:00 +0800", "snippet": "MySQL æ•°æ®åº“å®‰è£…å¥½ä»¥åï¼Œä½¿ç”¨å‰éœ€è¦å¯¹æ•°æ®åº“åˆå§‹åŒ–ï¼Œæ¯”å¦‚åˆ›å»ºåº“è¡¨ã€åˆ›å»ºç”¨æˆ·ã€æˆæƒç­‰ï¼Œä¸‹é¢å†™ä¸€ä¸ªå…¸å‹å»ºåº“ã€å»ºè¡¨ã€å»ºç”¨æˆ·çš„æµç¨‹åˆ›å»ºæ–°çš„æ•°æ®åº“å¹¶æˆæƒ-- åˆ›å»ºæ•°æ®åº“å¹¶æŒ‡å®šå­—ç¬¦é›†utf8mb4create database if not exists ohemin default charset utf8mb4 collate utf8mb4_general_ci;-- åˆ›å»ºæ•°æ®åº“ç”¨æˆ·å¹¶æŒ‡å®šå¯†ç create user &#39;devuser&#39;@&#39;localhost&#39; identified by password(&#39;123456&#39;);-- æŸ¥è¯¢ç”¨æˆ·select user,host from mysql.user;-- åˆ é™¤ç”¨æˆ·drop user devuser@localhost;drop user devuser@&#39;%&#39;;-- æ›´æ”¹å¯†ç æ–¹æ³•1, å¯†ç å®æ—¶æ›´æ–°;set password for test = password(&#39;123456&#39;);-- æ›´æ”¹å¯†ç æ–¹æ³•2, éœ€è¦åˆ·æ–°;update mysql.user set password=password(&#39;123456&#39;) where user=&#39;test&#39;;flush privileges; å»ºåº“å­—ç¬¦é›†å¯ä»¥é€‰æ‹©utf8æˆ–è€…utf8mb4ï¼Œå®ƒä»¬çš„åŒºåˆ«åœ¨äºutf8mb4å¯ä»¥åœ¨è®°å½•å€¼ä¸­æ­£ç¡®æ”¯æŒæ“ä½œç³»ç»Ÿæˆ–è€…ç¤¾äº¤è½¯ä»¶çš„è¡¨æƒ…ç¬¦å·ï¼Œè€Œutf8åˆ™ä¼šå‡ºç°é”™è¯¯ã€‚å¥½æ¶ˆæ¯æ˜¯é«˜ç‰ˆæœ¬çš„MySQLå·²ç»å°†è¿™ä¸¤ä¸ªå­—ç¬¦é›†åˆå¹¶ï¼Œæ— è®ºé€‰æ‹©utf8æˆ–è€…utf8mb4éƒ½å¯ä»¥æ­£å¸¸ä½¿ç”¨è¡¨æƒ…ç¬¦å·. collate utf8mb4_general_ci æ˜¯æ•°æ®åº“æ ¡å¯¹è§„åˆ™ï¼Œciæ˜¯case insensitiveç¼©å†™ï¼Œè¡¨ç¤ºå¤§å°ä¸æ•æ„Ÿï¼Œåœ¨ä½¿ç”¨ä¸Šå»ºè¡¨è¯­å¥æˆ–è€…æŸ¥è¯¢ä¸­çš„å¤§å†™è¡¨åæˆ–å­—æ®µåå‡è½¬ä¸ºå°å†™ï¼›å¦‚æœæƒ³ä½¿ç”¨åŸºäºOracleæ•°æ®åº“åŒºåˆ†å¤§å°å†™çš„è§„åˆ™å¯ç”¨ collate utf8mb4_general_csï¼Œcså³case sensitiveç¼©å†™ï¼Œè¡¨ç¤ºå¤§å°å†™æ•æ„Ÿã€‚ç”¨æˆ·åˆ†é…æƒé™-- æˆäºˆç”¨æˆ·devuseré€šè¿‡å¤–ç½‘IPå¯¹æ•°æ®åº“&#39;os&#39;çš„å…¨éƒ¨æƒé™grant all privileges on os.* to &#39;devuser&#39;@&#39;%&#39; identified by &#39;devuser123&#39;;-- æˆäºˆç”¨æˆ·devuseré€šè¿‡ä»»æ„På¯¹äºæ•°æ®åº“osä¸­è¡¨çš„åˆ›å»º\\ä¿®æ”¹\\åˆ é™¤æƒé™ ,ä»¥åŠè¡¨æ•°æ®çš„å¢åˆ æ”¹æŸ¥æƒé™ grant create,alter,drop,select,insert,update,delete on happyos.* to happyos@&#39;%&#39;;-- åˆ·æ–°æƒé™flush privileges;" }, { "title": "macä¸­å®‰è£…MySQLæ•°æ®åº“", "url": "/posts/mac-mysql-install/", "categories": "Database, MySQL", "tags": "develop, environment", "date": "2015-05-26 19:22:00 +0800", "snippet": "apache å·²ç»é…ç½®å¥½å¹¶å¯åŠ¨äº†ï¼Œä¸‹ä¸€æ­¥è¦å®‰è£…Javaå¼€å‘å¿…å¤‡æ•°æ®åº“ï¼ŒMySQLè¿™æ¬¡å®‰è£…æ¯”è¾ƒç®€å•ï¼Œå…ˆåˆ°å®˜ç½‘ä¸‹è½½å®‰è£…åŒ…ï¼š æµè§ˆå™¨æ‰“å¼€ https://dev.mysql.com/downloads/ åœ¨æ‰“å¼€çš„é¡µé¢ä¸­ç‚¹å‡» MySQL Community Serverï¼Œè¿™ä¸ªæ˜¯ç¤¾åŒºç‰ˆï¼Œå¼€å‘è€…å…è´¹ä½¿ç”¨ è¿›å…¥æ–°é¡µé¢åä¼šæœ‰ç³»ç»Ÿç‰ˆæœ¬ç­‰é€‰æ‹©ï¼Œæˆ‘ä»¬é€‰æ‹©è‡ªå·±å¯¹åº”æ“ä½œç³»ç»Ÿçš„ç‰ˆæœ¬ï¼Œç„¶åç‚¹å‡»DownloadæŒ‰é’®å¼€å§‹ä¸‹è½½ ä¸‹è½½å®Œæˆåæ–‡ä»¶ç±»ä¼¼mysql-5.7.23-xxx.dmgï¼Œç‚¹å‡»æ‰“å¼€ï¼Œåœ¨å¼¹å‡ºçš„çª—å£ä¸­ä»æ˜¾ç¤ºä¸€ä¸ªåç§°ç›¸ä¼¼ä½†æ–‡ä»¶åç¼€ä¸ºpkgçš„æ–‡ä»¶ï¼Œç»§ç»­åŒå‡»æ‰“å¼€ï¼Œä¼šå¯åŠ¨ä¸€ä¸ªå®‰è£…ç¨‹åºï¼Œä¸€è·¯nextå®Œæˆå®‰è£… å®‰è£…å®Œæˆåï¼Œä¼šåœ¨ç³»ç»Ÿåå¥½è®¾ç½®ä¸­ï¼Œæ–°å¢åŠ äº†ä¸€ä¸ªåä¸ºMySQLçš„å›¾æ ‡ï¼Œç‚¹å‡»è¿›å»åå¯ä»¥çœ‹åˆ°ä¸€ä¸ªStart MySQL ServeræŒ‰é’®ï¼Œå°±æ˜¯è¿™é‡Œå¯åŠ¨MySQLäº†ï¼Œä¸‹æ–¹è¿˜æœ‰ä¸€ä¸ªå¤é€‰æ¡†ï¼Œå¯ä»¥è®¾ç½®æ˜¯å¦åœ¨ç³»ç»Ÿå¯åŠ¨æ—¶è‡ªåŠ¨è¿è¡ŒMySQLæœåŠ¡ï¼Œå¯ä»¥è§†æƒ…å†µè‡ªå·±å†³å®šæ˜¯å¦è¦å‹¾é€‰ã€‚è‡³æ­¤å¼€å‘ç¯å¢ƒMySQLä¹Ÿå·²å®‰è£…å®Œæˆ" }, { "title": "ä½¿ç”¨macè‡ªå¸¦apacheæœåŠ¡", "url": "/posts/mac-apache-install/", "categories": "Mac, apache", "tags": "develop, environment", "date": "2015-05-25 09:22:00 +0800", "snippet": "mac ç³»ç»Ÿé€šå¸¸é»˜è®¤è‡ªå¸¦æœ‰Apache httpæœåŠ¡ï¼Œæˆ‘ä»¬è¦åšçš„å°±æ˜¯æŠŠå®ƒå¯åŠ¨ç®¡ç†apacheæœåŠ¡# å¯åŠ¨æœåŠ¡sudo apachectl start# åœæ­¢æœåŠ¡sudo apachectl stop# é‡å¯æœåŠ¡sudo apachectl restartç®¡ç†macå¯åŠ¨æœåŠ¡# apacheæœåŠ¡éšç³»ç»Ÿå¯åŠ¨launchctl load -w /System/Library/LaunchDaemons/org.apache.httpd.plist# éªŒè¯ä¸‹æ˜¯ä¸æ˜¯è®¾ç½®ä¸Šäº†launchctl list | grep httpd# åæ‚”äº†ï¼Œä¸æƒ³è®©æœåŠ¡è‡ªåŠ¨å¯åŠ¨launchctl unload -w /System/Library/LaunchDaemons/org.apache.httpd.plist# æŸ¥çœ‹æ‰€æœ‰çš„å¯åŠ¨æœåŠ¡launchctl list# ç¦ç”¨ä¸€ä¸ªå¯åŠ¨æœåŠ¡launchctl disable /System/Library/LaunchDaemons/org.apache.httpd.plist# å¯ç”¨ä¸€ä¸ªå¯åŠ¨æœåŠ¡launchctl enable /System/Library/LaunchDaemons/org.apache.httpd.plist# æ€æ­»å¯åŠ¨æœåŠ¡ï¼Œç”¨äºè§£å†³ä¸€äº›åœæ­¢å“åº”çš„æœåŠ¡launchctl disable /System/Library/LaunchDaemons/org.apache.httpd.plist# ç›´æ¥å¯åŠ¨launchctl start /System/Library/LaunchDaemons/org.apache.httpd.plist# ç›´æ¥åœæ­¢launchctl stop /System/Library/LaunchDaemons/org.apache.httpd.plistç¼–è¾‘apacheé…ç½®vi /etc/apache2/httpd.confå»ºå°†DocumentRootç›®å½•æ”¹æ‰# é»˜è®¤ç½‘é¡µæ–‡ä»¶åœ¨ /Library/WebServer/Documents ç®¡ç†èµ·æ¥ä¸æ–¹ä¾¿ï¼Œæ”¹ä¸ºæ›´æ–¹ä¾¿ç®¡ç†çš„ç›®å½•# Macç‰ˆå‘½ä»¤ï¼Œç¬¬1ä¸ªå‚æ•°ä¸ºç©ºå­—ç¬¦ä¸²ï¼Œæ„æ€æ˜¯åŸåœ°æ›¿æ¢ï¼Œå¦‚æœä¸ä¸ºç©ºåˆ™æ›¿æ¢å‰äº§ç”Ÿä¸€å¤„å¤‡ä»½æ–‡ä»¶ï¼Œå°†å‚æ•°ä¸­å­—ç¬¦æ·»åŠ åˆ°å¤‡ä»½æ–‡ä»¶æ‰©å±•ååsudo sed -i &#39;&#39; &#39;s/\\/Library\\/WebServer\\/Documents/\\/Users\\/[your name]\\/www/g&#39; &#39;/etc/apache2/httpd.conf&#39;# Linuxç‰ˆå‘½ä»¤sudo sed -i &#39;s/\\/Library\\/WebServer\\/Documents/\\/Users\\/[your name]\\/www/g&#39; &#39;/etc/apache2/httpd.conf&#39;" }, { "title": "å¼€ç¯‡", "url": "/posts/started/", "categories": "", "tags": "", "date": "2015-05-23 20:55:00 +0800", "snippet": "ç°åœ¨æ‰å¼€å§‹ç»´æŠ¤åšå®¢ä¸è§‰å¤ªæ™šå—ï¼Ÿä»äº‹è½¯ä»¶å¼€å‘å¤šå¹´ï¼Œæ‰å¼€å§‹ç»´æŠ¤è‡ªå·±çš„æŠ€æœ¯åšå®¢ï¼Œä¼¼ä¹æœ‰äº›æ™šã€‚å›æƒ³å½“åˆä¸ºä»€ä¹ˆæ²¡æœ‰ç»´æŠ¤åœ¨çº¿åšå®¢ï¼Œè‡ªå·±ç»™å‡ºçš„ç†ç”±æœ‰å¦‚ä¸‹ä¸¤ç‚¹: ä¸ªäººä¹ æƒ¯åŠå¯¹åšå®¢ç½‘ç«™çš„ä¸ä¿¡ä»» ç”±äºä¸ªäººå…¥è¡Œæ—¶äº’è”ç½‘åˆšåˆšå…´èµ·ï¼Œç½‘ç»œèµ„æ–™åŠä¸Šç½‘æ¡ä»¶è¿˜ä¸ä¼¼ä»Šå¤©è¿™èˆ¬å‘è¾¾ï¼Œä¹ æƒ¯äºåœ¨ä¸ªäººPCä¸Šç»´æŠ¤æ—¥è®°ã€æ–‡æ¡£ç­‰ã€‚åœ¨çº¿åšå®¢ç½‘ç«™åˆšåˆšå…´èµ·ï¼Œåšå®¢ç½‘ç«™å¦‚é›¨åæ˜¥ç¬‹ã€å±‚å‡ºä¸ç©·ã€‚ä½†æˆ‘æ„Ÿè§‰ç›ˆåˆ©æ¨¡å¼ä¸æ˜ï¼Œä»é•¿è¿œçœ‹ç»è¥æƒ…å†µä¸ç¨³å®šï¼Œä»€ä¹ˆæ—¶å€™å…³é—­ç½‘ç«™è°ä¹Ÿè¯´ä¸å‡†ï¼Œè€Œä¸”ä¸€ä½†ç½‘ç«™å…³é—­æ–‡ç« å†…å®¹ä¸¢å¤±æŸå¤±å·¨å¤§ã€‚ é€‰æ‹©å›°éš¾ é€‰æ‹©å“ªç§æ–¹å¼å¼€å§‹åšå®¢ï¼Œç¬¬ä¸‰æ–¹ï¼Ÿæ–°æµªåšå®¢ã€CSDNã€ç®€ä¹¦ã€QQç©ºé—´ï¼Œä¼˜ç‚¹æ˜¯ä½¿ç”¨æ–¹ä¾¿ï¼Œå®Œæˆè´¦å·æ³¨å†Œåå°±å¯ä»¥å‘è¡¨è‡ªå·±çš„ç¬¬ä¸€ç¯‡æ–‡ç« äº†ï¼Œå°±æ˜¯çœäº‹ã€‚ä¸è¿‡ä»æ­¤å°±ç»‘å®šåœ¨è¯¥å¹³å°ä¸Šï¼Œåç»­å¦‚æœè¿è¥æ–¹ä¿®æ”¹æ”¿ç­–å¦‚ï¼šå†…å®¹é™åˆ¶ã€æœåŠ¡æ”¶è´¹ã€ç”šè‡³å…³é—­æœåŠ¡ï¼Œå¯¹ç”¨æˆ·æ¥è¯´ç”¨å¾—è¶Šä¹…æŸå¤±è¶Šå¤§ï¼›è‡ªå»ºåšå®¢ï¼ŸåŠ¨æ€ç«™ç‚¹ or é™æ€ç«™ç‚¹ã€è¿˜æ˜¯åŸºäºæ¨¡æ¿ç”Ÿæˆçš„ä¼ªé™æ€ï¼Œå„æœ‰ä¼˜ç¼ºç‚¹ï¼Œå½“æ—¶åŠ¨æ€åšå®¢ä¸»æµæ–¹æ¡ˆæ˜¯ä¹°ä¸»æœºï¼Œéƒ¨ç½²ä¸€å¥—PHPåšå®¢ç«™ç‚¹ï¼Œä»ç•Œé¢åˆ°åŠŸèƒ½å†åˆ°ç»´æŠ¤ï¼Œå…¶å®æ­å»ºç®¡ç†æˆæœ¬å¹¶ä¸ä½ï¼›é™æ€ç½‘ç«™ç›´æ¥ç¼–å†™HTMLæ–‡ä»¶åˆ›å»ºæˆæœ¬è¶³å¤Ÿä½ï¼Œä½†å¤±å»æ‰©å±•æ€§ï¼Œåç»­è¦åŠ ä¸ªåŠŸèƒ½æ”¹ä¸ªå¤–è§‚å•¥çš„å°±å¾ˆéš¾äº†ã€‚æƒ³æ¥æƒ³å»æ²¡æœ‰æ»¡æ„çš„æ–¹æ¡ˆå°±æš‚æ—¶æç½®äº†ï¼Œåæ­£å†™æ–‡ä»¶å­˜åœ¨è‡ªå·±ç”µè„‘ä¸Šä¹Ÿæ²¡å•¥é—®é¢˜ã€‚ é‚£ä»¥å‰è¿™äº›ç–‘è™‘è§£å†³äº†å—ï¼Ÿåšå®¢ç«™ç»è¿‡åå¤šå¹´çš„å‘å±•ï¼Œå¸‚åœºå¤§æµªæ·˜æ²™ï¼Œå‰©ä¸‹æ¥çš„æœåŠ¡å•†éƒ½æœ‰è‡ªå·±çš„ç”Ÿå­˜ä¹‹é“ï¼Œçªç„¶å…³é—­çš„é£é™©å°äº†å¾ˆå¤šã€‚è‡ªå»ºåšå®¢çš„æ–¹æ¡ˆä¹Ÿå·²ç»æˆç†Ÿï¼Œä¸»æµçš„å‡ ç§é¢å‘æœ‰ä¸åŒéœ€æ±‚çš„äººç¾¤ã€‚æ— æŠ€æœ¯èƒŒæ™¯é€‰æ‹©åšå®¢ç½‘ç«™æˆ–è€…äº‘æœåŠ¡å•†çš„åšå®¢ç½‘ç«™+äº‘æœåŠ¡å™¨å¥—é¤ï¼Œæ·˜å®ä¸Šä¹Ÿæœ‰å¤§æŠŠå„å¼åšå®¢å»ºç«™ï¼Œå®Œå…¨å¯ä»¥æä½ä»·æ ¼æ­å»ºä¸€å¥—ä¸ªäººåšå®¢ç«™ã€‚æ‡‚ç‚¹æŠ€æœ¯çš„ä¸€ä¸ªæ¯”è¾ƒå¥½çš„é€‰æ‹©ä½¿ç”¨GitHub Pageså»ºç«™ï¼Œé™¤äº†èŠ±ç‚¹æ—¶é—´æ— å…¶å®ƒæˆæœ¬ï¼Œè€Œå¥½å¤„æ˜¯ä¸Šé¢ä¸¤ç§æ–¹å¼æ— æ³•æ¯”æ‹Ÿçš„ï¼Œæˆ‘éšä¾¿åˆ—ä¸¾å‡ ä¸ªï¼šæ— åŸŸåæœåŠ¡å™¨è´¹ç”¨ã€æœ¬åœ°å’Œå’Œè¿œç¨‹åŒå‰¯æœ¬æ•°æ®æœ‰ä¿éšœã€æ–¹ä¾¿è¿ç§»å’Œå¤šç«™åŒæ­¥â€¦æ€»ç»“å°±æ˜¯:çœŸé¦™ï¼" } ]
